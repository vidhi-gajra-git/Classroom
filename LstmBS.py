{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7280095,"sourceType":"datasetVersion","datasetId":4221054}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:24.507629Z","iopub.execute_input":"2025-02-10T08:29:24.507949Z","iopub.status.idle":"2025-02-10T08:29:24.515206Z","shell.execute_reply.started":"2025-02-10T08:29:24.507927Z","shell.execute_reply":"2025-02-10T08:29:24.514260Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat\n/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Salinas_gt.mat\n/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/PaviaU_gt.mat\n/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/KSC.mat\n/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Salinas_corrected.mat\n/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat\n/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/PaviaU.mat\n/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/KSC_gt.mat\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom scipy.io import loadmat\n\ndef load_IndianPines_dataset_lstm(data_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat',\n                                  gt_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat'):\n    \"\"\"\n    Loads the hyperspectral data and ground truth labels for the Indian Pines dataset.\n    For LSTM input, each pixel's spectral signature is treated as a sequence.\n    \n    Args:\n        data_filepath (str): Path to the hyperspectral data file (MAT file).\n        gt_filepath (str): Path to the ground truth (GT) file (MAT file).\n    \n    Returns:\n        X (torch.FloatTensor): Tensor of shape (N, sequence_length, input_dim) where\n                               N is the number of labeled pixels,\n                               sequence_length is the number of spectral bands,\n                               input_dim is typically 1 (each band is a scalar value).\n        y (torch.LongTensor): Tensor of shape (N,) with the class labels.\n    \"\"\"\n    # Load hyperspectral data from the MAT file.\n    # The data is assumed to be in the variable 'indian_pines_corrected'\n    # with shape (H, W, C) where H and W are spatial dimensions and C is the number of spectral bands.\n    data = loadmat(data_filepath)['indian_pines_corrected']\n    print(\"Original data shape:\", data.shape)  # (H, W, C)\n    \n    # Normalize the data to the range [-1, 1]\n    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n    data = (data * 2) - 1  # Scale to range [-1, 1]\n    \n    # Load ground truth labels from the GT file.\n    # The GT data is assumed to be in the variable 'indian_pines_gt' with shape (H, W)\n    gt = loadmat(gt_filepath)['indian_pines_gt']\n    print(\"Ground truth shape:\", gt.shape)  # (H, W)\n    \n    # Get spatial dimensions and number of spectral bands.\n    H, W, C = data.shape  # H: height, W: width, C: number of spectral bands\n    \n    # Reshape the hyperspectral data so that each pixel's spectral signature is a separate sample.\n    # First, flatten the spatial dimensions: the new shape becomes (H*W, C)\n    data_flat = data.reshape(-1, C)  # Each row is one pixel's spectrum.\n    \n    # For LSTM input, we want each pixel to be a sequence.\n    # Here, each pixel's spectral signature is a sequence of length C.\n    # We add a feature dimension (input_dim). In our case, each spectral band is a single value, so input_dim=1.\n    # The resulting shape becomes (H*W, C, 1)\n    X = data_flat[:, :, np.newaxis]\n    \n    # Flatten the ground truth labels to align with the pixels.\n    # The GT shape becomes (H*W,)\n    y = gt.reshape(-1)\n    \n    # Optionally, remove pixels with a label of 0 (often used for unlabeled or background pixels)\n    valid_idx = y > 0  # Keep only pixels with a valid class label.\n    X = X[valid_idx]\n    y = y[valid_idx]\n    \n    print(\"Number of valid pixels (samples):\", X.shape[0])\n    \n    # Convert numpy arrays to PyTorch tensors.\n    X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: (N, sequence_length, input_dim)\n    y_tensor = torch.tensor(y, dtype=torch.long)       # Shape: (N,)\n    \n    return X_tensor, y_tensor\n\n# Example usage:\nif __name__ == \"__main__\":\n    X, y = load_IndianPines_dataset_lstm()\n    print(\"X shape (for LSTM):\", X.shape)  # Expected: (N, C, 1) where N is the number of labeled pixels\n    print(\"y shape:\", y.shape)             # Expected: (N,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:24.523743Z","iopub.execute_input":"2025-02-10T08:29:24.524045Z","iopub.status.idle":"2025-02-10T08:29:24.698893Z","shell.execute_reply.started":"2025-02-10T08:29:24.524020Z","shell.execute_reply":"2025-02-10T08:29:24.698035Z"}},"outputs":[{"name":"stdout","text":"Original data shape: (145, 145, 200)\nGround truth shape: (145, 145)\nNumber of valid pixels (samples): 10249\nX shape (for LSTM): torch.Size([10249, 200, 1])\ny shape: torch.Size([10249])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom scipy.io import loadmat\n\n# ----------------------------\n# 1. Data Loading Function\n# ----------------------------\n\ndef load_IndianPines_dataset_lstm(data_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat',\n                                  gt_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat'):\n    \"\"\"\n    Loads the hyperspectral data and ground truth labels for the Indian Pines dataset.\n    For LSTM input, each pixel's spectral signature is treated as a sequence.\n    \n    Args:\n        data_filepath (str): Path to the hyperspectral data file (MAT file).\n        gt_filepath (str): Path to the ground truth (GT) file (MAT file).\n    \n    Returns:\n        X (torch.FloatTensor): Tensor of shape (N, sequence_length, input_dim) where\n                               N is the number of labeled pixels,\n                               sequence_length is the number of spectral bands,\n                               input_dim is 1 (each band is a scalar value).\n        y (torch.LongTensor): Tensor of shape (N,) with the class labels.\n    \"\"\"\n    # Load hyperspectral data (expected shape: H x W x C)\n    data = loadmat(data_filepath)['indian_pines_corrected']\n    print(\"Original data shape:\", data.shape)\n    \n    # Normalize data to the range [-1, 1]\n    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n    data = (data * 2) - 1\n    \n    # Load ground truth labels (expected shape: H x W)\n    gt = loadmat(gt_filepath)['indian_pines_gt']\n    plt.imshow(gt)\n    print(\"Ground truth shape:\", gt.shape)\n    \n    H, W, C = data.shape\n    \n    # Flatten spatial dimensions so each pixel's spectrum is one sample.\n    data_flat = data.reshape(-1, C)  # shape: (H*W, C)\n    # For LSTM: each pixel becomes a sequence (sequence length = C, input_dim = 1)\n    X = data_flat[:, :, np.newaxis]  # shape: (N, C, 1)\n    \n    # Flatten ground truth to align with pixels.\n    y = gt.reshape(-1)\n    \n    # Filter out unlabeled pixels (assuming label 0 is unlabeled)\n    valid_idx = y >0\n    X = X[valid_idx]\n    y = y[valid_idx]\n    \n    print(\"Number of labeled pixels:\", X.shape[0])\n    \n    # Convert to PyTorch tensors.\n    X_tensor = torch.tensor(X, dtype=torch.float32)\n    y_tensor = torch.tensor(y, dtype=torch.long)\n    \n    return X_tensor, y_tensor\n\n# ----------------------------\n# 2. Model: BiLSTM with Attention\n# ----------------------------\n\nclass BiLSTMWithAttention(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n        \"\"\"\n        Args:\n            input_dim (int): Number of features per time step (e.g., spectral bands per pixel).\n            hidden_dim (int): Number of hidden units in each LSTM direction.\n            num_layers (int): Number of stacked LSTM layers.\n            output_dim (int): Number of classes for classification.\n        \"\"\"\n        super(BiLSTMWithAttention, self).__init__()\n        \n        # Bidirectional LSTM: output features per time step = 2 * hidden_dim.\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n                            batch_first=True, bidirectional=True) # Set bidirectional to True\n        \n        # Final classification layer: we use 2 * hidden_dim because of bidirectionality\n        self.fc = nn.Linear(hidden_dim*2 , output_dim)  # 2 * hidden_dim for bidirectional LSTM\n    \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, sequence_length, input_dim)\n        Returns:\n            out: Class scores of shape (batch_size, output_dim)\n        \"\"\"\n        # x: (B, L, input_dim)\n        lstm_out, _ = self.lstm(x)  # lstm_out: (B, L, 2 * hidden_dim) due to bidirectional LSTM\n        \n        # We take the output of the last time step (LSTM last hidden state)\n        last_hidden_state = lstm_out[:, -1, :]  # (B, 2 * hidden_dim)\n        \n        # Final classification layer\n        out = self.fc(last_hidden_state)  # (B, output_dim)\n        \n        return out, None \n   \n\n# ----------------------------\n# 3. Training Setup and Loop\n# ----------------------------\n\ndef train_model(model, train_loader, test_loader, device='cuda', num_epochs=50, lr=1e-3, subtract_one=True):\n    criterion = nn.CrossEntropyLoss()  # expects target indices in [0, output_dim-1]\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    train_losses = []\n    test_losses = []\n    test_accuracies = []\n    \n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        epoch_train_loss = 0.0\n        \n        for X_batch, y_batch in train_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            optimizer.zero_grad()\n            outputs, _ = model(X_batch)\n            \n            # If your ground truth labels start at 1 (e.g., 1 to num_classes),\n            # subtract 1 so that they are in the range [0, num_classes-1].\n            targets = (y_batch - 1) if subtract_one else y_batch\n            \n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            epoch_train_loss += loss.item() * X_batch.size(0)\n        \n        epoch_train_loss /= len(train_loader.dataset)\n        train_losses.append(epoch_train_loss)\n        \n        # Evaluate on the test set.\n        model.eval()\n        epoch_test_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for X_batch, y_batch in test_loader:\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                outputs, _ = model(X_batch)\n                targets = (y_batch - 1) if subtract_one else y_batch\n                loss = criterion(outputs, targets)\n                epoch_test_loss += loss.item() * X_batch.size(0)\n                \n                _, predicted = torch.max(outputs, 1)\n                total += y_batch.size(0)\n                correct += (predicted == targets).sum().item()\n        \n        epoch_test_loss /= len(test_loader.dataset)\n        test_losses.append(epoch_test_loss)\n        test_accuracy = correct / total\n        test_accuracies.append(test_accuracy)\n        \n        print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, \"\n              f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {test_accuracy:.4f}\")\n    \n    return train_losses, test_losses, test_accuracies\n\n# ----------------------------\n# 4. Plotting Functions\n# ----------------------------\n\ndef plot_losses(train_losses, test_losses):\n    plt.figure(figsize=(8, 5))\n    plt.plot(train_losses, label=\"Train Loss\")\n    plt.plot(test_losses, label=\"Test Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training and Test Loss\")\n    plt.legend()\n    plt.show()\n\ndef plot_attention(band_indices, avg_attn_weights):\n    plt.figure(figsize=(10, 5))\n    plt.stem(band_indices, avg_attn_weights, use_line_collection=True)\n    plt.xlabel(\"Spectral Band Index\")\n    plt.ylabel(\"Average Attention Weight\")\n    plt.title(\"Average Attention Weights for Spectral Bands\")\n    plt.show()\n\n# ----------------------------\n# 5. Main: Load Data, Train Model, Plot Results\n# ----------------------------\n\n    # Optionally set CUDA_LAUNCH_BLOCKING=1 in your environment for debugging:\n    #   %env CUDA_LAUNCH_BLOCKING=1   (in Jupyter Notebook)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# device=torch.device('cpu')\nprint(\"Using device:\", device)\n\n# Load data (adjust paths if needed)\nX, y = load_IndianPines_dataset_lstm(\n)\n# X: (N, sequence_length, 1), y: (N,)\n\n# Determine the number of classes based on ground truth.\n# If your labels are 1-indexed, then:\nnum_classes = int(y.max().item())\nprint(\"Number of classes:\", num_classes)\n\n# Split into training and test sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Create DataLoaders\nbatch_size = 64\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset  = TensorDataset(X_test, y_test)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Model hyperparameters:\n# Our LSTM expects input_dim = 1 (each spectral band is one measurement),\n# and the sequence length equals the number of spectral bands.\ninput_dim = 1       \nhidden_dim = 128\nnum_layers = 3\noutput_dim = num_classes  # Set output_dim equal to the number of classes.\n\n# Instantiate and move the model to the device.\nmodel = BiLSTMWithRegularization(input_dim, hidden_dim, num_layers, output_dim).to(device)\nprint(model)\n\n# Train the model.\n# If your ground truth labels are 1-indexed, we subtract one inside the training loop.\nnum_epochs = 50\ntrain_losses, test_losses, test_accuracies = train_model(\n    model, train_loader, test_loader, device, num_epochs=num_epochs, subtract_one=True\n)\n\n# Plot training and test losses.\nplot_losses(train_losses, test_losses)\n\n# ----------------------------\n# 6. Extract and Plot Average Attention Weights (Band Importance)\n# ----------------------------\nmodel.eval()\nall_attn_weights = []\nwith torch.no_grad():\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        _, attn_weights = model(X_batch)\n        # attn_weights: (B, sequence_length, 1); squeeze last dimension.\n        all_attn_weights.append(attn_weights.squeeze(-1).cpu().numpy())\n\n# Concatenate attention weights from all batches: (num_samples, sequence_length)\nall_attn_weights = np.concatenate(all_attn_weights, axis=0)\n# Compute the average attention weight for each spectral band.\navg_attn_weights = np.mean(all_attn_weights, axis=0)\n\nband_indices = np.arange(avg_attn_weights.shape[0])\nplot_attention(band_indices, avg_attn_weights)\n\n# Plot test accuracy over epochs.\nplt.figure(figsize=(8, 5))\nplt.plot(test_accuracies, label=\"Test Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Test Accuracy Over Epochs\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:24.715925Z","iopub.execute_input":"2025-02-10T08:29:24.716229Z","iopub.status.idle":"2025-02-10T08:29:25.396989Z","shell.execute_reply.started":"2025-02-10T08:29:24.716206Z","shell.execute_reply":"2025-02-10T08:29:25.394145Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nOriginal data shape: (145, 145, 200)\nGround truth shape: (145, 145)\nNumber of labeled pixels: 10249\nNumber of classes: 16\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-e4a1f9b70277>\u001b[0m in \u001b[0;36m<cell line: 235>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;31m# Instantiate and move the model to the device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBiLSTMWithRegularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BiLSTMWithRegularization' is not defined"],"ename":"NameError","evalue":"name 'BiLSTMWithRegularization' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.397576Z","iopub.status.idle":"2025-02-10T08:29:25.397825Z","shell.execute_reply":"2025-02-10T08:29:25.397724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%env CUDA_LAUNCH_BLOCKING=1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.398471Z","iopub.status.idle":"2025-02-10T08:29:25.398762Z","shell.execute_reply":"2025-02-10T08:29:25.398654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.system(\"nvidia-smi\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.399427Z","iopub.status.idle":"2025-02-10T08:29:25.399800Z","shell.execute_reply":"2025-02-10T08:29:25.399638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the LSTM Autoencoder Model\nclass LSTM_Autoencoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, seq_len):\n        super(LSTM_Autoencoder, self).__init__()\n        \n        # Encoder\n        self.lstm_encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        \n        # Decoder\n        self.lstm_decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, input_dim)  # Fully connected layer to output original dimension\n    \n    def forward(self, x):\n        # Encoder\n        _, (hn, _) = self.lstm_encoder(x)\n        \n        # Repeat the latent state (hn) to match the sequence length\n        decoder_input = hn[-1, :, :].unsqueeze(1).repeat(1, x.size(1), 1)  # Repeat for seq_len\n        \n        # Decoder\n        decoded, _ = self.lstm_decoder(decoder_input)\n        \n        # Output layer (fully connected)\n        decoded = self.fc(decoded)\n        \n        return decoded\n\n# Sample sequence (same as in the Keras code)\nsequence = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\nsequence = sequence.reshape((1, len(sequence), 1))  # Shape (1, seq_len, 1)\n\n# Convert the sequence to a PyTorch tensor\nsequence_tensor = torch.tensor(sequence, dtype=torch.float32)\n\n# Model parameters\ninput_dim = 1\nhidden_dim = 100\nseq_len = sequence.shape[1]\n\n# Initialize the model\nmodel = LSTM_Autoencoder(input_dim, hidden_dim, seq_len)\n\n# Loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nepochs = 300\nfor epoch in range(epochs):\n    model.train()\n    \n    # Forward pass\n    output = model(sequence_tensor)\n    \n    # Compute the loss\n    loss = criterion(output, sequence_tensor)\n    \n    # Backward pass and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # Print the loss after each epoch\n    if epoch % 50 == 0:\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n\n# Predict with the trained model\nmodel.eval()\nwith torch.no_grad():\n    reconstructed_sequence = model(sequence_tensor)\n\n# Print the reconstructed sequence\nreconstructed_sequence = reconstructed_sequence.squeeze().numpy()\nprint(\"Reconstructed Sequence:\", reconstructed_sequence)\n\n# Plot the original and reconstructed sequence\nplt.plot(sequence[0, :, 0], label='Original Sequence')\nplt.plot(reconstructed_sequence, label='Reconstructed Sequence')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.400911Z","iopub.status.idle":"2025-02-10T08:29:25.401223Z","shell.execute_reply":"2025-02-10T08:29:25.401114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \ntorch.cuda.empty_cache()\nimport gc\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.401889Z","iopub.status.idle":"2025-02-10T08:29:25.402179Z","shell.execute_reply":"2025-02-10T08:29:25.402046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom scipy.io import loadmat\nimport random\n# Define the LSTM Autoencoder Model\nclass LSTM_Autoencoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, seq_len):\n        super(LSTM_Autoencoder, self).__init__()\n        \n        # Encoder\n        self.lstm_encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.latent=None\n        # Decoder\n        self.lstm_decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, input_dim)  # Fully connected layer to output original dimension\n    \n    def forward(self, x):\n        # Encoder\n        _, (hn, _) = self.lstm_encoder(x)\n        \n        # Repeat the latent state (hn) to match the sequence length\n        decoder_input = hn[-1, :, :].unsqueeze(1).repeat(1, x.size(1), 1)  # Repeat for seq_len\n        \n        # Decoder\n        decoded, _ = self.lstm_decoder(decoder_input)\n        \n        # Output layer (fully connected)\n        decoded = self.fc(decoded)\n        \n        return decoded\n\n# Load the hyperspectral image dataset\ndef load_IndianPines_dataset_lstm(data_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat', gt_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat'):\n    from scipy.io import loadmat\n    # Load hyperspectral data (expected shape: H x W x C)\n    data = loadmat(data_filepath)['indian_pines_corrected']\n    print(\"Original data shape:\", data.shape)\n    \n    # Normalize data to the range [-1, 1]\n    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n    data = (data * 2) - 1  # Normalize to range [-1, 1]\n    \n    # Load ground truth labels (expected shape: H x W)\n    gt = loadmat(gt_filepath)['indian_pines_gt']\n    print(\"Ground truth shape:\", gt.shape)\n    \n    H, W, C = data.shape\n    \n    # Flatten spatial dimensions so each pixel's spectrum is one sample\n    data_flat = data.reshape(-1, C)  # shape: (H*W, C)\n    X = data_flat[:, :, np.newaxis]  # shape: (N, C, 1)\n    \n    # Flatten ground truth to align with pixels\n    y = gt.reshape(-1)\n    \n    # Filter out unlabeled pixels (assuming label 0 is unlabeled)\n    valid_idx = y > 0\n    X = X[valid_idx]\n    y = y[valid_idx]\n    \n    print(\"Number of labeled pixels:\", X.shape[0])\n    \n    # Convert to PyTorch tensors\n    X_tensor = torch.tensor(X, dtype=torch.float32)\n    y_tensor = torch.tensor(y, dtype=torch.long)\n    \n    return X_tensor, y_tensor\n\n# Load the dataset\ndata_filepath = '/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat'\ngt_filepath = '/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat'\nX, y = load_IndianPines_dataset_lstm(data_filepath, gt_filepath)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define model parameters\ninput_dim = 1  # Each band is a single feature\nhidden_dim = 100\nseq_len = X_train.shape[1]  # Sequence length = number of spectral bands (C)\n\n# Initialize the model\nmodel = LSTM_Autoencoder(input_dim, hidden_dim, seq_len)\n\n# Check if GPU is available, if not use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Move model to the selected device (GPU/CPU)\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# Training the model\nepochs = 300\nbatch_size = 128\n\n# Training the model\nfor epoch in range(epochs):\n    model.train()  # Ensure model is in training mode during training\n    total_loss = 0\n    \n    # Mini-batch training\n    for i in range(0, len(X_train), batch_size):\n        X_batch = X_train[i:i+batch_size]\n        y_batch = y_train[i:i+batch_size]\n        \n        # Move batch to the selected device (GPU/CPU)\n        X_batch = X_batch.to(device)\n        y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n        \n        # Forward pass\n        output = model(X_batch)\n        \n        # Compute the loss\n        loss = criterion(output, X_batch)\n        total_loss += loss.item()\n        \n        # Backward pass and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # After each mini-batch, plot a random sample from the train set\n        if epoch % 20 == 0 and i% (batch_size*20)==0:  # Plot every 5 mini-batches (to reduce plot frequency)\n            # Pick a random sample from the training set\n            index = random.randint(0, X_batch.shape[0] - 1)\n            \n            # Convert batch to numpy for plotting\n            original = X_batch.squeeze().cpu().numpy()\n            reconstructed = output.squeeze().detach().cpu().numpy()\n            \n            plt.figure(figsize=(10, 5))\n            plt.plot(original[index, :], label='Original Sequence')\n            plt.plot(reconstructed[index, :], label='Reconstructed Sequence')\n            plt.legend()\n            plt.title(f\"Epoch [{epoch+1}/{epochs}] - Sample {index} - Original vs Reconstructed\")\n            plt.show()\n\n    # Print the loss after each epoch\n    print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(X_train):.8f}')\n\n# At the end of training, switch the model to evaluation mode if needed\nmodel.eval()\nwith torch.no_grad():\n    # Testing and further evaluation...\n    X_test = X_test.to(device)\n    test_output = model(X_test)\n    test_loss = criterion(test_output, X_test)\n    print(f'Test MSE Loss: {test_loss.item():.4f}')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.403333Z","iopub.status.idle":"2025-02-10T08:29:25.403727Z","shell.execute_reply":"2025-02-10T08:29:25.403560Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport time\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.metrics import structural_similarity as ssim\n\nclass LSTM_Autoencoder_with_latent(nn.Module):\n    def __init__(self, input_dim, hidden_dim, seq_len):\n        super(LSTM_Autoencoder_with_latent, self).__init__()\n        \n        # Encoder\n        self.lstm_encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        \n        # Decoder\n        self.lstm_decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, input_dim)  # Fully connected layer to output original dimension\n    \n    def forward(self, x):\n        # Encoder\n        _, (hn, _) = self.lstm_encoder(x)\n        \n        # Return the latent (encoded) feature for SSIM comparison\n        latent = hn[-1, :, :]  # Latent feature is the last hidden state (from the last layer of LSTM)\n        \n        # Repeat the latent state (hn) to match the sequence length\n        decoder_input = hn[-1, :, :] .unsqueeze(1).repeat(1, x.size(1), 1)  # Repeat for seq_len\n        \n        # Decoder\n        decoded, _ = self.lstm_decoder(decoder_input)\n        \n        # Output layer (fully connected)\n        decoded = self.fc(decoded)\n        \n        return decoded, latent  # Return both decoded and latent\n\ndef compute_ssim_between_latent_and_original(original, latent):\n    \"\"\"\n    Compute SSIM between original hyperspectral bands and the latent features.\n    original and latent should be of the shape (batch_size, seq_len, 1)\n    \"\"\"\n    # Initialize an array to hold SSIM values for each band\n    ssim_values = np.zeros(original.shape[2])\n\n    # Iterate over each band\n    for band in range(original.shape[2]):\n        orig_band = original[:, :, band].cpu().numpy()\n        latent_band = latent[:, band].cpu().detach().numpy()\n\n        # Compute SSIM for this band (latent should be a 1D feature for comparison)\n        ssim_values[band] = ssim(orig_band, latent_band, data_range=latent_band.max() - latent_band.min(), multichannel=False)\n\n    return ssim_values\n\n# Initialize the model with latent feature extraction\nmodel = LSTM_Autoencoder_with_latent(input_dim=1, hidden_dim=100, seq_len=X_train.shape[1])\n\n# model.to(device)  # Move model to the selected device (GPU/CPU)\n# model = LSTM_Autoencoder(input_dim, hidden_dim, seq_len)\n\n# Check if GPU is available, if not use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Move model to the selected device (GPU/CPU)\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# Measure computation time for training or evaluation phase\nstart_time = time.time()\nepochs = 300\nbatch_size = 128\n\n# Training the model\nfor epoch in range(epochs):\n    model.train()  # Ensure model is in training mode during training\n    total_loss = 0\n    \n    # Mini-batch training\n    for i in range(0, len(X_train), batch_size):\n        X_batch = X_train[i:i+batch_size]\n        y_batch = y_train[i:i+batch_size]\n        \n        # Move batch to the selected device (GPU/CPU)\n        X_batch = X_batch.to(device)\n        y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n        \n        # Forward pass\n        \n        output, latent = model(X_batch)\n        \n        # Compute the loss\n        loss = criterion(output, X_batch)\n        total_loss += loss.item()\n        \n        # Backward pass and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # After each mini-batch, plot a random sample from the train set\n        if epoch % 20 == 0 and i% (batch_size*40)==0:  # Plot every 5 mini-batches (to reduce plot frequency)\n            # Pick a random sample from the training set\n            index = random.randint(0, X_batch.shape[0] - 1)\n            \n            # Convert batch to numpy for plotting\n            original = X_batch.squeeze().cpu().numpy()\n            reconstructed = output.squeeze().detach().cpu().numpy()\n            \n            plt.figure(figsize=(10, 5))\n            plt.plot(original[index, :], label='Original Sequence')\n            plt.plot(reconstructed[index, :], label='Reconstructed Sequence')\n            plt.legend()\n            plt.title(f\"Epoch [{epoch+1}/{epochs}] - Sample {index} - Original vs Reconstructed\")\n            plt.show()\n\n    # Print the loss after each epoch\n    print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(X_train):.8f}')\nend_time=time.time()\nprint(f\"Total computation time = {end_time-start_time}\")\n# Assuming model and data are already defined, perform the forward pass and extract latent features\nstart_time=time.time()\nmodel.eval()\nwith torch.no_grad():\n    # Move data to the device\n    X_test = X_test.to(device)\n    \n    # Get the decoded output and latent feature from the model\n    decoded_output, latent_features = model(X_test)  # decoded_output: [batch_size, seq_len, input_dim]\n    \n    # Compute SSIM values for each band between original and latent features\n    ssim_values = compute_ssim_between_latent_and_original(X_test, latent_features)\n\n# End time measurement\nend_time = time.time()\ncomputation_time = end_time - start_time\nprint(f\"Computation Time: {computation_time:.4f} seconds\")\n\n# Plot SSIM values for each band\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, len(ssim_values) + 1), ssim_values, marker='o')\nplt.title('SSIM between Original Bands and Latent Features')\nplt.xlabel('Band Number')\nplt.ylabel('SSIM Value')\nplt.grid(True)\nplt.show()\n\n# Rank bands based on SSIM values and identify important bands\nimportant_bands = np.argsort(ssim_values)[::-1]  # Sort in descending order of SSIM (higher is better)\nprint(\"Important Bands (sorted by SSIM):\", important_bands)\n\n# Optionally, visualize the most important band\ntop_band_idx = important_bands[0]\nprint(f\"Most important band: {top_band_idx + 1} with SSIM: {ssim_values[top_band_idx]}\")\n\n# Visualize the original and latent features for the most important band\nindex = 0  # Random sample index from X_test\noriginal_band = X_test[index, :, top_band_idx].cpu().numpy()\nlatent_band = latent_features[index, top_band_idx].cpu().detach().numpy()\n\nplt.figure(figsize=(10, 5))\nplt.plot(original_band, label='Original Band', color='blue')\nplt.plot(latent_band, label='Latent Feature', color='red', linestyle='--')\nplt.title(f\"Band {top_band_idx + 1} - Original vs Latent Feature\")\nplt.legend()\nplt.show()\n\n# Measure the size of the model (in bytes)\ntorch.save(model.state_dict(), 'model.pth')\nmodel_size = os.path.getsize('model.pth') / (1024 * 1024)  # Convert bytes to megabytes\nprint(f\"Model size: {model_size:.2f} MB\")\n\n# Optionally delete the saved model file to keep the environment clean\nos.remove('model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.404788Z","iopub.status.idle":"2025-02-10T08:29:25.405153Z","shell.execute_reply":"2025-02-10T08:29:25.404989Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(latent.shape)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.406088Z","iopub.status.idle":"2025-02-10T08:29:25.406489Z","shell.execute_reply":"2025-02-10T08:29:25.406304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tqdm import tqdm\ndef compute_latent_band_similarity(latent, original_bands):\n    \"\"\"\n    Compute similarity between latent features and original spectral bands.\n    We use cosine similarity to compare the latent feature and each band in the original hyperspectral data.\n    \n    latent: Tensor of shape (batch_size, hidden_dim)\n    original_bands: Tensor of shape (batch_size, seq_len, input_dim)\n    \n    Returns: similarity scores for each band.\n    \"\"\"\n    # Initialize a list to hold the cosine similarities for each band\n    batch_size, seq_len, _ = original_bands.shape\n    similarity_scores = np.zeros(seq_len)\n\n    # Iterate over each band (spectral band)\n    for band in tqdm(range(seq_len)):\n        # print()\n        # Extract the original band (shape: batch_size, 1)\n        band_data = original_bands[:, band, :].cpu().numpy()  # (batch_size, 1)\n\n        # Get the latent features (shape: batch_size, hidden_dim)\n        latent_data = latent.cpu().detach().numpy()  # (batch_size, hidden_dim)\n\n        # Compute cosine similarity between the latent features and the band\n        # We need to reshape band_data for similarity computation\n        similarity=np.zeros(latent_data[0].reshape(-1, 1).shape)\n        # print(latent_data.shape)\n        # print(f\"Shape of band_data ={band_data.shape}\")\n        similarity=cosine_similarity(latent_data.reshape(-1, 1), band_data.reshape(-1, 1))  # Reshape band_data for similarity computation\n\n        # Take the mean similarity score across the batch\n        similarity_scores[band] = similarity.mean()\n\n    return similarity_scores\ndata_filepath = '/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat'\ngt_filepath = '/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat'\nX, y = load_IndianPines_dataset_lstm(data_filepath, gt_filepath)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# model=torch.load('/kaggle/working/model.pth')\nclass LSTM_Autoencoder_with_latent(nn.Module):\n    def __init__(self, input_dim, hidden_dim, seq_len):\n        super(LSTM_Autoencoder_with_latent, self).__init__()\n        \n        # Encoder\n        self.lstm_encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        \n        # Decoder\n        self.lstm_decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, input_dim)  # Fully connected layer to output original dimension\n    \n    def forward(self, x):\n        # Encoder\n        _, (hn, _) = self.lstm_encoder(x)\n        \n        # Return the latent (encoded) feature for SSIM comparison\n        latent = hn[-1, :, :]  # Latent feature is the last hidden state (from the last layer of LSTM)\n        \n        # Repeat the latent state (hn) to match the sequence length\n        decoder_input = hn[-1, :, :] .unsqueeze(1).repeat(1, x.size(1), 1)  # Repeat for seq_len\n        \n        # Decoder\n        decoded, _ = self.lstm_decoder(decoder_input)\n        \n        # Output layer (fully connected)\n        decoded = self.fc(decoded)\n        \n        return decoded, latent  # Return both decoded and latent\nimport torch\n\n# Define the model architecture (same as the one used for training)\nmodel = LSTM_Autoencoder_with_latent(input_dim=1, hidden_dim=100, seq_len=X_test.shape[1])\n\n# Load the state dictionary\nmodel.load_state_dict(torch.load('/kaggle/working/model.pth'))\n\n# Move the model to the appropriate device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Assuming model and data are already defined, perform the forward pass and extract latent features\n# model.eval()\nwith torch.no_grad():\n    # Move data to the device\n    X_test = X_test.to(device)\n    \n    # Get the decoded output and latent feature from the model\n    decoded_output, latent_features = model(X_test)  # decoded_output: [batch_size, seq_len, input_dim]\n    \n    # Compute similarity scores for each band between latent features and original bands\n    similarity_scores = compute_latent_band_similarity(latent_features, X_test)\n\n# Plot Similarity Scores for each band\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, len(similarity_scores) + 1), np.abs(similarity_scores), marker='o')\nplt.title('Cosine Similarity between Latent Features and Original Bands')\nplt.xlabel('Band Number')\nplt.ylabel('Cosine Similarity')\nplt.grid(True)\nplt.show()\n\n# Rank bands based on similarity scores (higher is better)\nimportant_bands = np.argsort(np.abs(similarity_scores))[::-1]  # Sort in descending order of similarity (higher is better)\nprint(\"Important Bands (sorted by similarity):\", important_bands)\n\n# Optionally, visualize the most important band\ntop_band_idx = important_bands[0]\nprint(f\"Most important band: {top_band_idx + 1} with similarity: {similarity_scores[top_band_idx]}\")\n\n# Visualize the original and latent features for the most important band\nindex = 0  # Random sample index from X_test\noriginal_band = X_test[:,  top_band_idx].cpu().numpy()\nlatent_band = latent_features[:, top_band_idx].cpu().detach().numpy()\n\nplt.figure(figsize=(10, 5))\nplt.plot(original_band, label='Original Band', color='blue')\nplt.plot(latent_band, label='Latent Feature', color='red', linestyle='--')\nplt.title(f\"Band {top_band_idx + 1} - Original vs Latent Feature\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.407354Z","iopub.status.idle":"2025-02-10T08:29:25.407684Z","shell.execute_reply":"2025-02-10T08:29:25.407572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argsort(np.abs(similarity_scores))[::-1] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.408350Z","iopub.status.idle":"2025-02-10T08:29:25.408681Z","shell.execute_reply":"2025-02-10T08:29:25.408545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(range(1, len(similarity_scores) + 1), np.abs(similarity_scores), marker='o')\nplt.title('Cosine Similarity between Latent Features and Original Bands')\nplt.xlabel('Band Number')\nplt.ylabel('Cosine Similarity')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.409717Z","iopub.status.idle":"2025-02-10T08:29:25.409989Z","shell.execute_reply":"2025-02-10T08:29:25.409877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.pth')\nmodel_size = os.path.getsize('model.pth') / (1024 * 1024)  # Convert bytes to megabytes\nprint(f\"Model size: {model_size:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.410781Z","iopub.status.idle":"2025-02-10T08:29:25.411070Z","shell.execute_reply":"2025-02-10T08:29:25.410962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" selected_bands=[\n    41, 37, 40, 38, 42, 43, 47, 49, 48, 51, 50, 36, 52, 44, 46, 6, 7, 8,\n    45, 5, 15, 14, 16, 13, 63, 10, 17, 65, 11, 53, 9, 64, 21, 18, 33, 66,\n    67, 68, 20, 69, 22, 19, 24, 28, 12, 27, 25, 23, 34, 54, 70, 26, 62, 39,\n    55, 71, 30, 32, 35, 72, 4, 29, 31, 73, 2, 3, 61, 153, 154, 155, 156, 157,\n    158, 159, 144, 145, 146, 147, 148, 149, 167, 150, 151, 56, 57, 58, 59, 60, 136, 137,\n    138, 139, 140, 141, 142, 143, 152, 1, 184, 185, 186, 0, 188, 189, 190, 191, 176, 177,\n    178, 179, 180, 181, 164, 166, 165, 198, 163, 162, 161, 160, 182, 174, 173, 172, 171, 170,\n    169, 168, 183, 175, 125, 124, 123, 122, 121, 120, 119, 74, 117, 116, 115, 114, 113, 112,\n    111, 110, 118, 197, 196, 187, 132, 195, 194, 193, 192, 126, 134, 133, 199, 131, 130, 129,\n    128, 127, 135, 90, 89, 88, 87, 86, 85, 84, 109, 82, 81, 80, 79, 78, 77, 76,\n    75, 83, 108, 107, 106, 105, 104, 103, 102, 101, 91, 99, 98, 97, 96, 95, 94, 93,\n    92, 100\n]\n\n#  adam optimizer gradient backpropagation \n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\nimport cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom cuml.ensemble import RandomForestClassifier\nimport scipy.io\nimport math \nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef preprocess_data(image, ground_truth, selected_bands, train_ratio=0.8):\n\n    rows, cols, bands = image.shape\n    # print(image.shape )\n    new_image=image[:,:,selected_bands]\n    # print(new_image.shape)\n    \n    reshaped_data = image.reshape((-1, bands))\n\n    reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(new_image)# Flatten spatial dimensions into 2D\n    reshaped_gt = ground_truth.flatten()  # Flatten ground truth\n\n    # Remove pixels where ground truth is 0 (no label)\n    valid_mask = reshaped_gt >0\n    reshaped_data = reshaped_data[valid_mask]\n    # reshaped_data = new_image [valid_mask]\n    \n    reshaped_gt = reshaped_gt[valid_mask]\n    # rows, cols, bands = image.shape\n    # new_image = image[:, :, selected_bands]\n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    \n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(reshaped_data.shape)# Flatten spatial dimensions into 2D\n    # reshaped_gt = ground_truth.flatten()# Flatten ground truth\n\n    # # Remove pixels where ground truth is 0 (no label)\n    # valid_mask = reshaped_gt >= 0\n    # reshaped_data = reshaped_data[valid_mask]\n    # reshaped_gt = reshaped_gt[valid_mask]\n\n    # Split into train and test\n    num_train = int(len(reshaped_gt) * train_ratio)\n    train_data = reshaped_data[:num_train]\n    train_gt = reshaped_gt[:num_train]\n    test_data = reshaped_data[num_train:]\n    test_gt = reshaped_gt[num_train:]\n    # print(f\"Shape of gt is {train_gt.shape}\")\n\n    return train_data, train_gt, test_data, test_gt\n\n# Load hyperspectral data\ntrain_data = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat')\nimage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\ngt= scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']  # Ground truth (training)\n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\n\n# Selected bands\n# selected_bands = [37, 176, 9, 139, 25, 88, 12, 19, 20, 46, 145, 153, 83, 23, 104, 39, 27, 68, 84, 152, 181, 60, 174, 119, 172, 70, 101, 131, 3, 63, 6, 190, 66, 110, 74, 165, 175, 62, 157, 5]\n\n# Store average frequency of bands for each iteration\navg_frequencies = []\nband_collection=[]\nfor i in range(1, len(selected_bands) + 1):\n    band_collection.append(selected_bands[i if i <=1 else (i-1)*((-1)**i)])\nfor i in range(1, len(selected_bands) + 1,10):\n   \n    # Load the training data\n    # train_data = scipy.io.loadmat('/kaggle/working/Indian_pines_corrected.mat')\n    # mage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\n    # train_gt = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']   # Ground truth (training)\n    \n    print(band_collection[:i])\n    \n    # Preprocess data\n    train_data, train_gt, test_data, test_gt = preprocess_data(image, gt, sorted(band_collection[:i]))\n    \n    # Convert to CuPy arrays\n    train_data_cp = cp.array(train_data).astype('float32')\n    train_gt_cp = cp.array(train_gt).astype('int32')\n    test_data_cp = cp.array(test_data).astype('float32')\n    test_gt_cp = cp.array(test_gt).astype('int32')\n\n    # Normalize\n    train_mean = cp.mean(train_data_cp, axis=0)\n    train_std = cp.std(train_data_cp, axis=0)\n    train_data_cp = (train_data_cp - train_mean) / train_std\n    test_data_cp = (test_data_cp - train_mean) / train_std\n\n    # Train Random Forest model\n    rf_model = RandomForestClassifier(n_estimators=400,n_streams=1, max_depth=25, random_state=42)\n    rf_model.fit(train_data_cp, train_gt_cp)\n\n    # Predict on test set\n    predictions_cp = rf_model.predict(test_data_cp)\n    predictions = cp.asnumpy(predictions_cp)\n    test_gt_np = cp.asnumpy(test_gt_cp)\n\n    # Compute accuracy and confusion matrix\n    conf_matrix = confusion_matrix(test_gt_np, predictions)\n    class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n\n    # Average band importance (store for plotting)\n    avg_frequencies.append(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n\n    # Display results\n    # print(\"\\nClassification Report:\")\n    print(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n    \n    # Create classification maps\n    # pred_map = np.zeros_like(train_gt.flatten())\n    height=int(145*0.8)\n    width=int(145*0.8)\n    # train_gt_reshaped = train_gt.reshape(height, width)\n    # test_gt_reshaped=test_gt.reshape(int(145*0.2), 145)\n    # print(f\"reshaped  = {train_gt_reshaped.shape}\")\n    \n    # pred_map[-len(predictions):] = predictions\n    # pred_map = predictions.reshape(int(145*0.2), 145)\n    # plt.figure(figsize=(12, 6))\n    # plt.subplot(1, 2, 1)\n    # plt.title(\"Actual Classification\")\n\n    # plt.imshow(test_gt_reshaped, cmap=\"jet\")\n    # plt.colorbar()\n    # plt.subplot(1, 2, 2)\n    # plt.title(\"Predicted Classification\")\n    # plt.imshow(pred_map, cmap=\"jet\")\n    # plt.colorbar()\n    # plt.show()\n\n# Plot average frequencies\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(selected_bands) + 1,10), avg_frequencies, marker='o')\nplt.xlabel(\"Iteration (Number of Bands Selected)\")\nplt.ylabel(\"Average accuracy achieved\")\nplt.title(\"Average Frequency of Bands per Iteration\")\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.411645Z","iopub.status.idle":"2025-02-10T08:29:25.411956Z","shell.execute_reply":"2025-02-10T08:29:25.411803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" selected_bands=[114, 113, 112, 115, 116, 117, 111, 138, 118, 137, 119, 171, 110, 140, 139, 108, 172, 120, 136, 170, 141, 153, 121, 169, 135, 173, 134, 152, 148, 109, 168, 149, 122, 133, 167, 174, 154, 132, 107, 123, 166, 155, 147, 124, 131, 165, 164, 125, 130, 156, 157, 126, 163, 129, 128, 162, 158, 127, 161, 160, 159, 175, 176, 177, 151, 178, 179, 185, 142, 150, 182, 180, 146, 181, 187, 190, 186, 189, 183, 184, 188, 106, 193, 191, 192, 105, 194, 196, 195, 197, 145, 17, 24, 22, 104, 18, 21, 12, 23, 29, 19, 28, 20, 10, 9, 27, 30, 11, 25, 31, 8, 32, 26, 33, 7, 16, 13, 6, 14, 15, 5, 4, 101, 3, 198, 143, 144, 100, 2, 34, 99, 102, 1, 103, 41, 42, 43, 40, 44, 47, 48, 49, 50, 46, 51, 52, 45, 98, 38, 53, 39, 54, 57, 56, 55, 97, 58, 37, 199, 69, 68, 74, 70, 71, 67, 66, 72, 59, 65, 73, 60, 64, 92, 91, 63, 76, 62, 94, 61, 81, 35, 96, 80, 77, 83, 36, 85, 95, 82, 93, 84, 75, 78, 86, 79, 90, 0, 89, 88, 87]\n#  adam optimizer gradient backpropagation \n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\nimport cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom cuml.ensemble import RandomForestClassifier\nimport scipy.io\nimport math \nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef preprocess_data(image, ground_truth, selected_bands, train_ratio=0.8):\n\n    rows, cols, bands = image.shape\n    # print(image.shape )\n    new_image=image[:,:,selected_bands]\n    # print(new_image.shape)\n    \n    reshaped_data = image.reshape((-1, bands))\n\n    reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(new_image)# Flatten spatial dimensions into 2D\n    reshaped_gt = ground_truth.flatten()  # Flatten ground truth\n\n    # Remove pixels where ground truth is 0 (no label)\n    valid_mask = reshaped_gt >0\n    reshaped_data = reshaped_data[valid_mask]\n    # reshaped_data = new_image [valid_mask]\n    \n    reshaped_gt = reshaped_gt[valid_mask]\n    # rows, cols, bands = image.shape\n    # new_image = image[:, :, selected_bands]\n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    \n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(reshaped_data.shape)# Flatten spatial dimensions into 2D\n    # reshaped_gt = ground_truth.flatten()# Flatten ground truth\n\n    # # Remove pixels where ground truth is 0 (no label)\n    # valid_mask = reshaped_gt >= 0\n    # reshaped_data = reshaped_data[valid_mask]\n    # reshaped_gt = reshaped_gt[valid_mask]\n\n    # Split into train and test\n    num_train = int(len(reshaped_gt) * train_ratio)\n    train_data = reshaped_data[:num_train]\n    train_gt = reshaped_gt[:num_train]\n    test_data = reshaped_data[num_train:]\n    test_gt = reshaped_gt[num_train:]\n    # print(f\"Shape of gt is {train_gt.shape}\")\n\n    return train_data, train_gt, test_data, test_gt\n\n# Load hyperspectral data\ntrain_data = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat')\nimage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\ngt= scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']  # Ground truth (training)\n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\n\n# Selected bands\n# selected_bands = [37, 176, 9, 139, 25, 88, 12, 19, 20, 46, 145, 153, 83, 23, 104, 39, 27, 68, 84, 152, 181, 60, 174, 119, 172, 70, 101, 131, 3, 63, 6, 190, 66, 110, 74, 165, 175, 62, 157, 5]\n\n# Store average frequency of bands for each iteration\navg_frequencies = []\nband_collection=[]\n\nfor i in range(1, len(selected_bands) + 1,10):\n   \n    # Load the training data\n    # train_data = scipy.io.loadmat('/kaggle/working/Indian_pines_corrected.mat')\n    # mage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\n    # train_gt = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']   # Ground truth (training)\n    \n    print(selected_bands[:i])\n    \n    # Preprocess data\n    train_data, train_gt, test_data, test_gt = preprocess_data(image, gt, sorted(selected_bands[:i]))\n    \n    # Convert to CuPy arrays\n    train_data_cp = cp.array(train_data).astype('float32')\n    train_gt_cp = cp.array(train_gt).astype('int32')\n    test_data_cp = cp.array(test_data).astype('float32')\n    test_gt_cp = cp.array(test_gt).astype('int32')\n\n    # Normalize\n    train_mean = cp.mean(train_data_cp, axis=0)\n    train_std = cp.std(train_data_cp, axis=0)\n    train_data_cp = (train_data_cp - train_mean) / train_std\n    test_data_cp = (test_data_cp - train_mean) / train_std\n\n    # Train Random Forest model\n    rf_model = RandomForestClassifier(n_estimators=400,n_streams=1, max_depth=25, random_state=42)\n    rf_model.fit(train_data_cp, train_gt_cp)\n\n    # Predict on test set\n    predictions_cp = rf_model.predict(test_data_cp)\n    predictions = cp.asnumpy(predictions_cp)\n    test_gt_np = cp.asnumpy(test_gt_cp)\n\n    # Compute accuracy and confusion matrix\n    conf_matrix = confusion_matrix(test_gt_np, predictions)\n    class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n\n    # Average band importance (store for plotting)\n    avg_frequencies.append(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n\n    # Display results\n    # print(\"\\nClassification Report:\")\n    print(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n    \n    # Create classification maps\n    # pred_map = np.zeros_like(train_gt.flatten())\n    height=int(145*0.8)\n    width=int(145*0.8)\n    # train_gt_reshaped = train_gt.reshape(height, width)\n    # test_gt_reshaped=test_gt.reshape(int(145*0.2), 145)\n    # print(f\"reshaped  = {train_gt_reshaped.shape}\")\n    \n    # pred_map[-len(predictions):] = predictions\n    # pred_map = predictions.reshape(int(145*0.2), 145)\n    # plt.figure(figsize=(12, 6))\n    # plt.subplot(1, 2, 1)\n    # plt.title(\"Actual Classification\")\n\n    # plt.imshow(test_gt_reshaped, cmap=\"jet\")\n    # plt.colorbar()\n    # plt.subplot(1, 2, 2)\n    # plt.title(\"Predicted Classification\")\n    # plt.imshow(pred_map, cmap=\"jet\")\n    # plt.colorbar()\n    # plt.show()\n\n# Plot average frequencies\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(selected_bands) + 1,10), avg_frequencies, marker='o')\nplt.xlabel(\"Iteration (Number of Bands Selected)\")\nplt.ylabel(\"Average accuracy achieved\")\nplt.title(\"Average Frequency of Bands per Iteration\")\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.412857Z","iopub.status.idle":"2025-02-10T08:29:25.413176Z","shell.execute_reply":"2025-02-10T08:29:25.413017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" selected_bands=[\n    41, 37, 40, 38, 42, 43, 47, 49, 48, 51, 50, 36, 52, 44, 46, 6, 7, 8,\n    45, 5, 15, 14, 16, 13, 63, 10, 17, 65, 11, 53, 9, 64, 21, 18, 33, 66,\n    67, 68, 20, 69, 22, 19, 24, 28, 12, 27, 25, 23, 34, 54, 70, 26, 62, 39,\n    55, 71, 30, 32, 35, 72, 4, 29, 31, 73, 2, 3, 61, 153, 154, 155, 156, 157,\n    158, 159, 144, 145, 146, 147, 148, 149, 167, 150, 151, 56, 57, 58, 59, 60, 136, 137,\n    138, 139, 140, 141, 142, 143, 152, 1, 184, 185, 186, 0, 188, 189, 190, 191, 176, 177,\n    178, 179, 180, 181, 164, 166, 165, 198, 163, 162, 161, 160, 182, 174, 173, 172, 171, 170,\n    169, 168, 183, 175, 125, 124, 123, 122, 121, 120, 119, 74, 117, 116, 115, 114, 113, 112,\n    111, 110, 118, 197, 196, 187, 132, 195, 194, 193, 192, 126, 134, 133, 199, 131, 130, 129,\n    128, 127, 135, 90, 89, 88, 87, 86, 85, 84, 109, 82, 81, 80, 79, 78, 77, 76,\n    75, 83, 108, 107, 106, 105, 104, 103, 102, 101, 91, 99, 98, 97, 96, 95, 94, 93,\n    92, 100\n]\n\n#  adam optimizer gradient backpropagation \n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\nimport cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom cuml.ensemble import RandomForestClassifier\nimport scipy.io\nimport math \nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef preprocess_data(image, ground_truth, selected_bands, train_ratio=0.8):\n\n    rows, cols, bands = image.shape\n    # print(image.shape )\n    new_image=image[:,:,selected_bands]\n    # print(new_image.shape)\n    \n    reshaped_data = image.reshape((-1, bands))\n\n    reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(new_image)# Flatten spatial dimensions into 2D\n    reshaped_gt = ground_truth.flatten()  # Flatten ground truth\n\n    # Remove pixels where ground truth is 0 (no label)\n    valid_mask = reshaped_gt >0\n    reshaped_data = reshaped_data[valid_mask]\n    # reshaped_data = new_image [valid_mask]\n    \n    reshaped_gt = reshaped_gt[valid_mask]\n    # rows, cols, bands = image.shape\n    # new_image = image[:, :, selected_bands]\n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    \n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(reshaped_data.shape)# Flatten spatial dimensions into 2D\n    # reshaped_gt = ground_truth.flatten()# Flatten ground truth\n\n    # # Remove pixels where ground truth is 0 (no label)\n    # valid_mask = reshaped_gt >= 0\n    # reshaped_data = reshaped_data[valid_mask]\n    # reshaped_gt = reshaped_gt[valid_mask]\n\n    # Split into train and test\n    num_train = int(len(reshaped_gt) * train_ratio)\n    train_data = reshaped_data[:num_train]\n    train_gt = reshaped_gt[:num_train]\n    test_data = reshaped_data[num_train:]\n    test_gt = reshaped_gt[num_train:]\n    # print(f\"Shape of gt is {train_gt.shape}\")\n\n    return train_data, train_gt, test_data, test_gt\n\n# Load hyperspectral data\ntrain_data = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat')\nimage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\ngt= scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']  # Ground truth (training)\n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\n\n# Selected bands\n# selected_bands = [37, 176, 9, 139, 25, 88, 12, 19, 20, 46, 145, 153, 83, 23, 104, 39, 27, 68, 84, 152, 181, 60, 174, 119, 172, 70, 101, 131, 3, 63, 6, 190, 66, 110, 74, 165, 175, 62, 157, 5]\n\n# Store average frequency of bands for each iteration\navg_frequencies = []\nband_collection=[]\nfor i in range(1, len(selected_bands) + 1):\n    band_collection.append(selected_bands[i if i <=1 else (i-1)*((-1)**i)])\nfor i in range(1, len(selected_bands) + 1,10):\n   \n    # Load the training data\n    # train_data = scipy.io.loadmat('/kaggle/working/Indian_pines_corrected.mat')\n    # mage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\n    # train_gt = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']   # Ground truth (training)\n    \n    print(band_collection[:i])\n    \n    # Preprocess data\n    train_data, train_gt, test_data, test_gt = preprocess_data(image, gt, sorted(band_collection[:i]))\n    \n    # Convert to CuPy arrays\n    train_data_cp = cp.array(train_data).astype('float32')\n    train_gt_cp = cp.array(train_gt).astype('int32')\n    test_data_cp = cp.array(test_data).astype('float32')\n    test_gt_cp = cp.array(test_gt).astype('int32')\n\n    # Normalize\n    train_mean = cp.mean(train_data_cp, axis=0)\n    train_std = cp.std(train_data_cp, axis=0)\n    train_data_cp = (train_data_cp - train_mean) / train_std\n    test_data_cp = (test_data_cp - train_mean) / train_std\n\n    # Train Random Forest model\n    rf_model = RandomForestClassifier(n_estimators=400,n_streams=1, max_depth=25, random_state=42)\n    rf_model.fit(train_data_cp, train_gt_cp)\n\n    # Predict on test set\n    predictions_cp = rf_model.predict(test_data_cp)\n    predictions = cp.asnumpy(predictions_cp)\n    test_gt_np = cp.asnumpy(test_gt_cp)\n\n    # Compute accuracy and confusion matrix\n    conf_matrix = confusion_matrix(test_gt_np, predictions)\n    class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n\n    # Average band importance (store for plotting)\n    avg_frequencies.append(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n\n    # Display results\n    # print(\"\\nClassification Report:\")\n    print(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n    \n    # Create classification maps\n    # pred_map = np.zeros_like(train_gt.flatten())\n    height=int(145*0.8)\n    width=int(145*0.8)\n    # train_gt_reshaped = train_gt.reshape(height, width)\n    # test_gt_reshaped=test_gt.reshape(int(145*0.2), 145)\n    # print(f\"reshaped  = {train_gt_reshaped.shape}\")\n    \n    # pred_map[-len(predictions):] = predictions\n    # pred_map = predictions.reshape(int(145*0.2), 145)\n    # plt.figure(figsize=(12, 6))\n    # plt.subplot(1, 2, 1)\n    # plt.title(\"Actual Classification\")\n\n    # plt.imshow(test_gt_reshaped, cmap=\"jet\")\n    # plt.colorbar()\n    # plt.subplot(1, 2, 2)\n    # plt.title(\"Predicted Classification\")\n    # plt.imshow(pred_map, cmap=\"jet\")\n    # plt.colorbar()\n    # plt.show()\n\n# Plot average frequencies\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(selected_bands) + 1,10), avg_frequencies, marker='o')\nplt.xlabel(\"Iteration (Number of Bands Selected)\")\nplt.ylabel(\"Average accuracy achieved\")\nplt.title(\"Average Frequency of Bands per Iteration\")\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.414072Z","iopub.status.idle":"2025-02-10T08:29:25.414410Z","shell.execute_reply":"2025-02-10T08:29:25.414240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nrf_model2= RandomForestClassifier(n_estimators=400, max_depth=25, random_state=42)\nrf_model2.fit(train_data_cp, train_gt_cp)\n# plt.figure(figsize=(10, 5))\nprint(rf_model.feature_importances_)\nplt.plot([i for i in range (0,200)],rf_model.feature_importances_)\nplt.title(\"Feature Importance from Random Forest\")\nplt.xlabel(\"Feature Index\")\nplt.ylabel(\"Importance Score\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.415270Z","iopub.status.idle":"2025-02-10T08:29:25.415573Z","shell.execute_reply":"2025-02-10T08:29:25.415459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tqdm import tqdm\n\ndef compute_latent_band_similarity(latent, original_bands):\n    \"\"\"\n    Compute similarity between latent features and original spectral bands.\n    Uses cosine similarity to compare the latent space with each spectral band.\n\n    latent: Tensor of shape (batch_size, hidden_dim)\n    original_bands: Tensor of shape (batch_size, seq_len, input_dim)\n\n    Returns: similarity scores for each band.\n    \"\"\"\n    batch_size, seq_len, _ = original_bands.shape\n    similarity_scores = np.zeros(seq_len)\n\n    latent_data = latent.cpu().detach().numpy()  # Shape: (batch_size, hidden_dim)\n\n    for band in tqdm(range(seq_len)):\n        band_data = original_bands[:, band, 0].cpu().numpy()  # Shape: (batch_size,)\n        \n        # Reshape correctly for cosine similarity computation\n        band_data = band_data.reshape(-1, 1)  # Shape: (batch_size, 1)\n        latent_data_band = latent_data[:, :1]  # Extract first latent feature (band projection)\n\n        similarity = cosine_similarity(latent_data_band, band_data)\n        \n        # Take the mean similarity score across the batch\n        similarity_scores[band] = similarity.mean()\n\n    return similarity_scores\n\n\n# Load trained model\nmodel = LSTM_Autoencoder(input_dim=1, hidden_dim=100, seq_len=X_test.shape[1])\n\n# Load the state dictionary\nmodel.load_state_dict(torch.load('/kaggle/working/model.pth'))\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.load_state_dict(torch.load('/kaggle/working/model.pth'))\nmodel.eval()\nwith torch.no_grad():\n    X_test = X_test.to(device)\n    \n    # Forward pass to get latent features\n    _, latent_features = model(X_test)  # Assuming model returns (decoded_output, latent_features)\n    \n    # Compute similarity scores for each band\n    similarity_scores = compute_latent_band_similarity(latent_features, X_test)\n\n# Plot similarity scores\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, len(similarity_scores) + 1), similarity_scores, marker='o')\nplt.title('Cosine Similarity between Latent Features and Original Bands')\nplt.xlabel('Band Number')\nplt.ylabel('Cosine Similarity')\nplt.grid(True)\nplt.show()\n\n# Rank bands based on similarity scores (higher is better)\nimportant_bands = np.argsort(np.abs(similarity_scores))[::-1]  # Sort in descending order of similarity\nprint(\"Important Bands (sorted by similarity):\", important_bands.tolist())\n\n# Visualize the most important band\ntop_band_idx = important_bands[0]\nprint(f\"Most important band: {top_band_idx + 1} with similarity: {similarity_scores[top_band_idx]:.4f}\")\n\n# Extract original and latent features for the most important band\nindex = 0  # Sample index\noriginal_band = X_test[:, top_band_idx, 0].cpu().numpy()\nlatent_band = latent_features[:, 0].cpu().detach().numpy()  # Using first latent feature\n\nplt.figure(figsize=(10, 5))\nplt.plot(original_band, label='Original Band', color='blue')\nplt.plot(latent_band, label='Latent Feature', color='red', linestyle='--')\nplt.title(f\"Band {top_band_idx + 1} - Original vs Latent Feature\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.416321Z","iopub.status.idle":"2025-02-10T08:29:25.416672Z","shell.execute_reply":"2025-02-10T08:29:25.416535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import mutual_info_regression\nfrom scipy.stats import pearsonr\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n# import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom scipy.io import loadmat\nimport random\n# Load the hyperspectral image dataset\ndef load_IndianPines_dataset_lstm(data_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat', gt_filepath='/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat'):\n    from scipy.io import loadmat\n    # Load hyperspectral data (expected shape: H x W x C)\n    data = loadmat(data_filepath)['indian_pines_corrected']\n    print(\"Original data shape:\", data.shape)\n    \n    # Normalize data to the range [-1, 1]\n    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n    data = (data * 2) - 1  # Normalize to range [-1, 1]\n    \n    # Load ground truth labels (expected shape: H x W)\n    gt = loadmat(gt_filepath)['indian_pines_gt']\n    print(\"Ground truth shape:\", gt.shape)\n    \n    H, W, C = data.shape\n    \n    # Flatten spatial dimensions so each pixel's spectrum is one sample\n    data_flat = data.reshape(-1, C)  # shape: (H*W, C)\n    X = data_flat[:, :, np.newaxis]  # shape: (N, C, 1)\n    \n    # Flatten ground truth to align with pixels\n    y = gt.reshape(-1)\n    \n    # Filter out unlabeled pixels (assuming label 0 is unlabeled)\n    valid_idx = y > 0\n    X = X[valid_idx]\n    y = y[valid_idx]\n    \n    print(\"Number of labeled pixels:\", X.shape[0])\n    \n    # Convert to PyTorch tensors\n    X_tensor = torch.tensor(X, dtype=torch.float32)\n    y_tensor = torch.tensor(y, dtype=torch.long)\n    \n    return X_tensor, y_tensor\n\n# Load the dataset\ndata_filepath = '/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat'\ngt_filepath = '/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat'\nX, y = load_IndianPines_dataset_lstm(data_filepath, gt_filepath)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Load the state dictionary\nclass LSTM_Autoencoder_with_latent(nn.Module):\n    def __init__(self, input_dim, hidden_dim, seq_len):\n        super(LSTM_Autoencoder_with_latent, self).__init__()\n        \n        # Encoder\n        self.lstm_encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        \n        # Decoder\n        self.lstm_decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, input_dim)  # Fully connected layer to output original dimension\n    \n    def forward(self, x):\n        # Encoder\n        _, (hn, _) = self.lstm_encoder(x)\n        \n        # Return the latent (encoded) feature for SSIM comparison\n        latent = hn[-1, :, :]  # Latent feature is the last hidden state (from the last layer of LSTM)\n        \n        # Repeat the latent state (hn) to match the sequence length\n        decoder_input = hn[-1, :, :] .unsqueeze(1).repeat(1, x.size(1), 1)  # Repeat for seq_len\n        \n        # Decoder\n        decoded, _ = self.lstm_decoder(decoder_input)\n        \n        # Output layer (fully connected)\n        decoded = self.fc(decoded)\n        \n        return decoded, latent\n# Load trained model\nmodel = LSTM_Autoencoder_with_latent(input_dim=1, hidden_dim=100, seq_len=X_test.shape[1])\nmodel.load_state_dict(torch.load('/kaggle/working/model.pth'))\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model.load_state_dict(torch.load('/kaggle/working/model.pth'))\nmodel=model.to(device)\nmodel.eval()\ndef compute_pearson_correlation(latent, original_bands):\n    \"\"\"\n    Compute the Pearson correlation between latent features and each band of the original hyperspectral data.\n\n    latent: Tensor of shape (batch_size, hidden_dim)\n    original_bands: Tensor of shape (batch_size, seq_len, input_dim)\n\n    Returns: Pearson correlation scores for each band.\n    \"\"\"\n    batch_size, seq_len, _ = original_bands.shape\n    correlation_scores = np.zeros(seq_len)\n    print(\"Computing Pearson Coeff\")\n    for band in tqdm(range(seq_len)):\n        # Extract the original band data (shape: batch_size)\n        band_data = original_bands[:, band, :].cpu().numpy().flatten()  # Flatten to 1D vector\n\n        # Compute Pearson correlation between the latent feature and the band\n        latent_data = latent.cpu().detach().numpy().mean(axis=1)  # Take the mean over hidden_dim to get a scalar value per sample\n\n        # Compute Pearson correlation\n        correlation, _ = pearsonr(latent_data, band_data)\n        correlation_scores[band] = correlation\n\n    return correlation_scores\n\ndef compute_mutual_information(latent, original_bands):\n    \"\"\"\n    Compute Mutual Information between latent features and each band of the original hyperspectral data.\n\n    latent: Tensor of shape (batch_size, hidden_dim)\n    original_bands: Tensor of shape (batch_size, seq_len, input_dim)\n\n    Returns: Mutual information scores for each band.\n    \"\"\"\n    batch_size, seq_len, _ = original_bands.shape\n    mi_scores = np.zeros(seq_len)\n    print(\"Computing MI ..........................\")\n    for band in tqdm(range(seq_len)):\n        # Extract the original band data (shape: batch_size)\n        band_data = original_bands[:, band, :].cpu().numpy()  # Use original band data (shape: batch_size)\n\n        # Get the latent features (shape: batch_size, hidden_dim)\n        latent_data = latent.cpu().detach().numpy()\n\n        # Mutual Information computation\n        # Mutual Information between band data (1D) and latent data (latent vector)\n        mi = mutual_info_regression(latent_data, band_data)  # Perform MI regression per band\n        \n        # Aggregate the mutual information scores by taking the mean of all features\n        mi_scores[band] = mi.mean()  # Taking the mean across the latent features\n\n    return mi_scores\n\n\nwith torch.no_grad():\n    # Move data to the device\n    X_test = X_test.to(device)\n    \n    # Get the decoded output and latent feature from the model\n    decoded_output, latent_features = model(X_test)  # decoded_output: [batch_size, seq_len, input_dim]\n\n    # Compute Pearson correlation scores for each band between latent features and original bands\n    pearson_scores = compute_pearson_correlation(latent_features, X_test)\n    \n    # Compute Mutual Information scores for each band\n    mi_scores = compute_mutual_information(latent_features, X_test)\n\n# Combine the two measures and rank bands by their combined score\ncombined_scores = np.abs(pearson_scores) + mi_scores  # You can also experiment with weighted sums if you prefer\n\n# Plot Pearson and Mutual Information Scores\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, len(pearson_scores) + 1), pearson_scores, label='Pearson Correlation', marker='o')\nplt.plot(range(1, len(mi_scores) + 1), mi_scores, label='Mutual Information', marker='x')\nplt.title('Pearson Correlation and Mutual Information for Each Band')\nplt.xlabel('Band Number')\nplt.ylabel('Score')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Rank bands based on combined scores (higher is better)\nimportant_bands_person = np.argsort(combined_scores)[::-1]  # Sort in descending order of combined score (higher is better)\n\n# Print Important Bands\nprint(\"Important Bands (sorted by pearson scores):\", important_bands_pearson)\n\n# Optionally, visualize the most important band\ntop_band_idx = important_bands[0]\nprint(f\"Most important band: {top_band_idx + 1} with combined score: {combined_scores[top_band_idx]}\")\n\n# Visualize the original and latent features for the most important band\nindex = 0  # Random sample index from X_test\noriginal_band = X_test[:, top_band_idx].cpu().numpy()\nlatent_band = latent_features[:, top_band_idx].cpu().detach().numpy()\n\nplt.figure(figsize=(10, 5))\nplt.plot(original_band, label='Original Band', color='blue')\nplt.plot(latent_band, label='Latent Feature', color='red', linestyle='--')\nplt.title(f\"Band {top_band_idx + 1} - Original vs Latent Feature\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.417589Z","iopub.status.idle":"2025-02-10T08:29:25.417920Z","shell.execute_reply":"2025-02-10T08:29:25.417802Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rank bands based on combined scores (higher is better)\n# Combine the two measures and rank bands by their combined score\ncombined_scores = pearson_scores + mi_scores \nimportant_bands_pearson = np.argsort(pearson_scores)[::-1]  # Sort in descending order of combined score (higher is better)\n\n# Print Important Bands\nprint(\"Important Bands (sorted by pearson scores):\", list(important_bands_pearson))\nprint(f\"Important Bands (sorted by mi scores):, {list(np.argsort(combined_scores)[::-1])}\")\n# Optionally, visualize the most important band\ntop_band_idx = important_bands[0]\nprint(f\"Most important band: {top_band_idx + 1} with combined score: {combined_scores[top_band_idx]}\")\n\n# Visualize the original and latent features for the most important band\nindex = 0  # Random sample index from X_test\noriginal_band = X_test[:, top_band_idx].cpu().numpy()\nlatent_band = latent_features[:, top_band_idx].cpu().detach().numpy()\n\nplt.figure(figsize=(10, 5))\nplt.plot(original_band, label='Original Band', color='blue')\nplt.plot(latent_band, label='Latent Feature', color='red', linestyle='--')\nplt.title(f\"Band {top_band_idx + 1} - Original vs Latent Feature\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.418804Z","iopub.status.idle":"2025-02-10T08:29:25.419146Z","shell.execute_reply":"2025-02-10T08:29:25.419008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # selected_bands=[113, 115, 114, 116, 117, 118, 112, 119, 120, 172, 121, 173, 111, 122, 138, 137, 135, 136, 168, 139, 171, 134, 169, 167, 132, 133, 123, 170, 166, 174, 140, 165, 124, 164, 131, 163, 130, 125, 162, 126, 175, 127, 128, 129, 110, 161, 158, 108, 160, 157, 159, 154, 153, 176, 141, 155, 156, 109, 177, 178, 179, 180, 107, 181, 183, 152, 182, 148, 149, 185, 147, 186, 184, 187, 189, 188, 190, 142, 191, 151, 193, 28, 146, 20, 27, 29, 150, 24, 19, 18, 21, 26, 17, 25, 192, 30, 22, 12, 23, 194, 13, 16, 11, 106, 10, 31, 14, 32, 15, 9, 8, 33, 7, 6, 196, 105, 195, 5, 4, 101, 197, 100, 3, 145, 104, 34, 99, 2, 198, 98, 47, 143, 51, 49, 144, 41, 52, 45, 44, 48, 42, 46, 50, 43, 53, 1, 40, 54, 56, 55, 57, 97, 39, 38, 70, 68, 69, 58, 71, 72, 67, 66, 74, 102, 73, 59, 37, 65, 64, 91, 63, 60, 92, 62, 94, 76, 61, 103, 81, 96, 95, 80, 35, 83, 93, 82, 85, 77, 84, 75, 36, 78, 86, 199, 90, 89, 87, 88, 79, 0]\nselected_bands=[\n    36, 31, 90, 61, 168, 116, 181, 128, 82, 157, 194, 7, 63, 173, 114, 130, 174, 71,\n    171, 19, 78, 107, 187, 137, 40, 111, 104, 34, 66, 122, 158, 179, 102, 167, 29, 20,\n    45, 153, 73, 147, 180, 124, 131, 132, 3, 33, 68, 38, 24, 143, 4, 81, 54, 191,\n    178, 26, 195, 148, 0, 106, 32, 22, 8, 192, 175, 118, 161, 156, 115, 134, 112, 125,\n    58, 197, 56, 27, 86, 139, 183, 16, 103, 77, 80, 142, 53, 15, 75, 138, 105, 65,\n    152, 83, 28, 5, 184, 150, 87, 42, 48, 37, 117, 44, 30, 49, 10, 163, 93, 74,\n    25, 6, 196, 126, 188, 108, 89, 92, 149, 21, 145, 141, 96, 70, 113, 50, 43, 57,\n    165, 18, 193, 162, 60, 121, 95, 119, 185, 146, 199, 160, 190, 166, 94, 101, 67, 13,\n    120, 59, 186, 35, 127, 97, 23, 98, 100, 12, 151, 155, 11, 52, 176, 51, 144, 136,\n    47, 55, 129, 76, 177, 79, 9, 154, 14, 135, 72, 85, 169, 91, 99, 1, 140, 109,\n    2, 46, 17, 110, 64, 41, 198, 69, 84, 133, 88, 172, 170, 39, 164, 189, 62, 123,\n    182, 159\n]\n# 11, 151, 31, 10, 146, 32, 15, 90, 9, 150, 8, 33, 7, 192, 86, 194, 6, 93, 106, 84, 95, 82, 5, 79, 83, 85, 101, 96, 0, 80, 196, 94, 4, 81, 91, 195, 100, 105, 92, 97, 35, 99, 98, 34, 197, 3, 2, 145, 104, 1, 198, 102, 144, 143, 103, 199]\n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\nimport cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom cuml.ensemble import RandomForestClassifier\nimport scipy.io\nimport math \nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef preprocess_data(image, ground_truth, selected_bands, train_ratio=0.8):\n\n    rows, cols, bands = image.shape\n    # print(image.shape )\n    new_image=image[:,:,selected_bands]\n    # print(new_image.shape)\n    \n    reshaped_data = image.reshape((-1, bands))\n\n    reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(new_image)# Flatten spatial dimensions into 2D\n    reshaped_gt = ground_truth.flatten()  # Flatten ground truth\n\n    # Remove pixels where ground truth is 0 (no label)\n    valid_mask = reshaped_gt >=0\n    reshaped_data = reshaped_data[valid_mask]\n    # reshaped_data = new_image [valid_mask]\n    \n    reshaped_gt = reshaped_gt[valid_mask]\n    # rows, cols, bands = image.shape\n    # new_image = image[:, :, selected_bands]\n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    \n    # reshaped_data = new_image.reshape((-1, len(selected_bands)))\n    # print(reshaped_data.shape)# Flatten spatial dimensions into 2D\n    # reshaped_gt = ground_truth.flatten()# Flatten ground truth\n\n    # # Remove pixels where ground truth is 0 (no label)\n    # valid_mask = reshaped_gt >= 0\n    # reshaped_data = reshaped_data[valid_mask]\n    # reshaped_gt = reshaped_gt[valid_mask]\n\n    # Split into train and test\n    num_train = int(len(reshaped_gt) * train_ratio)\n    train_data = reshaped_data[:num_train]\n    train_gt = reshaped_gt[:num_train]\n    test_data = reshaped_data[num_train:]\n    test_gt = reshaped_gt[num_train:]\n    # print(f\"Shape of gt is {train_gt.shape}\")\n\n    return train_data, train_gt, test_data, test_gt\n\n# Load hyperspectral data\ntrain_data = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat')\nimage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\ngt= scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']  # Ground truth (training)\n# selected_bands=[44, 45, 49, 42, 47, 52, 50, 46, 36, 69, 38, 37, 51, 40, 39, 41, 55, 48, 53, 56, 70, 63, 54, 65, 182, 66, 105, 186, 114, 68, 132, 74, 67, 60, 64, 167, 73, 168, 159, 107]\n\n# Selected bands\n# selected_bands = [37, 176, 9, 139, 25, 88, 12, 19, 20, 46, 145, 153, 83, 23, 104, 39, 27, 68, 84, 152, 181, 60, 174, 119, 172, 70, 101, 131, 3, 63, 6, 190, 66, 110, 74, 165, 175, 62, 157, 5]\n\n# Store average frequency of bands for each iteration\navg_frequencies = []\nband_collection=[]\n\nfor i in range(1, len(selected_bands) + 1,30):\n   \n    # Load the training data\n    # train_data = scipy.io.loadmat('/kaggle/working/Indian_pines_corrected.mat')\n    # mage = train_data['indian_pines_corrected']  # Hyperspectral image (training)\n    # train_gt = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']   # Ground truth (training)\n    \n    print(sorted(selected_bands[:i]))\n    \n    # Preprocess data\n    train_data, train_gt, test_data, test_gt = preprocess_data(image, gt, sorted(selected_bands[:i]))\n    \n    # Convert to CuPy arrays\n    train_data_cp = cp.array(train_data).astype('float32')\n    train_gt_cp = cp.array(train_gt).astype('int32')\n    test_data_cp = cp.array(test_data).astype('float32')\n    test_gt_cp = cp.array(test_gt).astype('int32')\n\n    # Normalize\n    train_mean = cp.mean(train_data_cp, axis=0)\n    train_std = cp.std(train_data_cp, axis=0)\n    train_data_cp = (train_data_cp - train_mean) / train_std\n    test_data_cp = (test_data_cp - train_mean) / train_std\n\n    # Train Random Forest model\n    rf_model = RandomForestClassifier(n_estimators=300,n_streams=1, max_depth=15, random_state=42)\n    rf_model.fit(train_data_cp, train_gt_cp)\n\n    # Predict on test set\n    predictions_cp = rf_model.predict(test_data_cp)\n    predictions = cp.asnumpy(predictions_cp)\n    test_gt_np = cp.asnumpy(test_gt_cp)\n\n    # Compute accuracy and confusion matrix\n    conf_matrix = confusion_matrix(test_gt_np, predictions)\n    class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n\n    # Average band importance (store for plotting)\n    avg_frequencies.append(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n\n    # Display results\n    # print(\"\\nClassification Report:\")\n    print(classification_report(test_gt_np, predictions, output_dict=True)['accuracy'])\n    \n    # Create classification maps\n    pred_map = np.zeros_like(train_gt.flatten())\n    # height=int(145*0.8)\n    # width=int(145*0.8)\n    # train_gt_reshaped = train_gt.reshape(height, width)\n    test_gt_reshaped=test_gt.reshape(int(145*0.2), 145)\n    # print(f\"reshaped  = {train_gt_reshaped.shape}\")\n    \n    pred_map[-len(predictions):] = predictions\n    pred_map = predictions.reshape(int(145*0.2), 145)\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.title(\"Actual Classification\")\n\n    plt.imshow(test_gt_reshaped, cmap=\"jet\")\n    plt.colorbar()\n    plt.subplot(1, 2, 2)\n    plt.title(\"Predicted Classification\")\n    plt.imshow(pred_map, cmap=\"jet\")\n    plt.colorbar()\n    plt.show()\n\n# Plot average frequencies\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(selected_bands) + 1,30), avg_frequencies, marker='o')\nplt.xlabel(\"Iteration (Number of Bands Selected)\")\nplt.ylabel(\"Average accuracy achieved\")\nplt.title(\"Average Frequency of Bands per Iteration\")\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T11:59:57.677483Z","iopub.execute_input":"2025-02-10T11:59:57.677789Z","iopub.status.idle":"2025-02-10T12:00:33.044425Z","shell.execute_reply.started":"2025-02-10T11:59:57.677767Z","shell.execute_reply":"2025-02-10T12:00:33.043546Z"}},"outputs":[{"name":"stdout","text":"[36]\n0.6185493460166468\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 4 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[7, 19, 31, 34, 36, 40, 61, 63, 66, 71, 78, 82, 90, 104, 107, 111, 114, 116, 122, 128, 130, 137, 157, 158, 168, 171, 173, 174, 181, 187, 194]\n0.5843043995243757\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 4 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[0, 3, 4, 7, 19, 20, 24, 26, 29, 31, 32, 33, 34, 36, 38, 40, 45, 54, 61, 63, 66, 68, 71, 73, 78, 81, 82, 90, 102, 104, 106, 107, 111, 114, 116, 122, 124, 128, 130, 131, 132, 137, 143, 147, 148, 153, 157, 158, 167, 168, 171, 173, 174, 178, 179, 180, 181, 187, 191, 194, 195]\n0.5821640903686088\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 4 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[0, 3, 4, 7, 8, 15, 16, 19, 20, 22, 24, 26, 27, 29, 31, 32, 33, 34, 36, 38, 40, 45, 53, 54, 56, 58, 61, 63, 65, 66, 68, 71, 73, 75, 77, 78, 80, 81, 82, 86, 90, 102, 103, 104, 105, 106, 107, 111, 112, 114, 115, 116, 118, 122, 124, 125, 128, 130, 131, 132, 134, 137, 138, 139, 142, 143, 147, 148, 152, 153, 156, 157, 158, 161, 167, 168, 171, 173, 174, 175, 178, 179, 180, 181, 183, 187, 191, 192, 194, 195, 197]\n0.5759809750297266\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 4 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[0, 3, 4, 5, 6, 7, 8, 10, 15, 16, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 45, 48, 49, 53, 54, 56, 58, 61, 63, 65, 66, 68, 71, 73, 74, 75, 77, 78, 80, 81, 82, 83, 86, 87, 89, 90, 92, 93, 96, 102, 103, 104, 105, 106, 107, 108, 111, 112, 114, 115, 116, 117, 118, 122, 124, 125, 126, 128, 130, 131, 132, 134, 137, 138, 139, 141, 142, 143, 145, 147, 148, 149, 150, 152, 153, 156, 157, 158, 161, 163, 167, 168, 171, 173, 174, 175, 178, 179, 180, 181, 183, 184, 187, 188, 191, 192, 194, 195, 196, 197]\n0.5776456599286564\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 4 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[0, 3, 4, 5, 6, 7, 8, 10, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 53, 54, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 70, 71, 73, 74, 75, 77, 78, 80, 81, 82, 83, 86, 87, 89, 90, 92, 93, 94, 95, 96, 97, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 130, 131, 132, 134, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 150, 152, 153, 156, 157, 158, 160, 161, 162, 163, 165, 166, 167, 168, 171, 173, 174, 175, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 199]\n0.5797859690844233\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 4 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 165, 166, 167, 168, 169, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 199]\n0.5766944114149821\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 4 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.421071Z","iopub.status.idle":"2025-02-10T08:29:25.421367Z","shell.execute_reply":"2025-02-10T08:29:25.421258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Plot average frequencies\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(selected_bands) + 1,10), avg_frequencies, marker='o')\nplt.xlabel(\"Iteration (Number of Bands Selected)\")\nplt.ylabel(\"Average accuracy achieved\")\nplt.title(\"Average Frequency of Bands per Iteration\")\nplt.grid()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.422141Z","iopub.status.idle":"2025-02-10T08:29:25.422485Z","shell.execute_reply":"2025-02-10T08:29:25.422340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport xgboost as xgb\nimport scipy.io\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Function to preprocess data\ndef preprocess_data(image, ground_truth, selected_bands, train_ratio=0.8):\n    rows, cols, bands = image.shape\n    new_image = image[:, :, selected_bands]  # Select specific bands\n    reshaped_data = new_image.reshape((-1, len(selected_bands)))  # Flatten spatial dimensions into 2D\n    reshaped_gt = ground_truth.flatten()  # Flatten ground truth\n\n    # Remove pixels where ground truth is 0 (no label)\n    valid_mask = reshaped_gt >=0\n    reshaped_data = reshaped_data[valid_mask]\n    reshaped_gt = reshaped_gt[valid_mask]\n\n    # Split into train and test\n    num_train = int(len(reshaped_gt) * train_ratio)\n    train_data = reshaped_data[:num_train]\n    train_gt = reshaped_gt[:num_train]\n    test_data = reshaped_data[num_train:]\n    test_gt = reshaped_gt[num_train:]\n\n    return train_data, train_gt, test_data, test_gt\n\n# Load hyperspectral data\ndata = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_corrected.mat')\nimage = data['indian_pines_corrected']  # Hyperspectral image\ngt = scipy.io.loadmat('/kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/Indian_pines_gt.mat')['indian_pines_gt']  # Ground truth\n\n# List of selected bands\nselected_bands = [\n    36, 31, 90, 61, 168, 116, 181, 128, 82, 157, 194, 7, 63, 173, 114, 130, 174, 71,\n    171, 19, 78, 107, 187, 137, 40, 111, 104, 34, 66, 122, 158, 179, 102, 167, 29, 20,\n    45, 153, 73, 147, 180, 124, 131, 132, 3, 33, 68, 38, 24, 143, 4, 81, 54, 191,\n    178, 26, 195, 148, 0, 106, 32, 22, 8, 192, 175, 118, 161, 156, 115, 134, 112, 125,\n    58, 197, 56, 27, 86, 139, 183, 16, 103, 77, 80, 142, 53, 15, 75, 138, 105, 65,\n    152, 83, 28, 5, 184, 150, 87, 42, 48, 37, 117, 44, 30, 49, 10, 163, 93, 74,\n    25, 6, 196, 126, 188, 108, 89, 92, 149, 21, 145, 141, 96, 70, 113, 50, 43, 57,\n    165, 18, 193, 162, 60, 121, 95, 119, 185, 146, 199, 160, 190, 166, 94, 101, 67, 13,\n    120, 59, 186, 35, 127, 97, 23, 98, 100, 12, 151, 155, 11, 52, 176, 51, 144, 136,\n    47, 55, 129, 76, 177, 79, 9, 154, 14, 135, 72, 85, 169, 91, 99, 1, 140, 109,\n    2, 46, 17, 110, 64, 41, 198, 69, 84, 133, 88, 172, 170, 39, 164, 189, 62, 123,\n    182, 159\n]\n\n# Preprocess data\ntrain_data, train_gt, test_data, test_gt = preprocess_data(image, gt, selected_bands)\n\n# Normalize the data\ntrain_mean = np.mean(train_data, axis=0)\ntrain_std = np.std(train_data, axis=0)\ntrain_data = (train_data - train_mean) / train_std\ntest_data = (test_data - train_mean) / train_std\n\n# Train XGBoost model\nxgb_model = xgb.XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\nxgb_model.fit(train_data, train_gt)\n\n# Predict on test data\npredictions = xgb_model.predict(test_data)\n\n# Compute accuracy\naccuracy = accuracy_score(test_gt, predictions)\nprint(f\"XGBoost Accuracy: {accuracy:.4f}\")\n\n# Compute confusion matrix\nconf_matrix = confusion_matrix(test_gt, predictions)\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\n\n# Visualize confusion matrix\nplt.figure(figsize=(10, 6))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(test_gt), yticklabels=np.unique(test_gt))\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix of XGBoost Classifier\")\nplt.show()\n\n# Display classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_gt, predictions))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T12:04:11.104565Z","iopub.execute_input":"2025-02-10T12:04:11.104908Z","iopub.status.idle":"2025-02-10T12:04:11.244734Z","shell.execute_reply.started":"2025-02-10T12:04:11.104882Z","shell.execute_reply":"2025-02-10T12:04:11.243726Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-5a825fb044df>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Train XGBoost model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_label_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mlogloss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Predict on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m             ):\n\u001b[0;32m-> 1471\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1472\u001b[0m                     \u001b[0;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0;34mf\"Expected: {expected_classes}, got {classes}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16]"],"ename":"ValueError","evalue":"Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16]","output_type":"error"}],"execution_count":29},{"cell_type":"markdown","source":"# **1D SOA implementation**","metadata":{}},{"cell_type":"markdown","source":" ## Taylor based kernels <!--  -->","metadata":{}},{"cell_type":"code","source":"#  import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import convolve1d\n\n# Sample 1D image signal (pixel intensities)\nX = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n# Define a second-order Taylor-based filter\n# Instead of a simple linear filter, we include squared terms\ndef taylor_filter(x, w):\n    return w[0] + w[1]*x + w[2]*x**2\n\n# Filter coefficients (trainable parameters)\nw = [0.5, -1.2, 0.3]  # Example values\n\n# Apply the Taylor-based filter to each pixel\nfiltered_output = taylor_filter(X, w)\n\n# Plot results\nplt.plot(X, label=\"Original Signal\")\nplt.plot(filtered_output, label=\"Taylor Filtered Signal\", linestyle=\"dashed\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.423087Z","iopub.status.idle":"2025-02-10T08:29:25.423329Z","shell.execute_reply":"2025-02-10T08:29:25.423225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.ndimage import convolve\n\n# Sample 2D image (grayscale)\nimage = np.array([\n    [10, 20, 30],\n    [40, 50, 60],\n    [70, 80, 90]\n], dtype=np.float32)\n\n# Define a second-order Taylor-based filter\ndef taylor_filter_2d(x, w):\n    return w[0] + w[1]*x + w[2]*x**2\n\n# Apply Taylor transformation pixel-wise\nw = [0.1, -0.5, 0.2]  # Example weights\nfiltered_image = taylor_filter_2d(image, w)\nplt.imshow(image,cmap=\"gray\")\nplt.show()\n# Display result\nplt.imshow(filtered_image, cmap=\"gray\")\nplt.colorbar()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"PATH\"] = \"/opt/conda/bin:\" + os.environ[\"PATH\"]\n!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n!bash miniconda.sh -b -p /opt/conda \n!rm miniconda.sh\n!/opt/conda/bin/conda init bash\n\n!conda create -n srl-soa python=3.7 -y \n!eval \"$(/opt/conda/bin/conda shell.bash hook)\"\n!pip install tensorflow numpy argparse scipy scikit-learn skfeature-chappers munkres==1.1.4\n\n# !pip install -r /kaggle/working/SRL-SOA/requirements.txt\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T07:05:48.808924Z","iopub.execute_input":"2025-02-14T07:05:48.809126Z","iopub.status.idle":"2025-02-14T07:07:00.584853Z","shell.execute_reply.started":"2025-02-14T07:05:48.809107Z","shell.execute_reply":"2025-02-14T07:07:00.583859Z"}},"outputs":[{"name":"stdout","text":"--2025-02-14 07:05:48--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nResolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\nConnecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 154615621 (147M) [application/octet-stream]\nSaving to: miniconda.sh\n\nminiconda.sh        100%[===================>] 147.45M   241MB/s    in 0.6s    \n\n2025-02-14 07:05:49 (241 MB/s) - miniconda.sh saved [154615621/154615621]\n\nPREFIX=/opt/conda\nUnpacking payload ...\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /opt/conda\nno change     /opt/conda/condabin/conda\nno change     /opt/conda/bin/conda\nno change     /opt/conda/bin/conda-env\nno change     /opt/conda/bin/activate\nno change     /opt/conda/bin/deactivate\nno change     /opt/conda/etc/profile.d/conda.sh\nno change     /opt/conda/etc/fish/conf.d/conda.fish\nno change     /opt/conda/shell/condabin/Conda.psm1\nno change     /opt/conda/shell/condabin/conda-hook.ps1\nno change     /opt/conda/lib/python3.12/site-packages/xontrib/conda.xsh\nno change     /opt/conda/etc/profile.d/conda.csh\nmodified      /root/.bashrc\n\n==> For changes to take effect, close and re-open your current shell. <==\n\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/srl-soa\n\n  added / updated specs:\n    - python=3.7\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n    pip-22.3.1                 |   py37h06a4308_0         2.7 MB\n    python-3.7.16              |       h7a1cb2a_0        44.8 MB\n    setuptools-65.6.3          |   py37h06a4308_0         1.1 MB\n    wheel-0.38.4               |   py37h06a4308_0          63 KB\n    xz-5.6.4                   |       h5eee18b_1         567 KB\n    ------------------------------------------------------------\n                                           Total:        53.2 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.12.31-h06a4308_0 \n  certifi            pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0 \n  pip                pkgs/main/linux-64::pip-22.3.1-py37h06a4308_0 \n  python             pkgs/main/linux-64::python-3.7.16-h7a1cb2a_0 \n  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n  setuptools         pkgs/main/linux-64::setuptools-65.6.3-py37h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n  wheel              pkgs/main/linux-64::wheel-0.38.4-py37h06a4308_0 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n\n\n\nDownloading and Extracting Packages:\npython-3.7.16        | 44.8 MB   |                                       |   0% \nopenssl-1.1.1w       | 3.7 MB    |                                       |   0% \u001b[A\n\npip-22.3.1           | 2.7 MB    |                                       |   0% \u001b[A\u001b[A\n\n\nsetuptools-65.6.3    | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ncertifi-2022.12.7    | 150 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npython-3.7.16        | 44.8 MB   | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nopenssl-1.1.1w       | 3.7 MB    | #3                                    |   4% \u001b[A\n\npip-22.3.1           | 2.7 MB    | #7                                    |   5% \u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    | #############5                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nsetuptools-65.6.3    | 1.1 MB    | #####5                                |  15% \u001b[A\u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ncertifi-2022.12.7    | 150 KB    | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ncertifi-2022.12.7    | 150 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\npython-3.7.16        | 44.8 MB   | ##                                    |   6% \u001b[A\u001b[A\u001b[A\n\npip-22.3.1           | 2.7 MB    | ########################4             |  66% \u001b[A\u001b[A\nopenssl-1.1.1w       | 3.7 MB    | ####################2                 |  55% \u001b[A\n\n\n\n\n\nwheel-0.38.4         | 63 KB     | #########3                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nwheel-0.38.4         | 63 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ncertifi-2022.12.7    | 150 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npython-3.7.16        | 44.8 MB   | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\npip-22.3.1           | 2.7 MB    | ##################################### | 100% \u001b[A\u001b[A\nopenssl-1.1.1w       | 3.7 MB    | ##################################### | 100% \u001b[A\npython-3.7.16        | 44.8 MB   | ######3                               |  17% \u001b[A\n\n\n\n\n\nwheel-0.38.4         | 63 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npython-3.7.16        | 44.8 MB   | ##############2                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\npython-3.7.16        | 44.8 MB   | ############################7         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\npython-3.7.16        | 44.8 MB   | ##################################5   |  93% \u001b[A\n\n\nsetuptools-65.6.3    | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\npython-3.7.16        | 44.8 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n                                                                                \u001b[A\u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate srl-soa\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\nCollecting tensorflow\n  Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nCollecting numpy\n  Downloading numpy-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nCollecting argparse\n  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting scipy\n  Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nCollecting scikit-learn\n  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting skfeature-chappers\n  Downloading skfeature_chappers-1.1.0-py3-none-any.whl.metadata (926 bytes)\nCollecting munkres==1.1.4\n  Downloading munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\nCollecting absl-py>=1.0.0 (from tensorflow)\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting astunparse>=1.6.0 (from tensorflow)\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting flatbuffers>=24.3.25 (from tensorflow)\n  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\nCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting google-pasta>=0.1.1 (from tensorflow)\n  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\nCollecting libclang>=13.0.0 (from tensorflow)\n  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\nCollecting opt-einsum>=2.3.2 (from tensorflow)\n  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\nCollecting six>=1.12.0 (from tensorflow)\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\nCollecting wrapt>=1.11.0 (from tensorflow)\n  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nCollecting grpcio<2.0,>=1.24.3 (from tensorflow)\n  Downloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nCollecting tensorboard<2.19,>=2.18 (from tensorflow)\n  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting keras>=3.5.0 (from tensorflow)\n  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting numpy\n  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nCollecting h5py>=3.11.0 (from tensorflow)\n  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting joblib>=1.2.0 (from scikit-learn)\n  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn)\n  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\nCollecting pandas (from skfeature-chappers)\n  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\nCollecting namex (from keras>=3.5.0->tensorflow)\n  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\nCollecting optree (from keras>=3.5.0->tensorflow)\n  Downloading optree-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nCollecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting python-dateutil>=2.8.2 (from pandas->skfeature-chappers)\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting pytz>=2020.1 (from pandas->skfeature-chappers)\n  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\nCollecting tzdata>=2022.7 (from pandas->skfeature-chappers)\n  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow)\n  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\nDownloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\nDownloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\nDownloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m40.2/40.2 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading skfeature_chappers-1.1.0-py3-none-any.whl (66 kB)\nDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\nDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nDownloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\nDownloading gast-0.6.0-py3-none-any.whl (21 kB)\nDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\nDownloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\nDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\nDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\nDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\nDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\nDownloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\nDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\nDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\nDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\nDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\nDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\nDownloading optree-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (400 kB)\nDownloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nInstalling collected packages: pytz, namex, munkres, libclang, flatbuffers, argparse, wrapt, tzdata, threadpoolctl, termcolor, tensorboard-data-server, six, protobuf, optree, opt-einsum, numpy, MarkupSafe, markdown, joblib, grpcio, gast, absl-py, werkzeug, scipy, python-dateutil, ml-dtypes, h5py, google-pasta, astunparse, tensorboard, scikit-learn, pandas, keras, tensorflow, skfeature-chappers\nSuccessfully installed MarkupSafe-3.0.2 absl-py-2.1.0 argparse-1.4.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.12.1 joblib-1.4.2 keras-3.8.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 munkres-1.1.4 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 pandas-2.2.3 protobuf-5.29.3 python-dateutil-2.9.0.post0 pytz-2025.1 scikit-learn-1.6.1 scipy-1.15.1 six-1.17.0 skfeature-chappers-1.1.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 threadpoolctl-3.5.0 tzdata-2025.1 werkzeug-3.1.3 wrapt-1.17.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#  REMOVE OR DEACTIVATE THE ENV\n# import os\n\n# # Remove Conda paths from the environment variables\n# os.environ[\"PATH\"] = os.environ[\"PATH\"].replace('/opt/conda/bin:', '')\n# os.environ[\"LD_LIBRARY_PATH\"] = os.environ[\"LD_LIBRARY_PATH\"].replace('/opt/conda/lib:', '')\n# os.environ[\"CUDA_HOME\"] = ''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.427177Z","iopub.status.idle":"2025-02-10T08:29:25.427528Z","shell.execute_reply":"2025-02-10T08:29:25.427344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!export PATH=/usr/local/cuda-12.2/bin:$PATH\n!export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64:$LD_LIBRARY_PATH\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.428316Z","iopub.status.idle":"2025-02-10T08:29:25.428652Z","shell.execute_reply":"2025-02-10T08:29:25.428495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd SRL-SOA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T11:12:26.980946Z","iopub.execute_input":"2025-02-10T11:12:26.981285Z","iopub.status.idle":"2025-02-10T11:12:26.988738Z","shell.execute_reply.started":"2025-02-10T11:12:26.981250Z","shell.execute_reply":"2025-02-10T11:12:26.987963Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SRL-SOA\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install tabulate seaborn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T11:12:28.939300Z","iopub.execute_input":"2025-02-10T11:12:28.939612Z","iopub.status.idle":"2025-02-10T11:12:36.020410Z","shell.execute_reply.started":"2025-02-10T11:12:28.939588Z","shell.execute_reply":"2025-02-10T11:12:36.019588Z"}},"outputs":[{"name":"stdout","text":"Collecting tabulate\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nCollecting seaborn\n  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.12/site-packages (from seaborn) (2.0.2)\nRequirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.12/site-packages (from seaborn) (2.2.3)\nCollecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n  Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\nCollecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n  Downloading fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\nCollecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\nCollecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n  Downloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nCollecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\nDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\nDownloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\nDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nDownloading fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\nInstalling collected packages: tabulate, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\nSuccessfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1 seaborn-0.13.2 tabulate-0.9.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%cd ..\n!rm -r SRL-SOA\n!git clone https://github.com/vidhi-gajra-git/SRL-SOA.git\n%cd SRL-SOA\n!mkdir data \n!mkdir results \n!cp /kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/*.mat data/\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T08:25:48.255161Z","iopub.execute_input":"2025-02-19T08:25:48.255679Z","iopub.status.idle":"2025-02-19T08:25:49.561500Z","shell.execute_reply.started":"2025-02-19T08:25:48.255626Z","shell.execute_reply":"2025-02-19T08:25:49.559684Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'SRL-SOA'...\nremote: Enumerating objects: 598, done.\u001b[K\nremote: Counting objects: 100% (145/145), done.\u001b[K\nremote: Compressing objects: 100% (114/114), done.\u001b[K\nremote: Total 598 (delta 102), reused 31 (delta 31), pack-reused 453 (from 1)\u001b[K\nReceiving objects: 100% (598/598), 1.03 MiB | 22.83 MiB/s, done.\nResolving deltas: 100% (383/383), done.\n/kaggle/working/SRL-SOA\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T06:38:03.486239Z","iopub.execute_input":"2025-02-20T06:38:03.486763Z","iopub.status.idle":"2025-02-20T06:38:09.086209Z","shell.execute_reply.started":"2025-02-20T06:38:03.486720Z","shell.execute_reply":"2025-02-20T06:38:09.084499Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"2025-02-20 06:38:04.137981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1740033484.179082     216 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1740033484.190884     216 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nTraceback (most recent call last):\n  File \"/kaggle/working/SRL-SOA/main.py\", line 10, in <module>\n    import utils\n  File \"/kaggle/working/SRL-SOA/utils.py\", line 27\n    %matplotlib inline \n    ^\nSyntaxError: invalid syntax\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"[36  31  90  61 168 116 181 128  82 157 194   7  63 173 114 130 174  71\n 171  19  78 107 187 137  40 111 104  34  66 122 158 179 102 167  29  20\n  45 153  73 147 180 124 131 132   3  33  68  38  24 143   4  81  54 191\n 178  26 195 148   0 106  32  22   8 192 175 118 161 156 115 134 112 125\n  58 197  56  27  86 139 183  16 103  77  80 142  53  15  75 138 105  65\n 152  83  28   5 184 150  87  42  48  37 117  44  30  49  10 163  93  74\n  25   6 196 126 188 108  89  92 149  21 145 141  96  70 113  50  43  57\n 165  18 193 162  60 121  95 119 185 146 199 160 190 166  94 101  67  13\n 120  59 186  35 127  97  23  98 100  12 151 155  11  52 176  51 144 136\n  47  55 129  76 177  79   9 154  14 135  72  85 169  91  99   1 140 109\n   2  46  17 110  64  41 198  69  84 133  88 172 170  39 164 189  62 123\n 182 159]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflow==2.18.0\n!nvcc --version\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:29:25.432647Z","iopub.status.idle":"2025-02-10T08:29:25.432913Z","shell.execute_reply":"2025-02-10T08:29:25.432807Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Env Install ","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"PATH\"] = \"/opt/conda/bin:\" + os.environ[\"PATH\"]\n!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n!bash miniconda.sh -b -p /opt/conda \n!rm miniconda.sh\n!/opt/conda/bin/conda init bash\n\n!conda create -n srl-soa python=3.7 -y \n!eval \"$(/opt/conda/bin/conda shell.bash hook)\"\n!pip install tensorflow numpy argparse scipy scikit-learn skfeature-chappers munkres==1.1.4\n%cd SRL-SOA\n\n# !pip install -r /kaggle/working/SRL-SOA/requirements.txt\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:43:20.107553Z","iopub.execute_input":"2025-02-20T11:43:20.107927Z","iopub.status.idle":"2025-02-20T11:45:02.739729Z","shell.execute_reply.started":"2025-02-20T11:43:20.107899Z","shell.execute_reply":"2025-02-20T11:45:02.737688Z"}},"outputs":[{"name":"stdout","text":"--2025-02-20 11:43:20--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nResolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:bf9e, ...\nConnecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 154615621 (147M) [application/octet-stream]\nSaving to: miniconda.sh\n\nminiconda.sh        100%[===================>] 147.45M   293MB/s    in 0.5s    \n\n2025-02-20 11:43:20 (293 MB/s) - miniconda.sh saved [154615621/154615621]\n\nPREFIX=/opt/conda\nUnpacking payload ...\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /opt/conda\nno change     /opt/conda/condabin/conda\nno change     /opt/conda/bin/conda\nno change     /opt/conda/bin/conda-env\nno change     /opt/conda/bin/activate\nno change     /opt/conda/bin/deactivate\nno change     /opt/conda/etc/profile.d/conda.sh\nno change     /opt/conda/etc/fish/conf.d/conda.fish\nno change     /opt/conda/shell/condabin/Conda.psm1\nno change     /opt/conda/shell/condabin/conda-hook.ps1\nno change     /opt/conda/lib/python3.12/site-packages/xontrib/conda.xsh\nno change     /opt/conda/etc/profile.d/conda.csh\nmodified      /root/.bashrc\n\n==> For changes to take effect, close and re-open your current shell. <==\n\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/srl-soa\n\n  added / updated specs:\n    - python=3.7\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n    pip-22.3.1                 |   py37h06a4308_0         2.7 MB\n    python-3.7.16              |       h7a1cb2a_0        44.8 MB\n    setuptools-65.6.3          |   py37h06a4308_0         1.1 MB\n    wheel-0.38.4               |   py37h06a4308_0          63 KB\n    xz-5.6.4                   |       h5eee18b_1         567 KB\n    ------------------------------------------------------------\n                                           Total:        53.2 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.12.31-h06a4308_0 \n  certifi            pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0 \n  pip                pkgs/main/linux-64::pip-22.3.1-py37h06a4308_0 \n  python             pkgs/main/linux-64::python-3.7.16-h7a1cb2a_0 \n  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n  setuptools         pkgs/main/linux-64::setuptools-65.6.3-py37h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n  wheel              pkgs/main/linux-64::wheel-0.38.4-py37h06a4308_0 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n\n\n\nDownloading and Extracting Packages:\npython-3.7.16        | 44.8 MB   |                                       |   0% \nopenssl-1.1.1w       | 3.7 MB    |                                       |   0% \u001b[A\n\npip-22.3.1           | 2.7 MB    |                                       |   0% \u001b[A\u001b[A\n\n\nsetuptools-65.6.3    | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ncertifi-2022.12.7    | 150 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npython-3.7.16        | 44.8 MB   | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nopenssl-1.1.1w       | 3.7 MB    | #######4                              |  20% \u001b[A\n\npip-22.3.1           | 2.7 MB    | ##7                                   |   8% \u001b[A\u001b[A\n\n\nsetuptools-65.6.3    | 1.1 MB    | ##################7                   |  51% \u001b[A\u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    | ################7                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npython-3.7.16        | 44.8 MB   | #9                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nopenssl-1.1.1w       | 3.7 MB    | ###########################8          |  75% \u001b[A\n\npip-22.3.1           | 2.7 MB    | ############################7         |  78% \u001b[A\u001b[A\n\n\nsetuptools-65.6.3    | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\n\n\ncertifi-2022.12.7    | 150 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nwheel-0.38.4         | 63 KB     | #########3                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npython-3.7.16        | 44.8 MB   | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npython-3.7.16        | 44.8 MB   | ####8                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ncertifi-2022.12.7    | 150 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\npip-22.3.1           | 2.7 MB    | ##################################### | 100% \u001b[A\u001b[A\npython-3.7.16        | 44.8 MB   | ########9                             |  24% \u001b[A\n\n\n\n\n\nwheel-0.38.4         | 63 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npython-3.7.16        | 44.8 MB   | #################                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nxz-5.6.4             | 567 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\npython-3.7.16        | 44.8 MB   | ####################################2 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\nopenssl-1.1.1w       | 3.7 MB    | ##################################### | 100% \u001b[A\n\n\nsetuptools-65.6.3    | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n                                                                                \u001b[A\u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate srl-soa\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\nCollecting tensorflow\n  Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nCollecting numpy\n  Downloading numpy-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nCollecting argparse\n  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting scipy\n  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nCollecting scikit-learn\n  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting skfeature-chappers\n  Downloading skfeature_chappers-1.1.0-py3-none-any.whl.metadata (926 bytes)\nCollecting munkres==1.1.4\n  Downloading munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\nCollecting absl-py>=1.0.0 (from tensorflow)\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting astunparse>=1.6.0 (from tensorflow)\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting flatbuffers>=24.3.25 (from tensorflow)\n  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\nCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting google-pasta>=0.1.1 (from tensorflow)\n  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\nCollecting libclang>=13.0.0 (from tensorflow)\n  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\nCollecting opt-einsum>=2.3.2 (from tensorflow)\n  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\nCollecting six>=1.12.0 (from tensorflow)\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\nCollecting wrapt>=1.11.0 (from tensorflow)\n  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nCollecting grpcio<2.0,>=1.24.3 (from tensorflow)\n  Downloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nCollecting tensorboard<2.19,>=2.18 (from tensorflow)\n  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting keras>=3.5.0 (from tensorflow)\n  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting numpy\n  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nCollecting h5py>=3.11.0 (from tensorflow)\n  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting joblib>=1.2.0 (from scikit-learn)\n  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn)\n  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\nCollecting pandas (from skfeature-chappers)\n  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\nCollecting namex (from keras>=3.5.0->tensorflow)\n  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\nCollecting optree (from keras>=3.5.0->tensorflow)\n  Downloading optree-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nCollecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting python-dateutil>=2.8.2 (from pandas->skfeature-chappers)\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting pytz>=2020.1 (from pandas->skfeature-chappers)\n  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\nCollecting tzdata>=2022.7 (from pandas->skfeature-chappers)\n  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow)\n  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\nDownloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\nDownloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\nDownloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading skfeature_chappers-1.1.0-py3-none-any.whl (66 kB)\nDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\nDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nDownloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\nDownloading gast-0.6.0-py3-none-any.whl (21 kB)\nDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\nDownloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\nDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\nDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\nDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\nDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\nDownloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\nDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\nDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\nDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\nDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\nDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\nDownloading optree-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (400 kB)\nDownloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nInstalling collected packages: pytz, namex, munkres, libclang, flatbuffers, argparse, wrapt, tzdata, threadpoolctl, termcolor, tensorboard-data-server, six, protobuf, optree, opt-einsum, numpy, MarkupSafe, markdown, joblib, grpcio, gast, absl-py, werkzeug, scipy, python-dateutil, ml-dtypes, h5py, google-pasta, astunparse, tensorboard, scikit-learn, pandas, keras, tensorflow, skfeature-chappers\nSuccessfully installed MarkupSafe-3.0.2 absl-py-2.1.0 argparse-1.4.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 joblib-1.4.2 keras-3.8.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 munkres-1.1.4 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 pandas-2.2.3 protobuf-5.29.3 python-dateutil-2.9.0.post0 pytz-2025.1 scikit-learn-1.6.1 scipy-1.15.2 six-1.17.0 skfeature-chappers-1.1.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 threadpoolctl-3.5.0 tzdata-2025.1 werkzeug-3.1.3 wrapt-1.17.2\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -q tabulate seaborn ipykernel pandas matplotlib mlflow dagshub ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:45:02.742691Z","iopub.execute_input":"2025-02-20T11:45:02.743341Z","iopub.status.idle":"2025-02-20T11:45:52.918333Z","shell.execute_reply.started":"2025-02-20T11:45:02.743283Z","shell.execute_reply":"2025-02-20T11:45:52.916642Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m825.5/825.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m865.9/865.9 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m648.7/648.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pwd ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T06:33:38.446692Z","iopub.execute_input":"2025-02-20T06:33:38.447898Z","iopub.status.idle":"2025-02-20T06:33:38.577917Z","shell.execute_reply.started":"2025-02-20T06:33:38.447840Z","shell.execute_reply":"2025-02-20T06:33:38.576719Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SRL-SOA\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%cd ..\n!rm -r SRL-SOA\n!git clone https://github.com/vidhi-gajra-git/SRL-SOA.git\n%cd SRL-SOA\n!mkdir data \n!cp /kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/*.mat data/\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:45:52.920524Z","iopub.execute_input":"2025-02-20T11:45:52.921110Z","iopub.status.idle":"2025-02-20T11:45:54.263774Z","shell.execute_reply.started":"2025-02-20T11:45:52.921073Z","shell.execute_reply":"2025-02-20T11:45:54.262101Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'SRL-SOA'...\nremote: Enumerating objects: 839, done.\u001b[K\nremote: Counting objects: 100% (82/82), done.\u001b[K\nremote: Compressing objects: 100% (51/51), done.\u001b[K\nremote: Total 839 (delta 60), reused 31 (delta 31), pack-reused 757 (from 3)\u001b[K\nReceiving objects: 100% (839/839), 1.11 MiB | 8.90 MiB/s, done.\nResolving deltas: 100% (530/530), done.\n/kaggle/working/SRL-SOA\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T18:43:48.037209Z","iopub.execute_input":"2025-02-13T18:43:48.037536Z","iopub.status.idle":"2025-02-13T18:54:41.404226Z","shell.execute_reply.started":"2025-02-13T18:43:48.037508Z","shell.execute_reply":"2025-02-13T18:54:41.403095Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"2025-02-13 18:43:48.511748: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1739472228.535678     285 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1739472228.542683     285 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\nScene:  (145, 145, 200)\n\nClassification:\nTraining samples:  512\nTest samples:  9737\n\n\nNumber of bands:  200\n**********  METHOD : SVM **********\n\t\t\t\t\t *****  #RUNS : 6  *****\nW0000 00:00:1739472234.046325     285 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1DMultiScaleCombin\u001b[0m  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)               \u001b[32m134,600\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot (\u001b[94mDot\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 85.5271\nEpoch 1: val_loss improved from inf to 13.70896, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 83.7494 - val_loss: 13.7090\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.8624\nEpoch 2: val_loss improved from 13.70896 to 13.70729, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.8624 - val_loss: 13.7073\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.2293\nEpoch 3: val_loss improved from 13.70729 to 13.70571, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.2268 - val_loss: 13.7057\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1129\nEpoch 4: val_loss improved from 13.70571 to 13.70415, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 4.1177 - val_loss: 13.7041\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9391\nEpoch 5: val_loss improved from 13.70415 to 13.70243, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.9355 - val_loss: 13.7024\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2384\nEpoch 6: val_loss improved from 13.70243 to 13.70072, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.2406 - val_loss: 13.7007\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0915\nEpoch 7: val_loss improved from 13.70072 to 13.69891, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.0982 - val_loss: 13.6989\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2701\nEpoch 8: val_loss improved from 13.69891 to 13.69689, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.2736 - val_loss: 13.6969\nEpoch 9/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9545\nEpoch 9: val_loss improved from 13.69689 to 13.69485, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.9555 - val_loss: 13.6949\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7043\nEpoch 10: val_loss improved from 13.69485 to 13.69286, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.7057 - val_loss: 13.6929\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6009\nEpoch 11: val_loss improved from 13.69286 to 13.69099, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.5982 - val_loss: 13.6910\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6977\nEpoch 12: val_loss improved from 13.69099 to 13.68907, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.6937 - val_loss: 13.6891\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5936\nEpoch 13: val_loss improved from 13.68907 to 13.68711, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 2.5903 - val_loss: 13.6871\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2155\nEpoch 14: val_loss improved from 13.68711 to 13.68518, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 2.2107 - val_loss: 13.6852\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3087\nEpoch 15: val_loss improved from 13.68518 to 13.68299, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.3116 - val_loss: 13.6830\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8093\nEpoch 16: val_loss improved from 13.68299 to 13.68103, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.8114 - val_loss: 13.6810\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4948\nEpoch 17: val_loss improved from 13.68103 to 13.67898, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.4958 - val_loss: 13.6790\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5024\nEpoch 18: val_loss improved from 13.67898 to 13.67682, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.5033 - val_loss: 13.6768\nEpoch 19/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6016\nEpoch 19: val_loss improved from 13.67682 to 13.67405, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1.6021 - val_loss: 13.6740\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4993\nEpoch 20: val_loss improved from 13.67405 to 13.67162, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.4964 - val_loss: 13.6716\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4623\nEpoch 21: val_loss improved from 13.67162 to 13.66946, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.4611 - val_loss: 13.6695\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6296\nEpoch 22: val_loss improved from 13.66946 to 13.66701, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.6256 - val_loss: 13.6670\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6165\nEpoch 23: val_loss improved from 13.66701 to 13.66456, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.6234 - val_loss: 13.6646\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.3962\nEpoch 24: val_loss improved from 13.66456 to 13.66152, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 2.3995 - val_loss: 13.6615\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.7958\nEpoch 25: val_loss did not improve from 13.66152\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.9457 - val_loss: 13.6654\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.1114\nEpoch 26: val_loss did not improve from 13.66152\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 12.9740 - val_loss: 13.6654\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3515\nEpoch 27: val_loss did not improve from 13.66152\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.3522 - val_loss: 13.6627\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6572\nEpoch 28: val_loss improved from 13.66152 to 13.66079, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.6588 - val_loss: 13.6608\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4020\nEpoch 29: val_loss improved from 13.66079 to 13.65887, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 2.3995 - val_loss: 13.6589\nEpoch 30/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3961\nEpoch 30: val_loss improved from 13.65887 to 13.65673, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 2.3876 - val_loss: 13.6567\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8777\nEpoch 31: val_loss improved from 13.65673 to 13.65445, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1.8736 - val_loss: 13.6545\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3759\nEpoch 32: val_loss improved from 13.65445 to 13.65178, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.3731 - val_loss: 13.6518\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1502\nEpoch 33: val_loss improved from 13.65178 to 13.64922, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.1507 - val_loss: 13.6492\nEpoch 34/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1228\nEpoch 34: val_loss improved from 13.64922 to 13.64681, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.1225 - val_loss: 13.6468\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0668\nEpoch 35: val_loss improved from 13.64681 to 13.64408, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.0670 - val_loss: 13.6441\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1872\nEpoch 36: val_loss improved from 13.64408 to 13.64186, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.1867 - val_loss: 13.6419\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9077\nEpoch 37: val_loss improved from 13.64186 to 13.64183, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.9400 - val_loss: 13.6418\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5638\nEpoch 38: val_loss improved from 13.64183 to 13.64140, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 4.5379 - val_loss: 13.6414\nEpoch 39/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6681\nEpoch 39: val_loss improved from 13.64140 to 13.63906, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.6605 - val_loss: 13.6391\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1269\nEpoch 40: val_loss improved from 13.63906 to 13.63669, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1194 - val_loss: 13.6367\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1469\nEpoch 41: val_loss improved from 13.63669 to 13.63557, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1507 - val_loss: 13.6356\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4342\nEpoch 42: val_loss improved from 13.63557 to 13.63449, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.4352 - val_loss: 13.6345\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4416\nEpoch 43: val_loss improved from 13.63449 to 13.63264, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.4347 - val_loss: 13.6326\nEpoch 44/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9244\nEpoch 44: val_loss improved from 13.63264 to 13.63079, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1.9336 - val_loss: 13.6308\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6858\nEpoch 45: val_loss improved from 13.63079 to 13.62926, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 2.6781 - val_loss: 13.6293\nEpoch 46/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6370\nEpoch 46: val_loss improved from 13.62926 to 13.62726, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 1.6399 - val_loss: 13.6273\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8961\nEpoch 47: val_loss improved from 13.62726 to 13.62616, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.8983 - val_loss: 13.6262\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0784\nEpoch 48: val_loss improved from 13.62616 to 13.62398, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 2.0717 - val_loss: 13.6240\nEpoch 49/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3760\nEpoch 49: val_loss improved from 13.62398 to 13.62210, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1.3936 - val_loss: 13.6221\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0109\nEpoch 50: val_loss improved from 13.62210 to 13.62137, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.9939 - val_loss: 13.6214\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 25  62 198 190 118  14 164 121  70 105 117  93  55 126  36 140 188  89\n  16 197 179 100  12   6  71]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1DMultiScaleCombin\u001b[0m  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)               \u001b[32m134,600\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_1 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 132.9436\nEpoch 1: val_loss improved from inf to 82.14404, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 131.4734 - val_loss: 82.1440\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.6654\nEpoch 2: val_loss improved from 82.14404 to 82.14281, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 8.6338 - val_loss: 82.1428\nEpoch 3/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.0611\nEpoch 3: val_loss improved from 82.14281 to 82.14159, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 7.0551 - val_loss: 82.1416\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.3634\nEpoch 4: val_loss improved from 82.14159 to 82.14023, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.3557 - val_loss: 82.1402\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0495\nEpoch 5: val_loss improved from 82.14023 to 82.13892, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 4.0475 - val_loss: 82.1389\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5993\nEpoch 6: val_loss improved from 82.13892 to 82.13766, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.5981 - val_loss: 82.1377\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9078\nEpoch 7: val_loss improved from 82.13766 to 82.13625, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.9052 - val_loss: 82.1363\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2131\nEpoch 8: val_loss improved from 82.13625 to 82.13506, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.2206 - val_loss: 82.1351\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8218\nEpoch 9: val_loss improved from 82.13506 to 82.13373, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 4.7944 - val_loss: 82.1337\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1789\nEpoch 10: val_loss improved from 82.13373 to 82.13210, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.1710 - val_loss: 82.1321\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9141\nEpoch 11: val_loss improved from 82.13210 to 82.13068, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.9060 - val_loss: 82.1307\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8706\nEpoch 12: val_loss improved from 82.13068 to 82.12922, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.8655 - val_loss: 82.1292\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7331\nEpoch 13: val_loss improved from 82.12922 to 82.12778, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.7278 - val_loss: 82.1278\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9764\nEpoch 14: val_loss improved from 82.12778 to 82.12614, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.9770 - val_loss: 82.1261\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4255\nEpoch 15: val_loss improved from 82.12614 to 82.12447, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.4270 - val_loss: 82.1245\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0387\nEpoch 16: val_loss improved from 82.12447 to 82.12307, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.0280 - val_loss: 82.1231\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3258\nEpoch 17: val_loss improved from 82.12307 to 82.12151, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 2.3212 - val_loss: 82.1215\nEpoch 18/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9806\nEpoch 18: val_loss improved from 82.12151 to 82.12001, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 1.9814 - val_loss: 82.1200\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9807\nEpoch 19: val_loss improved from 82.12001 to 82.11842, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.9789 - val_loss: 82.1184\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1008\nEpoch 20: val_loss improved from 82.11842 to 82.11693, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1145 - val_loss: 82.1169\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8902\nEpoch 21: val_loss improved from 82.11693 to 82.11637, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.8917 - val_loss: 82.1164\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9630\nEpoch 22: val_loss improved from 82.11637 to 82.11471, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.9539 - val_loss: 82.1147\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1146\nEpoch 23: val_loss improved from 82.11471 to 82.11320, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1101 - val_loss: 82.1132\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8837\nEpoch 24: val_loss improved from 82.11320 to 82.11109, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.8803 - val_loss: 82.1111\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5558\nEpoch 25: val_loss improved from 82.11109 to 82.10931, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.5568 - val_loss: 82.1093\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7744\nEpoch 26: val_loss improved from 82.10931 to 82.10757, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.7742 - val_loss: 82.1076\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6999\nEpoch 27: val_loss improved from 82.10757 to 82.10577, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.7066 - val_loss: 82.1058\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7138\nEpoch 28: val_loss improved from 82.10577 to 82.10480, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 2.7249 - val_loss: 82.1048\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9512\nEpoch 29: val_loss improved from 82.10480 to 82.10326, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.9432 - val_loss: 82.1033\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1215\nEpoch 30: val_loss improved from 82.10326 to 82.10171, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1139 - val_loss: 82.1017\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.9300\nEpoch 31: val_loss did not improve from 82.10171\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.9583 - val_loss: 82.1078\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.7682\nEpoch 32: val_loss did not improve from 82.10171\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.7646 - val_loss: 82.1067\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.9607\nEpoch 33: val_loss did not improve from 82.10171\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 4.9427 - val_loss: 82.1051\nEpoch 34/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.9850\nEpoch 34: val_loss improved from 82.10171 to 82.10143, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 3.9522 - val_loss: 82.1014\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8942\nEpoch 35: val_loss improved from 82.10143 to 82.09886, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.8910 - val_loss: 82.0989\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8643\nEpoch 36: val_loss improved from 82.09886 to 82.09737, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.8613 - val_loss: 82.0974\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5130\nEpoch 37: val_loss improved from 82.09737 to 82.09494, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.5100 - val_loss: 82.0949\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3609\nEpoch 38: val_loss improved from 82.09494 to 82.09254, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.3571 - val_loss: 82.0925\nEpoch 39/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3567\nEpoch 39: val_loss improved from 82.09254 to 82.09129, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.3447 - val_loss: 82.0913\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2263\nEpoch 40: val_loss improved from 82.09129 to 82.08923, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2244 - val_loss: 82.0892\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1918\nEpoch 41: val_loss improved from 82.08923 to 82.08672, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1908 - val_loss: 82.0867\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1358\nEpoch 42: val_loss improved from 82.08672 to 82.08503, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.1331 - val_loss: 82.0850\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4277\nEpoch 43: val_loss improved from 82.08503 to 82.08333, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.4221 - val_loss: 82.0833\nEpoch 44/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5103\nEpoch 44: val_loss improved from 82.08333 to 82.08109, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.5076 - val_loss: 82.0811\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9718\nEpoch 45: val_loss improved from 82.08109 to 82.07847, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9658 - val_loss: 82.0785\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6739\nEpoch 46: val_loss improved from 82.07847 to 82.07643, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.6718 - val_loss: 82.0764\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8205\nEpoch 47: val_loss improved from 82.07643 to 82.07581, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.8239 - val_loss: 82.0758\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2884\nEpoch 48: val_loss improved from 82.07581 to 82.07464, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2835 - val_loss: 82.0746\nEpoch 49/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4485\nEpoch 49: val_loss improved from 82.07464 to 82.07441, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.4474 - val_loss: 82.0744\nEpoch 50/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7873\nEpoch 50: val_loss did not improve from 82.07441\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.7734 - val_loss: 82.0775\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 10 189  62 126  87 119  80 174 147  39  23  55  21 166 132 129 192  45\n 159  16  53 186 185 175 102]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1DMultiScaleCombin\u001b[0m  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)               \u001b[32m134,600\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_2 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 144.3615\nEpoch 1: val_loss improved from inf to 10.16136, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 142.8054 - val_loss: 10.1614\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.5380\nEpoch 2: val_loss improved from 10.16136 to 10.16024, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.5033 - val_loss: 10.1602\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4139\nEpoch 3: val_loss improved from 10.16024 to 10.15907, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 5.3831 - val_loss: 10.1591\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9053\nEpoch 4: val_loss improved from 10.15907 to 10.15787, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.8970 - val_loss: 10.1579\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6507\nEpoch 5: val_loss improved from 10.15787 to 10.15654, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.6420 - val_loss: 10.1565\nEpoch 6/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3162\nEpoch 6: val_loss improved from 10.15654 to 10.15512, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.3105 - val_loss: 10.1551\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3831\nEpoch 7: val_loss improved from 10.15512 to 10.15359, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.3742 - val_loss: 10.1536\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0242\nEpoch 8: val_loss improved from 10.15359 to 10.15197, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.0206 - val_loss: 10.1520\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9862\nEpoch 9: val_loss improved from 10.15197 to 10.15030, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.9821 - val_loss: 10.1503\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8634\nEpoch 10: val_loss improved from 10.15030 to 10.14859, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.8616 - val_loss: 10.1486\nEpoch 11/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8197\nEpoch 11: val_loss improved from 10.14859 to 10.14676, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.8191 - val_loss: 10.1468\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8724\nEpoch 12: val_loss improved from 10.14676 to 10.14490, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.8698 - val_loss: 10.1449\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4221\nEpoch 13: val_loss improved from 10.14490 to 10.14299, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 2.4236 - val_loss: 10.1430\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6198\nEpoch 14: val_loss improved from 10.14299 to 10.14111, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.6182 - val_loss: 10.1411\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2913\nEpoch 15: val_loss improved from 10.14111 to 10.13928, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.2927 - val_loss: 10.1393\nEpoch 16/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3470\nEpoch 16: val_loss improved from 10.13928 to 10.13738, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.3484 - val_loss: 10.1374\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2388\nEpoch 17: val_loss improved from 10.13738 to 10.13561, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.2408 - val_loss: 10.1356\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1089\nEpoch 18: val_loss improved from 10.13561 to 10.13387, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1096 - val_loss: 10.1339\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2162\nEpoch 19: val_loss improved from 10.13387 to 10.13192, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2152 - val_loss: 10.1319\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0881\nEpoch 20: val_loss improved from 10.13192 to 10.12991, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.0834 - val_loss: 10.1299\nEpoch 21/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8809\nEpoch 21: val_loss improved from 10.12991 to 10.12773, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.8811 - val_loss: 10.1277\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2441\nEpoch 22: val_loss improved from 10.12773 to 10.12557, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2369 - val_loss: 10.1256\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8569\nEpoch 23: val_loss improved from 10.12557 to 10.12323, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.8543 - val_loss: 10.1232\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1411\nEpoch 24: val_loss improved from 10.12323 to 10.12119, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1441 - val_loss: 10.1212\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2116\nEpoch 25: val_loss improved from 10.12119 to 10.11888, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.2062 - val_loss: 10.1189\nEpoch 26/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8490\nEpoch 26: val_loss improved from 10.11888 to 10.11678, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.8388 - val_loss: 10.1168\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0500\nEpoch 27: val_loss improved from 10.11678 to 10.11566, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.1527 - val_loss: 10.1157\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 17.6170\nEpoch 28: val_loss did not improve from 10.11566\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 17.4041 - val_loss: 10.1333\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3185\nEpoch 29: val_loss did not improve from 10.11566\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.3250 - val_loss: 10.1305\nEpoch 30/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5202\nEpoch 30: val_loss did not improve from 10.11566\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 3.5239 - val_loss: 10.1277\nEpoch 31/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2105\nEpoch 31: val_loss did not improve from 10.11566\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.2100 - val_loss: 10.1248\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9334\nEpoch 32: val_loss did not improve from 10.11566\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9343 - val_loss: 10.1222\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9314\nEpoch 33: val_loss did not improve from 10.11566\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9321 - val_loss: 10.1195\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8825\nEpoch 34: val_loss did not improve from 10.11566\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.8837 - val_loss: 10.1165\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5384\nEpoch 35: val_loss improved from 10.11566 to 10.11383, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.5287 - val_loss: 10.1138\nEpoch 36/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7542\nEpoch 36: val_loss improved from 10.11383 to 10.11098, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.7584 - val_loss: 10.1110\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4828\nEpoch 37: val_loss improved from 10.11098 to 10.10915, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.4689 - val_loss: 10.1091\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4575\nEpoch 38: val_loss improved from 10.10915 to 10.10694, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.4598 - val_loss: 10.1069\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1881\nEpoch 39: val_loss improved from 10.10694 to 10.10487, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.1741 - val_loss: 10.1049\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9415\nEpoch 40: val_loss improved from 10.10487 to 10.10272, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9406 - val_loss: 10.1027\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1276\nEpoch 41: val_loss improved from 10.10272 to 10.10263, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.1256 - val_loss: 10.1026\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9302\nEpoch 42: val_loss improved from 10.10263 to 10.10039, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9313 - val_loss: 10.1004\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6244\nEpoch 43: val_loss improved from 10.10039 to 10.09817, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.6237 - val_loss: 10.0982\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2593\nEpoch 44: val_loss improved from 10.09817 to 10.09664, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.2537 - val_loss: 10.0966\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8633\nEpoch 45: val_loss improved from 10.09664 to 10.09524, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.8582 - val_loss: 10.0952\nEpoch 46/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0410\nEpoch 46: val_loss improved from 10.09524 to 10.09284, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 2.0466 - val_loss: 10.0928\nEpoch 47/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2744\nEpoch 47: val_loss improved from 10.09284 to 10.09001, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.2758 - val_loss: 10.0900\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1364\nEpoch 48: val_loss improved from 10.09001 to 10.08767, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1389 - val_loss: 10.0877\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9918\nEpoch 49: val_loss improved from 10.08767 to 10.08516, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9974 - val_loss: 10.0852\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1101\nEpoch 50: val_loss improved from 10.08516 to 10.08281, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1158 - val_loss: 10.0828\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [149 197 173  11 144 185  17 119  53 140  87 152 145  34 170  16 100  54\n  29 151 128 191  51 117 154]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'kernel': 'rbf'}\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1DMultiScaleCombin\u001b[0m  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)               \u001b[32m134,600\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_3 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 256.5965\nEpoch 1: val_loss improved from inf to 17.72358, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 252.3562 - val_loss: 17.7236\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.7828\nEpoch 2: val_loss improved from 17.72358 to 17.72285, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.7857 - val_loss: 17.7229\nEpoch 3/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1101\nEpoch 3: val_loss improved from 17.72285 to 17.72195, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 4.1086 - val_loss: 17.7220\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6262\nEpoch 4: val_loss improved from 17.72195 to 17.72099, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.6258 - val_loss: 17.7210\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3958\nEpoch 5: val_loss improved from 17.72099 to 17.71989, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.3942 - val_loss: 17.7199\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0940\nEpoch 6: val_loss improved from 17.71989 to 17.71873, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.0962 - val_loss: 17.7187\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8720\nEpoch 7: val_loss improved from 17.71873 to 17.71754, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.8735 - val_loss: 17.7175\nEpoch 8/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8315\nEpoch 8: val_loss improved from 17.71754 to 17.71621, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.8470\nEpoch 42: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.8376 - val_loss: 17.6915\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.5122\nEpoch 43: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.5044 - val_loss: 17.6892\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0074\nEpoch 44: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.0039 - val_loss: 17.6872\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8348\nEpoch 45: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.8270 - val_loss: 17.6849\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4893\nEpoch 46: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.4861 - val_loss: 17.6824\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4482\nEpoch 47: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.4461 - val_loss: 17.6800\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7575\nEpoch 48: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.7464 - val_loss: 17.6773\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.0481\nEpoch 49: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.0482 - val_loss: 17.6749\nEpoch 50/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0486\nEpoch 50: val_loss did not improve from 17.66155\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.0440 - val_loss: 17.6725\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [167   3 159 124  59  85  55  43 156 120  92 157  45 185 194  34   2 173\n 139  56 106  41  52  12  24]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1DMultiScaleCombin\u001b[0m  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)               \u001b[32m134,600\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_4 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 60.2486\nEpoch 1: val_loss improved from inf to 17.09979, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 59.6949 - val_loss: 17.0998\nEpoch 2/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3989\nEpoch 2: val_loss improved from 17.09979 to 17.09829, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 7.4040 - val_loss: 17.0983\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.2010\nEpoch 3: val_loss improved from 17.09829 to 17.09752, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.1964 - val_loss: 17.0975\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.4498\nEpoch 4: val_loss improved from 17.09752 to 17.09619, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.4430 - val_loss: 17.0962\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6974\nEpoch 5: val_loss improved from 17.09619 to 17.09450, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.6944 - val_loss: 17.0945\nEpoch 6/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3816\nEpoch 6: val_loss improved from 17.09450 to 17.09286, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 3.3844 - val_loss: 17.0929\nEpoch 7/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4978\nEpoch 7: val_loss improved from 17.09286 to 17.09117, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.5001 - val_loss: 17.0912\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1913\nEpoch 8: val_loss improved from 17.09117 to 17.08936, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.1919 - val_loss: 17.0894\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9584\nEpoch 9: val_loss improved from 17.08936 to 17.08745, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9609 - val_loss: 17.0874\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.0493\nEpoch 10: val_loss improved from 17.08745 to 17.08521, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.0532 - val_loss: 17.0852\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1650\nEpoch 11: val_loss improved from 17.08521 to 17.08332, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.1662 - val_loss: 17.0833\nEpoch 12/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0248\nEpoch 12: val_loss improved from 17.08332 to 17.08148, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 3.0232 - val_loss: 17.0815\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5809\nEpoch 13: val_loss improved from 17.08148 to 17.07941, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.5842 - val_loss: 17.0794\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5832\nEpoch 14: val_loss improved from 17.07941 to 17.07738, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.5843 - val_loss: 17.0774\nEpoch 15/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7569\nEpoch 15: val_loss improved from 17.07738 to 17.07558, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7590 - val_loss: 17.0756\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6641\nEpoch 16: val_loss improved from 17.07558 to 17.07294, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.6647 - val_loss: 17.0729\nEpoch 17/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6806\nEpoch 17: val_loss improved from 17.07294 to 17.07125, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.6829 - val_loss: 17.0713\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7660\nEpoch 18: val_loss improved from 17.07125 to 17.06940, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7687 - val_loss: 17.0694\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6649\nEpoch 19: val_loss improved from 17.06940 to 17.06741, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.6682 - val_loss: 17.0674\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6787\nEpoch 20: val_loss improved from 17.06741 to 17.06518, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.6785 - val_loss: 17.0652\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7140\nEpoch 21: val_loss improved from 17.06518 to 17.06379, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7224 - val_loss: 17.0638\nEpoch 22/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8965\nEpoch 22: val_loss improved from 17.06379 to 17.06133, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9067 - val_loss: 17.0613\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.8913\nEpoch 23: val_loss improved from 17.06133 to 17.05937, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 6.8335 - val_loss: 17.0594\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7050\nEpoch 24: val_loss improved from 17.05937 to 17.05754, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7038 - val_loss: 17.0575\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1177\nEpoch 25: val_loss improved from 17.05754 to 17.05521, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1195 - val_loss: 17.0552\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9901\nEpoch 26: val_loss improved from 17.05521 to 17.05271, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9904 - val_loss: 17.0527\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8977\nEpoch 27: val_loss improved from 17.05271 to 17.05031, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9018 - val_loss: 17.0503\nEpoch 28/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2624\nEpoch 28: val_loss improved from 17.05031 to 17.04799, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2617 - val_loss: 17.0480\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9570\nEpoch 29: val_loss improved from 17.04799 to 17.04535, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9600 - val_loss: 17.0453\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9835\nEpoch 30: val_loss improved from 17.04535 to 17.04297, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9877 - val_loss: 17.0430\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0159\nEpoch 31: val_loss improved from 17.04297 to 17.04096, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.0203 - val_loss: 17.0410\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0529\nEpoch 32: val_loss improved from 17.04096 to 17.03938, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.0589 - val_loss: 17.0394\nEpoch 33/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7001\nEpoch 33: val_loss improved from 17.03938 to 17.03931, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7297 - val_loss: 17.0393\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1845\nEpoch 34: val_loss improved from 17.03931 to 17.03679, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.1627 - val_loss: 17.0368\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1703\nEpoch 35: val_loss improved from 17.03679 to 17.03388, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1707 - val_loss: 17.0339\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8703\nEpoch 36: val_loss improved from 17.03388 to 17.03099, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.8730 - val_loss: 17.0310\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7225\nEpoch 37: val_loss improved from 17.03099 to 17.02850, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.7249 - val_loss: 17.0285\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7498\nEpoch 38: val_loss improved from 17.02850 to 17.02596, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.7558 - val_loss: 17.0260\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0805\nEpoch 39: val_loss improved from 17.02596 to 17.02466, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 2.0798 - val_loss: 17.0247\nEpoch 40/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2707\nEpoch 40: val_loss improved from 17.02466 to 17.02155, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 2.2634 - val_loss: 17.0215\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6142\nEpoch 41: val_loss improved from 17.02155 to 17.01873, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6139 - val_loss: 17.0187\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6536\nEpoch 42: val_loss improved from 17.01873 to 17.01709, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6626 - val_loss: 17.0171\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8167\nEpoch 43: val_loss improved from 17.01709 to 17.01505, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.8132 - val_loss: 17.0150\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6643\nEpoch 44: val_loss improved from 17.01505 to 17.01435, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6780 - val_loss: 17.0143\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9498\nEpoch 45: val_loss improved from 17.01435 to 17.01173, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9353 - val_loss: 17.0117\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1623\nEpoch 46: val_loss improved from 17.01173 to 17.00946, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.1643 - val_loss: 17.0095\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1160\nEpoch 47: val_loss improved from 17.00946 to 17.00710, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1101 - val_loss: 17.0071\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5591\nEpoch 48: val_loss improved from 17.00710 to 17.00447, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.5598 - val_loss: 17.0045\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7299\nEpoch 49: val_loss improved from 17.00447 to 17.00294, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.7311 - val_loss: 17.0029\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5542\nEpoch 50: val_loss improved from 17.00294 to 17.00261, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.5639 - val_loss: 17.0026\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [123 179 143  65   0  87 167 155 116  69 163 120  14  33  70  19 129  98\n 150  29  62  45 140  27 199]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1DMultiScaleCombin\u001b[0m  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)               \u001b[32m134,600\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_5 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m134,600\u001b[0m (525.78 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 100.2888\nEpoch 1: val_loss improved from inf to 23.59776, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 98.8089 - val_loss: 23.5978\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.6889\nEpoch 2: val_loss improved from 23.59776 to 23.59674, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 5.6874 - val_loss: 23.5967\nEpoch 3/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.7756\nEpoch 3: val_loss improved from 23.59674 to 23.59542, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.7834 - val_loss: 23.5954\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.3691\nEpoch 4: val_loss improved from 23.59542 to 23.59388, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.3668 - val_loss: 23.5939\nEpoch 5/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6393\nEpoch 5: val_loss improved from 23.59388 to 23.59231, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.6403 - val_loss: 23.5923\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5015\nEpoch 6: val_loss improved from 23.59231 to 23.59064, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.5037 - val_loss: 23.5906\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3080\nEpoch 7: val_loss improved from 23.59064 to 23.58888, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.3093 - val_loss: 23.5889\nEpoch 8/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9574\nEpoch 8: val_loss improved from 23.58888 to 23.58715, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9589 - val_loss: 23.5872\nEpoch 9/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8892\nEpoch 9: val_loss improved from 23.58715 to 23.58544, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.8906 - val_loss: 23.5854\nEpoch 10/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6908\nEpoch 10: val_loss improved from 23.58544 to 23.58362, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.6953 - val_loss: 23.5836\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3546\nEpoch 11: val_loss improved from 23.58362 to 23.58165, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.3571 - val_loss: 23.5816\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1639\nEpoch 12: val_loss improved from 23.58165 to 23.57972, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1692 - val_loss: 23.5797\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0473\nEpoch 13: val_loss improved from 23.57972 to 23.57770, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.0494 - val_loss: 23.5777\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8427\nEpoch 14: val_loss improved from 23.57770 to 23.57566, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.8474 - val_loss: 23.5757\nEpoch 15/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7408\nEpoch 15: val_loss improved from 23.57566 to 23.57356, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.7470 - val_loss: 23.5736\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6717\nEpoch 16: val_loss improved from 23.57356 to 23.57148, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6830 - val_loss: 23.5715\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8446\nEpoch 17: val_loss improved from 23.57148 to 23.56943, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.8446 - val_loss: 23.5694\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6131\nEpoch 18: val_loss improved from 23.56943 to 23.56742, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6165 - val_loss: 23.5674\nEpoch 19/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4808\nEpoch 19: val_loss improved from 23.56742 to 23.56530, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 1.4807 - val_loss: 23.5653\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4909\nEpoch 20: val_loss improved from 23.56530 to 23.56309, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.4949 - val_loss: 23.5631\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6326\nEpoch 21: val_loss improved from 23.56309 to 23.56086, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6332 - val_loss: 23.5609\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5815\nEpoch 22: val_loss improved from 23.56086 to 23.55896, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.5913 - val_loss: 23.5590\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9518\nEpoch 23: val_loss improved from 23.55896 to 23.55653, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9557 - val_loss: 23.5565\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6697\nEpoch 24: val_loss improved from 23.55653 to 23.55394, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6715 - val_loss: 23.5539\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5153\nEpoch 25: val_loss improved from 23.55394 to 23.55178, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.5120 - val_loss: 23.5518\nEpoch 26/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1868\nEpoch 26: val_loss improved from 23.55178 to 23.54935, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.2003 - val_loss: 23.5494\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9593\nEpoch 27: val_loss improved from 23.54935 to 23.54822, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9779 - val_loss: 23.5482\nEpoch 28/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.6362\nEpoch 28: val_loss did not improve from 23.54822\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.6028 - val_loss: 23.5485\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7368\nEpoch 29: val_loss improved from 23.54822 to 23.54692, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7416 - val_loss: 23.5469\nEpoch 30/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3418\nEpoch 30: val_loss improved from 23.54692 to 23.54464, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.3333 - val_loss: 23.5446\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5372\nEpoch 31: val_loss improved from 23.54464 to 23.54268, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.5396 - val_loss: 23.5427\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2269\nEpoch 32: val_loss improved from 23.54268 to 23.54028, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.2290 - val_loss: 23.5403\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9961\nEpoch 33: val_loss improved from 23.54028 to 23.53801, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.9972 - val_loss: 23.5380\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0625\nEpoch 34: val_loss improved from 23.53801 to 23.53565, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.0641 - val_loss: 23.5357\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9946\nEpoch 35: val_loss improved from 23.53565 to 23.53327, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.9951 - val_loss: 23.5333\nEpoch 36/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1699\nEpoch 36: val_loss improved from 23.53327 to 23.53104, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 1.1694 - val_loss: 23.5310\nEpoch 37/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1468\nEpoch 37: val_loss improved from 23.53104 to 23.52860, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 1.1475 - val_loss: 23.5286\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1883\nEpoch 38: val_loss improved from 23.52860 to 23.52583, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.1897 - val_loss: 23.5258\nEpoch 39/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.0684\nEpoch 39: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.2245 - val_loss: 23.5657\nEpoch 40/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.5118\nEpoch 40: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.5025 - val_loss: 23.5609\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.7319\nEpoch 41: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.7322 - val_loss: 23.5564\nEpoch 42/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8053\nEpoch 42: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.8064 - val_loss: 23.5524\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2474\nEpoch 43: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.2524 - val_loss: 23.5479\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.0472\nEpoch 44: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.0494 - val_loss: 23.5429\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3250\nEpoch 45: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3252 - val_loss: 23.5394\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6009\nEpoch 46: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.6042 - val_loss: 23.5347\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4962\nEpoch 47: val_loss did not improve from 23.52583\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.4968 - val_loss: 23.5302\nEpoch 48/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3782\nEpoch 48: val_loss improved from 23.52583 to 23.52508, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.3844 - val_loss: 23.5251\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1586\nEpoch 49: val_loss improved from 23.52508 to 23.52132, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1603 - val_loss: 23.5213\nEpoch 50/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1281\nEpoch 50: val_loss improved from 23.52132 to 23.51846, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1273 - val_loss: 23.5185\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [156  49 117 107  59  38  91 179  69 116 112 185  23 199 100  82  87 166\n  62  58 144 129  14 104 155]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 6 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      9     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   926    38    44     1     1     0  ...    97   236    24     0     0     0     0\n2.0      0    52   436    26     1     0     0  ...    20   192    52     0     0     0     0\n3.0      0     5    37   132     1     4     0  ...     9     2    31     0     0     0     0\n4.0      1     3     1     4   388    10     0  ...     8     5     1     0     5     3     0\n5.0      0     1     0     4    13   627     0  ...     0     0     0     3     6    39     0\n6.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0      8     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n8.0      0     2     0     0     2    12     0  ...     0     0     0     2     0     2     0\n9.0      0    95    12     5     6     2     0  ...   588   193    22     0     0     0     0\n10.0     0   333    98    16    15     7     0  ...   125  1671    58     0     0     3     0\n11.0     0    77    69    15     1     2     0  ...    40    59   304     0     0     0     0\n12.0     0     0     0     0     1     1     0  ...     0     0     0   185     0     9     0\n13.0    21     0     0     0    18     1     0  ...     0     0     0     7  1059    96     0\n14.0     2     5     0     0    43    51     0  ...     8     0     3    46    77   126     0\n15.0     0     4     0     0     0     0     0  ...     6     3     0     0     0     0    74\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      7     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   736    24    23     2     3     0  ...    97   448    21     0     0     0     2\n2.0      0    40   432    17     0     1     0  ...     0   267    37     0     0     0     0\n3.0      0    16    56   124     0    17     0  ...     2     3     2     0     0     0     1\n4.0     12     1     1     6   350    27     7  ...     0     4     0     0    36     6     1\n5.0      0     0     0     0    30   616     0  ...     0     3     0     1     1    38     0\n6.0      0     0     0     0     1     0     7  ...     0     0     0     0     0     0     0\n7.0      0     2     0     0     1     0     6  ...     0     9     0     0     0     0     0\n8.0      0     0     0     0     0    20     0  ...     0     0     0     0     0     0     0\n9.0      0    98     9     8     4     1     0  ...   612   184    10     0     0     0     2\n10.0     0   179    68    14    10    12     2  ...    65  1917    50     0     0     2     1\n11.0     0    69    96    31     0     1     0  ...    13   136   218     0     0     0     4\n12.0     0     0     0     1     0     8     0  ...     0     0     0   183     0     0     0\n13.0     0     0     0     0    46     7     0  ...     0     0     0     2  1111    41     0\n14.0     3     0     0     0    37    99     3  ...     1     0     0    23    84   112     5\n15.0     0     3     0     0     0     0     0  ...     2     4     3     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      3     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   933    31     5     2     6     0  ...    97   202    60     1     0     1     3\n2.0      0   124   400     9     1     3     0  ...    25   179    53     0     0     0     0\n3.0      0    60    28    58     1    33     0  ...     4    12    29     0     0     1     0\n4.0      5     1     0     1   395    16     0  ...     2     1     3     0    16    12     0\n5.0      0     0     0     2     2   633     0  ...     1     7     0     9     5    35     0\n6.0      0     0     0     0     3     0     5  ...     0     0     0     0     0     0     0\n7.0     27     0     0     0     3     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     6     0  ...     0     0     0     6     0     0     0\n9.0      0   150     8     1     8     2     2  ...   607   116    28     0     0     1     0\n10.0     0   320    68     4     8    14     1  ...   161  1690    48     0     0     6     5\n11.0     0    94    48    18     1    13     0  ...    47    63   269     0     0     3     0\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    31    11     0  ...     0     4     0     3  1091    64     0\n14.0     0     8     0     0    12    72     0  ...     0    12     0    37   103   122     0\n15.0     0     0     1     0     0     0     0  ...     0     5     4     0     0     2    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     35     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   938    35    28     2     2     0  ...    90   237    20     0     0     0     0\n2.0      0    79   465    10     0     1     0  ...     8   199    34     0     0     0     0\n3.0      1    21    50    81     0     4     0  ...     3    37    29     0     0     0     0\n4.0     15     3     0     3   360    38     0  ...     4     8     8     0     8    13     0\n5.0      0     1     0     3     5   603     0  ...     3    21     0     0     1    58     0\n6.0      2     0     0     0     0     0    12  ...     0     0     0     0     0     0     0\n7.0     36     1     0     2     0     0     7  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     2    11     0  ...     0     0     0     6     0     1     0\n9.0      0    59     7     4     0     1     0  ...   666   165    14     0     0     0     0\n10.0     0   158   100     6     1     6     0  ...   112  1900    42     0     0     4     0\n11.0     0    33    39     7     0     0     0  ...    34    88   358     0     0     1     0\n12.0     0     0     0     0     0     3     0  ...     0     1     0   181     0     7     0\n13.0     0     0     0     0    54     1     0  ...     0     0     0     4  1102    41     0\n14.0     0     0     0     0    20    38     0  ...     1     0    11    32    81   181     0\n15.0     0     0     0     0     0     0     0  ...     7     7     1     0     0     0    72\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      1     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   852    17    23     4     2     0  ...   115   313    24     0     0     0     0\n2.0      1    86   334    11     1     3     0  ...    29   262    63     0     0     0     0\n3.0      1    37    40    66     3    25     0  ...     3    17    35     0     0     0     0\n4.0      5     2     1     3   390    12     2  ...     8     4     2     0    14     7     0\n5.0      0     0     0     0    19   623     0  ...     1     0     0     1    17    31     0\n6.0      2     4     0     0     5     0     7  ...     0     0     0     0     0     0     0\n7.0     10     6     0     0    12     3     6  ...     0     7     0     0     0     0     0\n8.0      0     0     0     0     0    15     0  ...     0     0     0     0     0     0     0\n9.0      4    93     5     3     1     4     2  ...   573   248     0     0     0     0     0\n10.0     5   210    74     2     6    14     1  ...    70  1873    53     0     0     1     0\n11.0     0    40    51    10     0     5     0  ...    33   134   284     0     0     0     1\n12.0     0     0     0     0     0    12     0  ...     0     0     0   174     0     4     0\n13.0     0     0     0     0    32     4     0  ...     0     0     0     5  1134    28     0\n14.0     1     0     0     0    39   105     0  ...     2     4     1    30    99    70     0\n15.0     0     4     0     0     0     0     0  ...     5     1     6     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 6:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      8     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   893    45    37     2     4     1  ...    85   274    15     0     0     0     0\n2.0      0    91   384    48     0     0     0  ...    12   213    44     0     0     0     0\n3.0      1    37    20   137     1    15     0  ...     2     8     1     0     0     0     0\n4.0      5     3     0     4   386    18     5  ...     5     9     2     0    17     3     0\n5.0      0     4     0     8     7   645     0  ...     0    11     0     0     3    11     0\n6.0      1     0     0     0     3     0    17  ...     0     0     0     0     0     0     0\n7.0     31     0     0     0     3     0    11  ...     2     1     0     0     0     0     0\n8.0      0     0     0     0     0     5     0  ...     0     0     0     0     0     0     0\n9.0      0   151    16     4     2     3     2  ...   527   222     1     0     0     0     0\n10.0     0   375    88    19     2    15     3  ...   135  1643    42     0     0     1     1\n11.0     0   126    36    33     0     5     0  ...     8    81   280     0     0     0     0\n12.0     0     0     0     0     0     5     0  ...     0     0     0   167     0     0     0\n13.0     0     0     0     0    54     5     0  ...     0     2     0     2  1082    55     0\n14.0     0     2     1     2    16    92     0  ...     1    16     0    17   111    99     0\n15.0     0     5     2     0     0     0     0  ...     4     7     1     0     0     0    71\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results5.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.715621          0.604066           0.675315\n1    2          0.712642          0.600206           0.668609\n2    3          0.709561          0.608398           0.667989\n3    4          0.755880          0.675521           0.719871\n4    5          0.706275          0.576317           0.661448\n5    6          0.694259          0.663927           0.649530\n\nAverage Performance Over 6 Runs:\nOverall Accuracy: 0.7157\nAverage Accuracy: 0.6214\nKappa Coefficient: 0.6738\nFigure(800x500)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Version 2 with batch normalization layer ","metadata":{}},{"cell_type":"code","source":"%cd SRL-SOA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:43:08.085357Z","iopub.execute_input":"2025-02-20T11:43:08.085765Z","iopub.status.idle":"2025-02-20T11:43:08.094809Z","shell.execute_reply.started":"2025-02-20T11:43:08.085737Z","shell.execute_reply":"2025-02-20T11:43:08.092819Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SRL-SOA\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%cd ..\n!rm -r SRL-SOA\n!git clone https://github.com/vidhi-gajra-git/SRL-SOA.git\n%cd SRL-SOA\n!mkdir data \n!mkdir results \n!cp /kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/*.mat data/\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:42:21.596648Z","iopub.execute_input":"2025-02-20T11:42:21.597117Z","iopub.status.idle":"2025-02-20T11:42:22.886598Z","shell.execute_reply.started":"2025-02-20T11:42:21.597084Z","shell.execute_reply":"2025-02-20T11:42:22.885061Z"}},"outputs":[{"name":"stdout","text":"/kaggle\nCloning into 'SRL-SOA'...\nremote: Enumerating objects: 839, done.\u001b[K\nremote: Counting objects: 100% (82/82), done.\u001b[K\nremote: Compressing objects: 100% (51/51), done.\u001b[K\nremote: Total 839 (delta 60), reused 31 (delta 31), pack-reused 757 (from 3)\u001b[K\nReceiving objects: 100% (839/839), 1.11 MiB | 19.30 MiB/s, done.\nResolving deltas: 100% (530/530), done.\n/kaggle/SRL-SOA\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"\n## Original seed =42, q=0->q ","metadata":{}},{"cell_type":"code","source":"# %matplotlib inline\n!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n\n\n#Original seed =42 \n","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-02-20T07:35:51.806158Z","iopub.execute_input":"2025-02-20T07:35:51.806591Z","iopub.status.idle":"2025-02-20T07:51:58.125098Z","shell.execute_reply.started":"2025-02-20T07:35:51.806555Z","shell.execute_reply":"2025-02-20T07:51:58.119925Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"2025-02-20 07:35:52.377844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1740036952.417540    4707 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1740036952.429546    4707 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAccessing as vidhi-gajra-git\nInitialized MLflow to track repo \u001b[32m\"vidhi-gajra-git/SRL_SOA\"\u001b[0m\nRepository vidhi-gajra-git/SRL_SOA initialized!\n\nScene:  (145, 145, 200)\n\nClassification:\nTraining samples:  512\nTest samples:  9737\n\n\nNumber of bands:  200\n**********  METHOD : SVM **********\n\t\t\t\t\t *****  #RUNS : 6  *****\n2025-02-20 07:36:01.185061: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot (\u001b[94mDot\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9580\nEpoch 1: val_loss improved from inf to 65.72444, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n2025/02/20 07:36:06 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to synchronously create group (name parameter cannot be an empty string)\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 8.8997 - val_loss: 65.7244\nEpoch 2/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2611\nEpoch 2: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2688 - val_loss: 65.7244\nEpoch 3/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5357\nEpoch 3: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5328 - val_loss: 65.7244\nEpoch 4/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4438\nEpoch 4: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4343 - val_loss: 65.7244\nEpoch 5/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3310\nEpoch 5: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3245 - val_loss: 65.7244\nEpoch 6/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2570\nEpoch 6: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2526 - val_loss: 65.7244\nEpoch 7/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2628\nEpoch 7: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2619 - val_loss: 65.7244\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3315\nEpoch 8: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3290 - val_loss: 65.7244\nEpoch 9/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2812\nEpoch 9: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2815 - val_loss: 65.7244\nEpoch 10/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0704\nEpoch 10: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0771 - val_loss: 65.7244\nEpoch 11/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2079\nEpoch 11: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2506 - val_loss: 65.7244\nEpoch 12/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3185\nEpoch 12: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.4539 - val_loss: 65.7244\nEpoch 13/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1610\nEpoch 13: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.1441 - val_loss: 65.7244\nEpoch 14/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3995\nEpoch 14: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4002 - val_loss: 65.7244\nEpoch 15/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0913\nEpoch 15: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0980 - val_loss: 65.7244\nEpoch 16/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0198\nEpoch 16: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0309 - val_loss: 65.7244\nEpoch 17/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0244\nEpoch 17: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0310 - val_loss: 65.7244\nEpoch 18/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0567\nEpoch 18: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0596 - val_loss: 65.7244\nEpoch 19/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0576\nEpoch 19: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0628 - val_loss: 65.7244\nEpoch 20/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0648\nEpoch 20: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0694 - val_loss: 65.7244\nEpoch 21/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0739\nEpoch 21: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0772 - val_loss: 65.7244\nEpoch 22/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0730\nEpoch 22: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0768 - val_loss: 65.7244\nEpoch 23/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0648\nEpoch 23: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0681 - val_loss: 65.7244\nEpoch 24/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0541\nEpoch 24: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0584 - val_loss: 65.7244\nEpoch 25/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0460\nEpoch 25: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0495 - val_loss: 65.7244\nEpoch 26/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0317\nEpoch 26: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0368 - val_loss: 65.7244\nEpoch 27/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0127\nEpoch 27: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0178 - val_loss: 65.7244\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9956\nEpoch 28: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9980 - val_loss: 65.7244\nEpoch 29/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9899\nEpoch 29: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9907 - val_loss: 65.7244\nEpoch 30/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9934\nEpoch 30: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0005 - val_loss: 65.7244\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0142\nEpoch 31: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0168 - val_loss: 65.7244\nEpoch 32/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0157\nEpoch 32: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0199 - val_loss: 65.7244\nEpoch 33/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0533\nEpoch 33: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0856 - val_loss: 65.7244\nEpoch 34/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4709\nEpoch 34: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5094 - val_loss: 65.7244\nEpoch 35/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4232\nEpoch 35: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4612 - val_loss: 65.7244\nEpoch 36/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3729\nEpoch 36: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.3536 - val_loss: 65.7244\nEpoch 37/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1142\nEpoch 37: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1101 - val_loss: 65.7244\nEpoch 38/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0231\nEpoch 38: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0219 - val_loss: 65.7244\nEpoch 39/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0047\nEpoch 39: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0031 - val_loss: 65.7244\nEpoch 40/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9346\nEpoch 40: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9344 - val_loss: 65.7244\nEpoch 41/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8923\nEpoch 41: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8916 - val_loss: 65.7244\nEpoch 42/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8246\nEpoch 42: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8250 - val_loss: 65.7244\nEpoch 43/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7750\nEpoch 43: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7753 - val_loss: 65.7244\nEpoch 44/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7380\nEpoch 44: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7378 - val_loss: 65.7244\nEpoch 45/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6837\nEpoch 45: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6858 - val_loss: 65.7244\nEpoch 46/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7313\nEpoch 46: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7366 - val_loss: 65.7244\nEpoch 47/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0605\nEpoch 47: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1225 - val_loss: 65.7244\nEpoch 48/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5404\nEpoch 48: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5441 - val_loss: 65.7244\nEpoch 49/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1980\nEpoch 49: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1935 - val_loss: 65.7244\nEpoch 50/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9212\nEpoch 50: val_loss did not improve from 65.72444\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9226 - val_loss: 65.7244\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n2025/02/20 07:37:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmps1rcsk4o/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 07:38:10 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 07:38:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpted691p8/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 07:38:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run stylish-elk-437 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/33f4e65aa14d4364b0b8963ce99906f7\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 87  18 149 182  83 110 113  63  22  27 164  36 150  55 106  99   0  54\n   1  48  88  91  49  21 195]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.001, 'kernel': 'rbf'}\nThe model shall evaluate for 1 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      2     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   752    20    46     2     1     0  ...   118   401    27     0     0     0     0\n2.0      0    85   387    21     0     1     0  ...    28   213    44     0     0     0     0\n3.0      0    40    42   101     0     8     0  ...     5     9    17     0     0     0     0\n4.0      4     9     0     4   370     6     0  ...    15     5     3     0    23     3     0\n5.0      0     4     0     1    19   632     0  ...     0     1     0     0     8    28     0\n6.0      0     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n7.0      4     4     0     0     1     0     0  ...     0     1     0     0     0     0     0\n8.0      0     0     0     3     2    12     0  ...     0     0     0     2     0     1     0\n9.0      0    92     4     3     0     3     0  ...   474   335    12     0     0     0     0\n10.0     0   241    77     6     8     5     0  ...    89  1837    57     0     0     6     0\n11.0     0   106    61     9     0     1     0  ...    62   214   114     0     0     0     0\n12.0     0     2     0     0     0     4     0  ...     1     0     0   179     0    10     0\n13.0     1     0     0     0    53     1     0  ...     0     0     0     4  1067    76     0\n14.0     1     4     0     2    28    44     0  ...     8     0     5    26    70   173     0\n15.0     0     5     0     0     0     0     0  ...     8     0     0     0     0     0    74\n\n[16 rows x 16 columns]\n View run serious-mink-715 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/d8e3479bf61d49a8be142e8a8b03df73\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results0.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.678238          0.554131           0.628028\n\nAverage Performance Over 1 Runs:\nOverall Accuracy: 0.6782\nAverage Accuracy: 0.5541\nKappa Coefficient: 0.6280\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_1 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9708\nEpoch 1: val_loss improved from inf to 6.07061, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n2025/02/20 07:39:00 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to synchronously create group (name parameter cannot be an empty string)\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 4.9474 - val_loss: 6.0706\nEpoch 2/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0656\nEpoch 2: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0112 - val_loss: 6.0706\nEpoch 3/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0555\nEpoch 3: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0500 - val_loss: 6.0706\nEpoch 4/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3916\nEpoch 4: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.3608 - val_loss: 6.0706\nEpoch 5/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4254\nEpoch 5: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.4177 - val_loss: 6.0706\nEpoch 6/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3552\nEpoch 6: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.3226 - val_loss: 6.0706\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8276\nEpoch 7: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.8222 - val_loss: 6.0706\nEpoch 8/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7987\nEpoch 8: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7963 - val_loss: 6.0706\nEpoch 9/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6460\nEpoch 9: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6229 - val_loss: 6.0706\nEpoch 10/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6179\nEpoch 10: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.6056 - val_loss: 6.0706\nEpoch 11/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4992\nEpoch 11: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4873 - val_loss: 6.0706\nEpoch 12/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4422\nEpoch 12: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4209 - val_loss: 6.0706\nEpoch 13/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6796\nEpoch 13: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6677 - val_loss: 6.0706\nEpoch 14/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4922\nEpoch 14: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4845 - val_loss: 6.0706\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2307\nEpoch 15: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2089 - val_loss: 6.0706\nEpoch 16/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1677\nEpoch 16: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1664 - val_loss: 6.0706\nEpoch 17/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4736\nEpoch 17: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4502 - val_loss: 6.0706\nEpoch 18/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1080\nEpoch 18: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0984 - val_loss: 6.0706\nEpoch 19/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2329\nEpoch 19: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2164 - val_loss: 6.0706\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1292\nEpoch 20: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1254 - val_loss: 6.0706\nEpoch 21/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1650\nEpoch 21: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1490 - val_loss: 6.0706\nEpoch 22/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2856\nEpoch 22: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2694 - val_loss: 6.0706\nEpoch 23/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3673\nEpoch 23: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3439 - val_loss: 6.0706\nEpoch 24/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2128\nEpoch 24: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2201 - val_loss: 6.0706\nEpoch 25/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0672\nEpoch 25: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9121 - val_loss: 6.0706\nEpoch 26/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4490\nEpoch 26: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.4400 - val_loss: 6.0706\nEpoch 27/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6975\nEpoch 27: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5334 - val_loss: 6.0706\nEpoch 28/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3277\nEpoch 28: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3251 - val_loss: 6.0706\nEpoch 29/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4343\nEpoch 29: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4213 - val_loss: 6.0706\nEpoch 30/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1981\nEpoch 30: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1944 - val_loss: 6.0706\nEpoch 31/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2321\nEpoch 31: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2263 - val_loss: 6.0706\nEpoch 32/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1168\nEpoch 32: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1152 - val_loss: 6.0706\nEpoch 33/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1147\nEpoch 33: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1108 - val_loss: 6.0706\nEpoch 34/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0631\nEpoch 34: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0635 - val_loss: 6.0706\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0868\nEpoch 35: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0863 - val_loss: 6.0706\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0224\nEpoch 36: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0242 - val_loss: 6.0706\nEpoch 37/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1026\nEpoch 37: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0993 - val_loss: 6.0706\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2042\nEpoch 38: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2073 - val_loss: 6.0706\nEpoch 39/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5410\nEpoch 39: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5211 - val_loss: 6.0706\nEpoch 40/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0632\nEpoch 40: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0652 - val_loss: 6.0706\nEpoch 41/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0427\nEpoch 41: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0429 - val_loss: 6.0706\nEpoch 42/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8994\nEpoch 42: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9007 - val_loss: 6.0706\nEpoch 43/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9363\nEpoch 43: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9387 - val_loss: 6.0706\nEpoch 44/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8816\nEpoch 44: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8830 - val_loss: 6.0706\nEpoch 45/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0698\nEpoch 45: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0745 - val_loss: 6.0706\nEpoch 46/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1736\nEpoch 46: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1717 - val_loss: 6.0706\nEpoch 47/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3896\nEpoch 47: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3922 - val_loss: 6.0706\nEpoch 48/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9247\nEpoch 48: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9250 - val_loss: 6.0706\nEpoch 49/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9136\nEpoch 49: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9139 - val_loss: 6.0706\nEpoch 50/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8153\nEpoch 50: val_loss did not improve from 6.07061\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8189 - val_loss: 6.0706\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n2025/02/20 07:39:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpdxzb_6an/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 07:40:49 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 07:40:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpydstmgjl/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 07:40:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run redolent-hog-316 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/5edb5aedf259447c91f7528bfc671281\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [156  58  93 161  90  86  65 186 121 157  77 159  46 150 145  17  48   9\n  50 147 133  89 143 134 107]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.001, 'kernel': 'rbf'}\nThe model shall evaluate for 2 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      2     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   752    20    46     2     1     0  ...   118   401    27     0     0     0     0\n2.0      0    85   387    21     0     1     0  ...    28   213    44     0     0     0     0\n3.0      0    40    42   101     0     8     0  ...     5     9    17     0     0     0     0\n4.0      4     9     0     4   370     6     0  ...    15     5     3     0    23     3     0\n5.0      0     4     0     1    19   632     0  ...     0     1     0     0     8    28     0\n6.0      0     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n7.0      4     4     0     0     1     0     0  ...     0     1     0     0     0     0     0\n8.0      0     0     0     3     2    12     0  ...     0     0     0     2     0     1     0\n9.0      0    92     4     3     0     3     0  ...   474   335    12     0     0     0     0\n10.0     0   241    77     6     8     5     0  ...    89  1837    57     0     0     6     0\n11.0     0   106    61     9     0     1     0  ...    62   214   114     0     0     0     0\n12.0     0     2     0     0     0     4     0  ...     1     0     0   179     0    10     0\n13.0     1     0     0     0    53     1     0  ...     0     0     0     4  1067    76     0\n14.0     1     4     0     2    28    44     0  ...     8     0     5    26    70   173     0\n15.0     0     5     0     0     0     0     0  ...     8     0     0     0     0     0    74\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     11     0     0     1     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   633    13    38     2     2     0  ...   127   530     9     0     0     0     2\n2.0      0    24   442    15     0     1     0  ...     0   291    21     0     0     0     0\n3.0      0    41    48   100     2    11     0  ...     3    15     0     0     0     0     1\n4.0      1     2     0    11   261    32     3  ...     2     0     1     0   145     0     0\n5.0      0     0     0     3    43   587     0  ...     0     1     0     2     3    50     0\n6.0      0     0     0     4     1     0    12  ...     0     0     0     0     0     0     0\n7.0     11     4     0    29     6     0     7  ...     0     1     0     0     0     0     0\n8.0      0     0     0     0     1    18     0  ...     0     0     0     1     0     0     0\n9.0      0    32     2    17     6     1     1  ...   546   320     3     0     0     0     0\n10.0     0    79    41    29     4    18     0  ...    74  2040    31     0     0     2     1\n11.0     0    78    89    34     1     1     0  ...    27   215   121     0     0     0     2\n12.0     0     0     0     2     1     2     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     0   110     2     0  ...     0     0     0    10  1066    19     0\n14.0     2     0     0     7    44    72     0  ...     0     0     0    39    96   104     3\n15.0     0     1     0     0     0     0     0  ...     1     4     6     0     0     0    76\n\n[16 rows x 16 columns]\n View run popular-perch-326 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/a6e02f7b7ddd4c338a0c4c9632b988e3\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results1.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.678238          0.554131           0.628028\n1    2          0.676184          0.572931           0.623897\n\nAverage Performance Over 2 Runs:\nOverall Accuracy: 0.6772\nAverage Accuracy: 0.5635\nKappa Coefficient: 0.6260\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_2 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8923\nEpoch 1: val_loss improved from inf to 22.29636, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n2025/02/20 07:41:24 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to synchronously create group (name parameter cannot be an empty string)\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 10.6899 - val_loss: 22.2964\nEpoch 2/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0733\nEpoch 2: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0683 - val_loss: 22.2964\nEpoch 3/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6829\nEpoch 3: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6818 - val_loss: 22.2964\nEpoch 4/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3444\nEpoch 4: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3394 - val_loss: 22.2964\nEpoch 5/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1673\nEpoch 5: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1589 - val_loss: 22.2964\nEpoch 6/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0737\nEpoch 6: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0725 - val_loss: 22.2964\nEpoch 7/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0254\nEpoch 7: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0293 - val_loss: 22.2964\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0862\nEpoch 8: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0923 - val_loss: 22.2964\nEpoch 9/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3356\nEpoch 9: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3743 - val_loss: 22.2964\nEpoch 10/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8958\nEpoch 10: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.8545 - val_loss: 22.2964\nEpoch 11/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1193\nEpoch 11: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.0237 - val_loss: 22.2964\nEpoch 12/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0421\nEpoch 12: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.0350 - val_loss: 22.2964\nEpoch 13/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8384\nEpoch 13: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.8181 - val_loss: 22.2964\nEpoch 14/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3984\nEpoch 14: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.3792 - val_loss: 22.2964\nEpoch 15/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9264\nEpoch 15: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9096 - val_loss: 22.2964\nEpoch 16/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6201\nEpoch 16: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6115 - val_loss: 22.2964\nEpoch 17/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4169\nEpoch 17: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4071 - val_loss: 22.2964\nEpoch 18/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3256\nEpoch 18: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3190 - val_loss: 22.2964\nEpoch 19/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2353\nEpoch 19: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2279 - val_loss: 22.2964\nEpoch 20/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1967\nEpoch 20: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1953 - val_loss: 22.2964\nEpoch 21/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1788\nEpoch 21: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1710 - val_loss: 22.2964\nEpoch 22/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1694\nEpoch 22: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1630 - val_loss: 22.2964\nEpoch 23/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1702\nEpoch 23: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1644 - val_loss: 22.2964\nEpoch 24/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1808\nEpoch 24: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1724 - val_loss: 22.2964\nEpoch 25/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1853\nEpoch 25: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1844 - val_loss: 22.2964\nEpoch 26/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2004\nEpoch 26: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1943 - val_loss: 22.2964\nEpoch 27/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2094\nEpoch 27: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2074 - val_loss: 22.2964\nEpoch 28/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2208\nEpoch 28: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2153 - val_loss: 22.2964\nEpoch 29/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2348\nEpoch 29: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2305 - val_loss: 22.2964\nEpoch 30/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2510\nEpoch 30: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2379 - val_loss: 22.2964\nEpoch 31/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2611\nEpoch 31: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2588 - val_loss: 22.2964\nEpoch 32/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2553\nEpoch 32: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2530 - val_loss: 22.2964\nEpoch 33/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2789\nEpoch 33: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2743 - val_loss: 22.2964\nEpoch 34/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2822\nEpoch 34: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2775 - val_loss: 22.2964\nEpoch 35/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3031\nEpoch 35: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3009 - val_loss: 22.2964\nEpoch 36/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3146\nEpoch 36: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3135 - val_loss: 22.2964\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3435\nEpoch 37: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3402 - val_loss: 22.2964\nEpoch 38/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3599\nEpoch 38: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3588 - val_loss: 22.2964\nEpoch 39/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3941\nEpoch 39: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3920 - val_loss: 22.2964\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4103\nEpoch 40: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4081 - val_loss: 22.2964\nEpoch 41/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4425\nEpoch 41: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4335 - val_loss: 22.2964\nEpoch 42/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4271\nEpoch 42: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4250 - val_loss: 22.2964\nEpoch 43/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4219\nEpoch 43: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4169 - val_loss: 22.2964\nEpoch 44/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3878\nEpoch 44: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3759 - val_loss: 22.2964\nEpoch 45/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3385\nEpoch 45: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3376 - val_loss: 22.2964\nEpoch 46/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2739\nEpoch 46: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2694 - val_loss: 22.2964\nEpoch 47/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2285\nEpoch 47: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2237 - val_loss: 22.2964\nEpoch 48/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1607\nEpoch 48: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1595 - val_loss: 22.2964\nEpoch 49/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1334\nEpoch 49: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1301 - val_loss: 22.2964\nEpoch 50/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0789\nEpoch 50: val_loss did not improve from 22.29636\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0784 - val_loss: 22.2964\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n2025/02/20 07:42:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmphbeld62x/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 07:43:13 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 07:43:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpo2bbjr85/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 07:43:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run salty-ray-956 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/691f0dd6f82f476cb86b2b6ee296334c\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [139 134 177 167 155 136  97  51  49 169 194  62 164 138 109 141 103  96\n 117  26 129 135 105 107 197]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'kernel': 'rbf'}\nThe model shall evaluate for 3 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      2     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   752    20    46     2     1     0  ...   118   401    27     0     0     0     0\n2.0      0    85   387    21     0     1     0  ...    28   213    44     0     0     0     0\n3.0      0    40    42   101     0     8     0  ...     5     9    17     0     0     0     0\n4.0      4     9     0     4   370     6     0  ...    15     5     3     0    23     3     0\n5.0      0     4     0     1    19   632     0  ...     0     1     0     0     8    28     0\n6.0      0     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n7.0      4     4     0     0     1     0     0  ...     0     1     0     0     0     0     0\n8.0      0     0     0     3     2    12     0  ...     0     0     0     2     0     1     0\n9.0      0    92     4     3     0     3     0  ...   474   335    12     0     0     0     0\n10.0     0   241    77     6     8     5     0  ...    89  1837    57     0     0     6     0\n11.0     0   106    61     9     0     1     0  ...    62   214   114     0     0     0     0\n12.0     0     2     0     0     0     4     0  ...     1     0     0   179     0    10     0\n13.0     1     0     0     0    53     1     0  ...     0     0     0     4  1067    76     0\n14.0     1     4     0     2    28    44     0  ...     8     0     5    26    70   173     0\n15.0     0     5     0     0     0     0     0  ...     8     0     0     0     0     0    74\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     11     0     0     1     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   633    13    38     2     2     0  ...   127   530     9     0     0     0     2\n2.0      0    24   442    15     0     1     0  ...     0   291    21     0     0     0     0\n3.0      0    41    48   100     2    11     0  ...     3    15     0     0     0     0     1\n4.0      1     2     0    11   261    32     3  ...     2     0     1     0   145     0     0\n5.0      0     0     0     3    43   587     0  ...     0     1     0     2     3    50     0\n6.0      0     0     0     4     1     0    12  ...     0     0     0     0     0     0     0\n7.0     11     4     0    29     6     0     7  ...     0     1     0     0     0     0     0\n8.0      0     0     0     0     1    18     0  ...     0     0     0     1     0     0     0\n9.0      0    32     2    17     6     1     1  ...   546   320     3     0     0     0     0\n10.0     0    79    41    29     4    18     0  ...    74  2040    31     0     0     2     1\n11.0     0    78    89    34     1     1     0  ...    27   215   121     0     0     0     2\n12.0     0     0     0     2     1     2     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     0   110     2     0  ...     0     0     0    10  1066    19     0\n14.0     2     0     0     7    44    72     0  ...     0     0     0    39    96   104     3\n15.0     0     1     0     0     0     0     0  ...     1     4     6     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   813    31     8     4     4     0  ...   111   308    64     0     0     1     0\n2.0      0   109   425    18     0     2     0  ...     9   146    85     0     0     0     0\n3.0      1    39    27    64     1    17     0  ...     9    23    47     0     0     0     0\n4.0      0     0     0     1   390    11     0  ...     2     3     3     0    28    10     0\n5.0      0     1     0     0    10   620     0  ...     7     3     0     7     8    40     0\n6.0      1     0     0     0     0     0    18  ...     0     0     0     0     0     0     0\n7.0    104     6     0     0     6     0     1  ...     0     0     1     0     0     0     0\n8.0      0     0     0     0     0    11     0  ...     0     0     0     6     0     0     0\n9.0      0   120     7     2    10     2     1  ...   601   153    26     0     0     3     0\n10.0     0   359   109    11    17    10     1  ...   159  1600    58     0     0     4     1\n11.0     0    77    60    26     0     6     0  ...    24    55   307     0     0     0     1\n12.0     0     0     0     0     1     1     0  ...     0     1     0   172     0    18     0\n13.0     0     0     0     0    32    10     0  ...     0     1     0     1  1090    70     0\n14.0     0     0     0     0    18    90     0  ...     0     4    10    38    83   125     0\n15.0     0     4     1     0     2     0     0  ...     5     1     5     0     0     0    70\n\n[16 rows x 16 columns]\n View run rebellious-dove-762 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/4100e415f012449396ab7dc0fa7ec54b\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results2.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.678238          0.554131           0.628028\n1    2          0.676184          0.572931           0.623897\n2    3          0.683270          0.614782           0.638582\n\nAverage Performance Over 3 Runs:\nOverall Accuracy: 0.6792\nAverage Accuracy: 0.5806\nKappa Coefficient: 0.6302\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_3 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0374\nEpoch 1: val_loss improved from inf to 43.38191, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n2025/02/20 07:43:52 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to synchronously create group (name parameter cannot be an empty string)\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 10.8042 - val_loss: 43.3819\nEpoch 2/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1281\nEpoch 2: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.1256 - val_loss: 43.3819\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7747\nEpoch 3: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7740 - val_loss: 43.3819\nEpoch 4/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8230\nEpoch 4: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.8096 - val_loss: 43.3819\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5661\nEpoch 5: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5622 - val_loss: 43.3819\nEpoch 6/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4499\nEpoch 6: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4419 - val_loss: 43.3819\nEpoch 7/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4511\nEpoch 7: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4389 - val_loss: 43.3819\nEpoch 8/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4586\nEpoch 8: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4447 - val_loss: 43.3819\nEpoch 9/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4162\nEpoch 9: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4053 - val_loss: 43.3819\nEpoch 10/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2938\nEpoch 10: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2810 - val_loss: 43.3819\nEpoch 11/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2042\nEpoch 11: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1994 - val_loss: 43.3819\nEpoch 12/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1215\nEpoch 12: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1183 - val_loss: 43.3819\nEpoch 13/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2360\nEpoch 13: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2301 - val_loss: 43.3819\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0790\nEpoch 14: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0842 - val_loss: 43.3819\nEpoch 15/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5558\nEpoch 15: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5277 - val_loss: 43.3819\nEpoch 16/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9896\nEpoch 16: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9840 - val_loss: 43.3819\nEpoch 17/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8781\nEpoch 17: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8700 - val_loss: 43.3819\nEpoch 18/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8120\nEpoch 18: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8059 - val_loss: 43.3819\nEpoch 19/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7874\nEpoch 19: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7838 - val_loss: 43.3819\nEpoch 20/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7914\nEpoch 20: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7860 - val_loss: 43.3819\nEpoch 21/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8372\nEpoch 21: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8323 - val_loss: 43.3819\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7328\nEpoch 22: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7325 - val_loss: 43.3819\nEpoch 23/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9741\nEpoch 23: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9789 - val_loss: 43.3819\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8951\nEpoch 24: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8942 - val_loss: 43.3819\nEpoch 25/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9610\nEpoch 25: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9614 - val_loss: 43.3819\nEpoch 26/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5875\nEpoch 26: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5857 - val_loss: 43.3819\nEpoch 27/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1201\nEpoch 27: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1207 - val_loss: 43.3819\nEpoch 28/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3033\nEpoch 28: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3094 - val_loss: 43.3819\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2383\nEpoch 29: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2481 - val_loss: 43.3819\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5210\nEpoch 30: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5270 - val_loss: 43.3819\nEpoch 31/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8777\nEpoch 31: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.8499 - val_loss: 43.3819\nEpoch 32/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1335\nEpoch 32: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0662 - val_loss: 43.3819\nEpoch 33/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1758\nEpoch 33: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1786 - val_loss: 43.3819\nEpoch 34/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8991\nEpoch 34: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9125 - val_loss: 43.3819\nEpoch 35/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8989\nEpoch 35: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9034 - val_loss: 43.3819\nEpoch 36/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8864\nEpoch 36: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8879 - val_loss: 43.3819\nEpoch 37/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8480\nEpoch 37: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8479 - val_loss: 43.3819\nEpoch 38/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7962\nEpoch 38: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7958 - val_loss: 43.3819\nEpoch 39/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7438\nEpoch 39: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7435 - val_loss: 43.3819\nEpoch 40/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6968\nEpoch 40: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6967 - val_loss: 43.3819\nEpoch 41/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6596\nEpoch 41: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6598 - val_loss: 43.3819\nEpoch 42/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6328\nEpoch 42: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6346 - val_loss: 43.3819\nEpoch 43/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6201\nEpoch 43: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6203 - val_loss: 43.3819\nEpoch 44/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6131\nEpoch 44: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6138 - val_loss: 43.3819\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6089\nEpoch 45: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6093 - val_loss: 43.3819\nEpoch 46/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6016\nEpoch 46: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6017 - val_loss: 43.3819\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5924\nEpoch 47: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5922 - val_loss: 43.3819\nEpoch 48/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5845\nEpoch 48: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5844 - val_loss: 43.3819\nEpoch 49/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5772\nEpoch 49: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5768 - val_loss: 43.3819\nEpoch 50/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5700\nEpoch 50: val_loss did not improve from 43.38191\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5698 - val_loss: 43.3819\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n2025/02/20 07:44:50 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpms0egof6/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 07:45:58 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 07:46:06 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmphg0gf7_e/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 07:46:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run bouncy-mink-695 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/af83186f454d4276a51388660256e3cd\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 82 165  69 192 100 128  74  90  70  73  21 199 126  42  50 187 124 132\n   2  26  66  94  65 193 104]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 10, 'decision_function_shape': 'ovo', 'kernel': 'linear'}\nThe model shall evaluate for 4 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      2     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   752    20    46     2     1     0  ...   118   401    27     0     0     0     0\n2.0      0    85   387    21     0     1     0  ...    28   213    44     0     0     0     0\n3.0      0    40    42   101     0     8     0  ...     5     9    17     0     0     0     0\n4.0      4     9     0     4   370     6     0  ...    15     5     3     0    23     3     0\n5.0      0     4     0     1    19   632     0  ...     0     1     0     0     8    28     0\n6.0      0     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n7.0      4     4     0     0     1     0     0  ...     0     1     0     0     0     0     0\n8.0      0     0     0     3     2    12     0  ...     0     0     0     2     0     1     0\n9.0      0    92     4     3     0     3     0  ...   474   335    12     0     0     0     0\n10.0     0   241    77     6     8     5     0  ...    89  1837    57     0     0     6     0\n11.0     0   106    61     9     0     1     0  ...    62   214   114     0     0     0     0\n12.0     0     2     0     0     0     4     0  ...     1     0     0   179     0    10     0\n13.0     1     0     0     0    53     1     0  ...     0     0     0     4  1067    76     0\n14.0     1     4     0     2    28    44     0  ...     8     0     5    26    70   173     0\n15.0     0     5     0     0     0     0     0  ...     8     0     0     0     0     0    74\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     11     0     0     1     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   633    13    38     2     2     0  ...   127   530     9     0     0     0     2\n2.0      0    24   442    15     0     1     0  ...     0   291    21     0     0     0     0\n3.0      0    41    48   100     2    11     0  ...     3    15     0     0     0     0     1\n4.0      1     2     0    11   261    32     3  ...     2     0     1     0   145     0     0\n5.0      0     0     0     3    43   587     0  ...     0     1     0     2     3    50     0\n6.0      0     0     0     4     1     0    12  ...     0     0     0     0     0     0     0\n7.0     11     4     0    29     6     0     7  ...     0     1     0     0     0     0     0\n8.0      0     0     0     0     1    18     0  ...     0     0     0     1     0     0     0\n9.0      0    32     2    17     6     1     1  ...   546   320     3     0     0     0     0\n10.0     0    79    41    29     4    18     0  ...    74  2040    31     0     0     2     1\n11.0     0    78    89    34     1     1     0  ...    27   215   121     0     0     0     2\n12.0     0     0     0     2     1     2     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     0   110     2     0  ...     0     0     0    10  1066    19     0\n14.0     2     0     0     7    44    72     0  ...     0     0     0    39    96   104     3\n15.0     0     1     0     0     0     0     0  ...     1     4     6     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   813    31     8     4     4     0  ...   111   308    64     0     0     1     0\n2.0      0   109   425    18     0     2     0  ...     9   146    85     0     0     0     0\n3.0      1    39    27    64     1    17     0  ...     9    23    47     0     0     0     0\n4.0      0     0     0     1   390    11     0  ...     2     3     3     0    28    10     0\n5.0      0     1     0     0    10   620     0  ...     7     3     0     7     8    40     0\n6.0      1     0     0     0     0     0    18  ...     0     0     0     0     0     0     0\n7.0    104     6     0     0     6     0     1  ...     0     0     1     0     0     0     0\n8.0      0     0     0     0     0    11     0  ...     0     0     0     6     0     0     0\n9.0      0   120     7     2    10     2     1  ...   601   153    26     0     0     3     0\n10.0     0   359   109    11    17    10     1  ...   159  1600    58     0     0     4     1\n11.0     0    77    60    26     0     6     0  ...    24    55   307     0     0     0     1\n12.0     0     0     0     0     1     1     0  ...     0     1     0   172     0    18     0\n13.0     0     0     0     0    32    10     0  ...     0     1     0     1  1090    70     0\n14.0     0     0     0     0    18    90     0  ...     0     4    10    38    83   125     0\n15.0     0     4     1     0     2     0     0  ...     5     1     5     0     0     0    70\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     17     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   717    29     5     1     3     0  ...   138   438    20     0     0     0     0\n2.0      0    49   334    20     0     0     0  ...     8   249   136     0     0     0     0\n3.0      0    17    60    94     0     8     0  ...     6    22    19     0     0     0     0\n4.0     17     5     3     1   332    31     4  ...     5     3     4     0    34    25     0\n5.0      0     9     2     9     8   548     0  ...     0     6     4     0    11    98     0\n6.0      1     0     0     0     2     0    11  ...     3     0     0     0     0     0     0\n7.0     18     3     0     0     4     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0    72    21     6     0     1     1  ...   607   191    17     0     0     0     0\n10.0     0   184   114     9     3     9     0  ...   121  1768   117     0     0     6     0\n11.0     0    42   100     3     0     2     0  ...    69   112   231     0     0     0     1\n12.0     0     0     0     0     0    11     0  ...     0     0     0   171     0    10     0\n13.0     1     0     0     0    46     7     0  ...     0     0     0     9  1114    25     0\n14.0     1     0     1     0     9    72     0  ...     2     0     2    35    92   150     0\n15.0     0     2     0     0     0     0     0  ...     3     2     6     0     0     0    74\n\n[16 rows x 16 columns]\n View run likeable-bass-600 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/b28ff908faa14a558bf2999824975226\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results3.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.678238          0.554131           0.628028\n1    2          0.676184          0.572931           0.623897\n2    3          0.683270          0.614782           0.638582\n3    4          0.677313          0.595444           0.629114\n\nAverage Performance Over 4 Runs:\nOverall Accuracy: 0.6788\nAverage Accuracy: 0.5843\nKappa Coefficient: 0.6299\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_4 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6885 \nEpoch 1: val_loss improved from inf to 60.56181, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n2025/02/20 07:46:38 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to synchronously create group (name parameter cannot be an empty string)\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 9.3023 - val_loss: 60.5618\nEpoch 2/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9783\nEpoch 2: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9857 - val_loss: 60.5618\nEpoch 3/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9722\nEpoch 3: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9744 - val_loss: 60.5618\nEpoch 4/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7933\nEpoch 4: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7947 - val_loss: 60.5618\nEpoch 5/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5121\nEpoch 5: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5121 - val_loss: 60.5618\nEpoch 6/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3314\nEpoch 6: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3312 - val_loss: 60.5618\nEpoch 7/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2115\nEpoch 7: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2115 - val_loss: 60.5618\nEpoch 8/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1559\nEpoch 8: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1578 - val_loss: 60.5618\nEpoch 9/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1009\nEpoch 9: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1011 - val_loss: 60.5618\nEpoch 10/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0407\nEpoch 10: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0440 - val_loss: 60.5618\nEpoch 11/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9891\nEpoch 11: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9907 - val_loss: 60.5618\nEpoch 12/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9837\nEpoch 12: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9846 - val_loss: 60.5618\nEpoch 13/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0317\nEpoch 13: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0295 - val_loss: 60.5618\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3762\nEpoch 14: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3706 - val_loss: 60.5618\nEpoch 15/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5384\nEpoch 15: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5444 - val_loss: 60.5618\nEpoch 16/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2925\nEpoch 16: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.3402 - val_loss: 60.5618\nEpoch 17/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6528\nEpoch 17: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7009 - val_loss: 60.5618\nEpoch 18/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7656\nEpoch 18: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.8123 - val_loss: 60.5618\nEpoch 19/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3551\nEpoch 19: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.3618 - val_loss: 60.5618\nEpoch 20/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5861\nEpoch 20: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.6122 - val_loss: 60.5618\nEpoch 21/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6192\nEpoch 21: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6181 - val_loss: 60.5618\nEpoch 22/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5071\nEpoch 22: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4981 - val_loss: 60.5618\nEpoch 23/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4206\nEpoch 23: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4151 - val_loss: 60.5618\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3189\nEpoch 24: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3169 - val_loss: 60.5618\nEpoch 25/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2439\nEpoch 25: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2350 - val_loss: 60.5618\nEpoch 26/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1773\nEpoch 26: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1724 - val_loss: 60.5618\nEpoch 27/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1271\nEpoch 27: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1256 - val_loss: 60.5618\nEpoch 28/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0934\nEpoch 28: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0919 - val_loss: 60.5618\nEpoch 29/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0746\nEpoch 29: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0678 - val_loss: 60.5618\nEpoch 30/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0539\nEpoch 30: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0501 - val_loss: 60.5618\nEpoch 31/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0342\nEpoch 31: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0334 - val_loss: 60.5618\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0146\nEpoch 32: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0122 - val_loss: 60.5618\nEpoch 33/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9910\nEpoch 33: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9862 - val_loss: 60.5618\nEpoch 34/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9612\nEpoch 34: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9581 - val_loss: 60.5618\nEpoch 35/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9375\nEpoch 35: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9297 - val_loss: 60.5618\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9037\nEpoch 36: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9016 - val_loss: 60.5618\nEpoch 37/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8801\nEpoch 37: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8737 - val_loss: 60.5618\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8486\nEpoch 38: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8467 - val_loss: 60.5618\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8230\nEpoch 39: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8215 - val_loss: 60.5618\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7988\nEpoch 40: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7980 - val_loss: 60.5618\nEpoch 41/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7751\nEpoch 41: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7745 - val_loss: 60.5618\nEpoch 42/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7501\nEpoch 42: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7498 - val_loss: 60.5618\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7331\nEpoch 43: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7324 - val_loss: 60.5618\nEpoch 44/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7274\nEpoch 44: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7265 - val_loss: 60.5618\nEpoch 45/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6975\nEpoch 45: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6973 - val_loss: 60.5618\nEpoch 46/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6797\nEpoch 46: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6790 - val_loss: 60.5618\nEpoch 47/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8242\nEpoch 47: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8270 - val_loss: 60.5618\nEpoch 48/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6818\nEpoch 48: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.7444 - val_loss: 60.5618\nEpoch 49/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5817\nEpoch 49: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.5798 - val_loss: 60.5618\nEpoch 50/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6152\nEpoch 50: val_loss did not improve from 60.56181\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.5937 - val_loss: 60.5618\nWARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c71406c7600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c71406c7600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n2025/02/20 07:47:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp496cgti4/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 07:48:27 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 07:48:35 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpvpz06bbs/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 07:48:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run zealous-bass-239 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/a0844404357d43a4a9c4c1a0b74f0cc0\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [103  82 115 102 125 199 126  42 101 131 181  30  66  51 178  11 159  32\n 114 161  59   7 107  18  94]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 5 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      2     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   752    20    46     2     1     0  ...   118   401    27     0     0     0     0\n2.0      0    85   387    21     0     1     0  ...    28   213    44     0     0     0     0\n3.0      0    40    42   101     0     8     0  ...     5     9    17     0     0     0     0\n4.0      4     9     0     4   370     6     0  ...    15     5     3     0    23     3     0\n5.0      0     4     0     1    19   632     0  ...     0     1     0     0     8    28     0\n6.0      0     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n7.0      4     4     0     0     1     0     0  ...     0     1     0     0     0     0     0\n8.0      0     0     0     3     2    12     0  ...     0     0     0     2     0     1     0\n9.0      0    92     4     3     0     3     0  ...   474   335    12     0     0     0     0\n10.0     0   241    77     6     8     5     0  ...    89  1837    57     0     0     6     0\n11.0     0   106    61     9     0     1     0  ...    62   214   114     0     0     0     0\n12.0     0     2     0     0     0     4     0  ...     1     0     0   179     0    10     0\n13.0     1     0     0     0    53     1     0  ...     0     0     0     4  1067    76     0\n14.0     1     4     0     2    28    44     0  ...     8     0     5    26    70   173     0\n15.0     0     5     0     0     0     0     0  ...     8     0     0     0     0     0    74\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     11     0     0     1     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   633    13    38     2     2     0  ...   127   530     9     0     0     0     2\n2.0      0    24   442    15     0     1     0  ...     0   291    21     0     0     0     0\n3.0      0    41    48   100     2    11     0  ...     3    15     0     0     0     0     1\n4.0      1     2     0    11   261    32     3  ...     2     0     1     0   145     0     0\n5.0      0     0     0     3    43   587     0  ...     0     1     0     2     3    50     0\n6.0      0     0     0     4     1     0    12  ...     0     0     0     0     0     0     0\n7.0     11     4     0    29     6     0     7  ...     0     1     0     0     0     0     0\n8.0      0     0     0     0     1    18     0  ...     0     0     0     1     0     0     0\n9.0      0    32     2    17     6     1     1  ...   546   320     3     0     0     0     0\n10.0     0    79    41    29     4    18     0  ...    74  2040    31     0     0     2     1\n11.0     0    78    89    34     1     1     0  ...    27   215   121     0     0     0     2\n12.0     0     0     0     2     1     2     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     0   110     2     0  ...     0     0     0    10  1066    19     0\n14.0     2     0     0     7    44    72     0  ...     0     0     0    39    96   104     3\n15.0     0     1     0     0     0     0     0  ...     1     4     6     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   813    31     8     4     4     0  ...   111   308    64     0     0     1     0\n2.0      0   109   425    18     0     2     0  ...     9   146    85     0     0     0     0\n3.0      1    39    27    64     1    17     0  ...     9    23    47     0     0     0     0\n4.0      0     0     0     1   390    11     0  ...     2     3     3     0    28    10     0\n5.0      0     1     0     0    10   620     0  ...     7     3     0     7     8    40     0\n6.0      1     0     0     0     0     0    18  ...     0     0     0     0     0     0     0\n7.0    104     6     0     0     6     0     1  ...     0     0     1     0     0     0     0\n8.0      0     0     0     0     0    11     0  ...     0     0     0     6     0     0     0\n9.0      0   120     7     2    10     2     1  ...   601   153    26     0     0     3     0\n10.0     0   359   109    11    17    10     1  ...   159  1600    58     0     0     4     1\n11.0     0    77    60    26     0     6     0  ...    24    55   307     0     0     0     1\n12.0     0     0     0     0     1     1     0  ...     0     1     0   172     0    18     0\n13.0     0     0     0     0    32    10     0  ...     0     1     0     1  1090    70     0\n14.0     0     0     0     0    18    90     0  ...     0     4    10    38    83   125     0\n15.0     0     4     1     0     2     0     0  ...     5     1     5     0     0     0    70\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     17     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   717    29     5     1     3     0  ...   138   438    20     0     0     0     0\n2.0      0    49   334    20     0     0     0  ...     8   249   136     0     0     0     0\n3.0      0    17    60    94     0     8     0  ...     6    22    19     0     0     0     0\n4.0     17     5     3     1   332    31     4  ...     5     3     4     0    34    25     0\n5.0      0     9     2     9     8   548     0  ...     0     6     4     0    11    98     0\n6.0      1     0     0     0     2     0    11  ...     3     0     0     0     0     0     0\n7.0     18     3     0     0     4     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0    72    21     6     0     1     1  ...   607   191    17     0     0     0     0\n10.0     0   184   114     9     3     9     0  ...   121  1768   117     0     0     6     0\n11.0     0    42   100     3     0     2     0  ...    69   112   231     0     0     0     1\n12.0     0     0     0     0     0    11     0  ...     0     0     0   171     0    10     0\n13.0     1     0     0     0    46     7     0  ...     0     0     0     9  1114    25     0\n14.0     1     0     1     0     9    72     0  ...     2     0     2    35    92   150     0\n15.0     0     2     0     0     0     0     0  ...     3     2     6     0     0     0    74\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     0     0     0     4  ...     0     0     0     0     0     0     0\n1.0      0   930     9     2     3     3     0  ...   126   256    21     0     0     0     0\n2.0      0    62   388     6     0     1     0  ...    24   267    42     0     0     0     0\n3.0      0    75    42    55     4    20     0  ...    12     4    15     0     0     0     0\n4.0      6     0     0     2   371    18     8  ...     6     3     6     0    32     3     0\n5.0      0     1     0     0    51   619     0  ...     0     0     0     1     8    13     0\n6.0      1     1     0     0     0     0    14  ...     2     0     0     0     0     0     0\n7.0     18    19     0     3    12     0    23  ...     2     0     0     0     0     0     0\n8.0      0     0     0     0     2    13     0  ...     0     0     0     2     0     0     0\n9.0      1    90     1     6     4     4     0  ...   562   259     7     0     0     0     0\n10.0     1   255    26     8     5    13     1  ...    53  1908    40     0     0     0     0\n11.0     1    46    56     4     0     2     0  ...    37   149   261     0     0     1     1\n12.0     0     0     0     1     0    12     0  ...     0     0     0   180     0     2     0\n13.0     0     0     0     0    48    12     0  ...     0     0     0     3  1123    17     0\n14.0     0     0     0     0    35   125     0  ...     6     2     1    34   108    60     0\n15.0     0     0     0     0     0     0     0  ...     7     2     7     0     0     0    73\n\n[16 rows x 16 columns]\n View run handsome-tern-262 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/16913dcd59f84469a3d464313e23c26c\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results4.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.678238          0.554131           0.628028\n1    2          0.676184          0.572931           0.623897\n2    3          0.683270          0.614782           0.638582\n3    4          0.677313          0.595444           0.629114\n4    5          0.711924          0.579522           0.667494\n\nAverage Performance Over 5 Runs:\nOverall Accuracy: 0.6854\nAverage Accuracy: 0.5834\nKappa Coefficient: 0.6374\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_5 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1394\nEpoch 1: val_loss improved from inf to 11.84288, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n2025/02/20 07:49:14 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Unable to synchronously create group (name parameter cannot be an empty string)\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.9011 - val_loss: 11.8429\nEpoch 2/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7612\nEpoch 2: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.7587 - val_loss: 11.8429\nEpoch 3/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3215\nEpoch 3: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3216 - val_loss: 11.8429\nEpoch 4/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1848\nEpoch 4: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1836 - val_loss: 11.8429\nEpoch 5/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1561\nEpoch 5: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1552 - val_loss: 11.8429\nEpoch 6/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4276\nEpoch 6: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4315 - val_loss: 11.8429\nEpoch 7/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1720\nEpoch 7: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1848 - val_loss: 11.8429\nEpoch 8/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0154\nEpoch 8: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0226 - val_loss: 11.8429\nEpoch 9/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2172\nEpoch 9: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2620 - val_loss: 11.8429\nEpoch 10/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7396\nEpoch 10: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.7281 - val_loss: 11.8429\nEpoch 11/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4815\nEpoch 11: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4788 - val_loss: 11.8429\nEpoch 12/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9914\nEpoch 12: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.9441 - val_loss: 11.8429\nEpoch 13/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3987\nEpoch 13: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3827 - val_loss: 11.8429\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0724\nEpoch 14: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0642 - val_loss: 11.8429\nEpoch 15/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8364\nEpoch 15: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8354 - val_loss: 11.8429\nEpoch 16/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7945\nEpoch 16: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7909 - val_loss: 11.8429\nEpoch 17/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7612\nEpoch 17: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7582 - val_loss: 11.8429\nEpoch 18/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7524\nEpoch 18: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7501 - val_loss: 11.8429\nEpoch 19/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9418\nEpoch 19: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9417 - val_loss: 11.8429\nEpoch 20/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0497\nEpoch 20: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0970 - val_loss: 11.8429\nEpoch 21/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7093\nEpoch 21: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.7358 - val_loss: 11.8429\nEpoch 22/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2254\nEpoch 22: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2446 - val_loss: 11.8429\nEpoch 23/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5587\nEpoch 23: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5261 - val_loss: 11.8429\nEpoch 24/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7598\nEpoch 24: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7580 - val_loss: 11.8429\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8271\nEpoch 25: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8238 - val_loss: 11.8429\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6798\nEpoch 26: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6789 - val_loss: 11.8429\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6991\nEpoch 27: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6976 - val_loss: 11.8429\nEpoch 28/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6273\nEpoch 28: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6276 - val_loss: 11.8429\nEpoch 29/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6918\nEpoch 29: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6914 - val_loss: 11.8429\nEpoch 30/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5983\nEpoch 30: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5997 - val_loss: 11.8429\nEpoch 31/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7536\nEpoch 31: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7524 - val_loss: 11.8429\nEpoch 32/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9286\nEpoch 32: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0285 - val_loss: 11.8429\nEpoch 33/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9617\nEpoch 33: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0181 - val_loss: 11.8429\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6442\nEpoch 34: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6523 - val_loss: 11.8429\nEpoch 35/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7135\nEpoch 35: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6748 - val_loss: 11.8429\nEpoch 36/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7902\nEpoch 36: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7891 - val_loss: 11.8429\nEpoch 37/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8200\nEpoch 37: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8137 - val_loss: 11.8429\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7435\nEpoch 38: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7424 - val_loss: 11.8429\nEpoch 39/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7363\nEpoch 39: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7339 - val_loss: 11.8429\nEpoch 40/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6805\nEpoch 40: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6790 - val_loss: 11.8429\nEpoch 41/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6743\nEpoch 41: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6717 - val_loss: 11.8429\nEpoch 42/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6298\nEpoch 42: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6306 - val_loss: 11.8429\nEpoch 43/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6378\nEpoch 43: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6372 - val_loss: 11.8429\nEpoch 44/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6143\nEpoch 44: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6167 - val_loss: 11.8429\nEpoch 45/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6543\nEpoch 45: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6556 - val_loss: 11.8429\nEpoch 46/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0227\nEpoch 46: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0366 - val_loss: 11.8429\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8084\nEpoch 47: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.8319 - val_loss: 11.8429\nEpoch 48/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0760\nEpoch 48: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0821 - val_loss: 11.8429\nEpoch 49/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0270\nEpoch 49: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0237 - val_loss: 11.8429\nEpoch 50/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0359\nEpoch 50: val_loss did not improve from 11.84288\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0356 - val_loss: 11.8429\nWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c71988acf40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c71988acf40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n2025/02/20 07:50:13 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpp6jbv494/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 07:51:16 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 07:51:24 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp6nlb8zf3/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 07:51:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run omniscient-sow-588 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/e6e0c5d99c9446489bb36c1887953adb\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [  3 187 102  23   8 121  24 184  25   4  53 166  63  30 105 157 180  72\n  86 186  76 117 134  74 101]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 6 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      2     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   752    20    46     2     1     0  ...   118   401    27     0     0     0     0\n2.0      0    85   387    21     0     1     0  ...    28   213    44     0     0     0     0\n3.0      0    40    42   101     0     8     0  ...     5     9    17     0     0     0     0\n4.0      4     9     0     4   370     6     0  ...    15     5     3     0    23     3     0\n5.0      0     4     0     1    19   632     0  ...     0     1     0     0     8    28     0\n6.0      0     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n7.0      4     4     0     0     1     0     0  ...     0     1     0     0     0     0     0\n8.0      0     0     0     3     2    12     0  ...     0     0     0     2     0     1     0\n9.0      0    92     4     3     0     3     0  ...   474   335    12     0     0     0     0\n10.0     0   241    77     6     8     5     0  ...    89  1837    57     0     0     6     0\n11.0     0   106    61     9     0     1     0  ...    62   214   114     0     0     0     0\n12.0     0     2     0     0     0     4     0  ...     1     0     0   179     0    10     0\n13.0     1     0     0     0    53     1     0  ...     0     0     0     4  1067    76     0\n14.0     1     4     0     2    28    44     0  ...     8     0     5    26    70   173     0\n15.0     0     5     0     0     0     0     0  ...     8     0     0     0     0     0    74\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     11     0     0     1     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   633    13    38     2     2     0  ...   127   530     9     0     0     0     2\n2.0      0    24   442    15     0     1     0  ...     0   291    21     0     0     0     0\n3.0      0    41    48   100     2    11     0  ...     3    15     0     0     0     0     1\n4.0      1     2     0    11   261    32     3  ...     2     0     1     0   145     0     0\n5.0      0     0     0     3    43   587     0  ...     0     1     0     2     3    50     0\n6.0      0     0     0     4     1     0    12  ...     0     0     0     0     0     0     0\n7.0     11     4     0    29     6     0     7  ...     0     1     0     0     0     0     0\n8.0      0     0     0     0     1    18     0  ...     0     0     0     1     0     0     0\n9.0      0    32     2    17     6     1     1  ...   546   320     3     0     0     0     0\n10.0     0    79    41    29     4    18     0  ...    74  2040    31     0     0     2     1\n11.0     0    78    89    34     1     1     0  ...    27   215   121     0     0     0     2\n12.0     0     0     0     2     1     2     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     0   110     2     0  ...     0     0     0    10  1066    19     0\n14.0     2     0     0     7    44    72     0  ...     0     0     0    39    96   104     3\n15.0     0     1     0     0     0     0     0  ...     1     4     6     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   813    31     8     4     4     0  ...   111   308    64     0     0     1     0\n2.0      0   109   425    18     0     2     0  ...     9   146    85     0     0     0     0\n3.0      1    39    27    64     1    17     0  ...     9    23    47     0     0     0     0\n4.0      0     0     0     1   390    11     0  ...     2     3     3     0    28    10     0\n5.0      0     1     0     0    10   620     0  ...     7     3     0     7     8    40     0\n6.0      1     0     0     0     0     0    18  ...     0     0     0     0     0     0     0\n7.0    104     6     0     0     6     0     1  ...     0     0     1     0     0     0     0\n8.0      0     0     0     0     0    11     0  ...     0     0     0     6     0     0     0\n9.0      0   120     7     2    10     2     1  ...   601   153    26     0     0     3     0\n10.0     0   359   109    11    17    10     1  ...   159  1600    58     0     0     4     1\n11.0     0    77    60    26     0     6     0  ...    24    55   307     0     0     0     1\n12.0     0     0     0     0     1     1     0  ...     0     1     0   172     0    18     0\n13.0     0     0     0     0    32    10     0  ...     0     1     0     1  1090    70     0\n14.0     0     0     0     0    18    90     0  ...     0     4    10    38    83   125     0\n15.0     0     4     1     0     2     0     0  ...     5     1     5     0     0     0    70\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     17     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   717    29     5     1     3     0  ...   138   438    20     0     0     0     0\n2.0      0    49   334    20     0     0     0  ...     8   249   136     0     0     0     0\n3.0      0    17    60    94     0     8     0  ...     6    22    19     0     0     0     0\n4.0     17     5     3     1   332    31     4  ...     5     3     4     0    34    25     0\n5.0      0     9     2     9     8   548     0  ...     0     6     4     0    11    98     0\n6.0      1     0     0     0     2     0    11  ...     3     0     0     0     0     0     0\n7.0     18     3     0     0     4     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0    72    21     6     0     1     1  ...   607   191    17     0     0     0     0\n10.0     0   184   114     9     3     9     0  ...   121  1768   117     0     0     6     0\n11.0     0    42   100     3     0     2     0  ...    69   112   231     0     0     0     1\n12.0     0     0     0     0     0    11     0  ...     0     0     0   171     0    10     0\n13.0     1     0     0     0    46     7     0  ...     0     0     0     9  1114    25     0\n14.0     1     0     1     0     9    72     0  ...     2     0     2    35    92   150     0\n15.0     0     2     0     0     0     0     0  ...     3     2     6     0     0     0    74\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     0     0     0     4  ...     0     0     0     0     0     0     0\n1.0      0   930     9     2     3     3     0  ...   126   256    21     0     0     0     0\n2.0      0    62   388     6     0     1     0  ...    24   267    42     0     0     0     0\n3.0      0    75    42    55     4    20     0  ...    12     4    15     0     0     0     0\n4.0      6     0     0     2   371    18     8  ...     6     3     6     0    32     3     0\n5.0      0     1     0     0    51   619     0  ...     0     0     0     1     8    13     0\n6.0      1     1     0     0     0     0    14  ...     2     0     0     0     0     0     0\n7.0     18    19     0     3    12     0    23  ...     2     0     0     0     0     0     0\n8.0      0     0     0     0     2    13     0  ...     0     0     0     2     0     0     0\n9.0      1    90     1     6     4     4     0  ...   562   259     7     0     0     0     0\n10.0     1   255    26     8     5    13     1  ...    53  1908    40     0     0     0     0\n11.0     1    46    56     4     0     2     0  ...    37   149   261     0     0     1     1\n12.0     0     0     0     1     0    12     0  ...     0     0     0   180     0     2     0\n13.0     0     0     0     0    48    12     0  ...     0     0     0     3  1123    17     0\n14.0     0     0     0     0    35   125     0  ...     6     2     1    34   108    60     0\n15.0     0     0     0     0     0     0     0  ...     7     2     7     0     0     0    73\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 6:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     20     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n1.0      0   903     3    42     3     4     0  ...   130   265     7     0     0     0     0\n2.0      0    48   365    22     0     0     0  ...    17   290    50     0     0     0     0\n3.0      0    66    20    93     0    15     2  ...     5    19     3     0     0     0     0\n4.0      2     3     0     9   379    16     4  ...     6    11     1     0    17     2     0\n5.0      0     0     0    24     9   606     0  ...     0     6     0     2     2    34     0\n6.0      1     0     0     0     1     0    18  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     4     0    10  ...     2     3     0     0     0     0     0\n8.0      0     0     0     0     2     3     0  ...     0     0     0     0     0     0     0\n9.0      0   103     5     8     0     2     1  ...   480   327     1     0     0     0     0\n10.0     0   134    32    20     7    11     0  ...   112  1973    32     0     0     0     1\n11.0     0    86    89    30     0     6     0  ...    34   198   126     0     0     0     0\n12.0     0     0     0     1     0    13     0  ...     0     0     0   158     0     8     0\n13.0     0     0     0     0    10    11     0  ...     0     0     0     1  1168    10     0\n14.0     0     0     3     1    14    99     0  ...     3     2     0    19   113   109     0\n15.0     0     1     0     0     0     0     0  ...     6     6     3     0     0     0    74\n\n[16 rows x 16 columns]\n View run adorable-lark-142 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/8bdaabc25b464ba2aad801e15cde9eaf\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results5.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.678238          0.554131           0.628028\n1    2          0.676184          0.572931           0.623897\n2    3          0.683270          0.614782           0.638582\n3    4          0.677313          0.595444           0.629114\n4    5          0.711924          0.579522           0.667494\n5    6          0.710897          0.663951           0.665025\n\nAverage Performance Over 6 Runs:\nOverall Accuracy: 0.6896\nAverage Accuracy: 0.5968\nKappa Coefficient: 0.6420\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Multi layer seed =42","metadata":{}},{"cell_type":"code","source":"# %matplotlib inline\n!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T08:00:02.175433Z","iopub.execute_input":"2025-02-20T08:00:02.175812Z","iopub.status.idle":"2025-02-20T08:24:40.245905Z","shell.execute_reply.started":"2025-02-20T08:00:02.175781Z","shell.execute_reply":"2025-02-20T08:24:40.244421Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"2025-02-20 08:00:02.784474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1740038402.824312   12400 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1740038402.836350   12400 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAccessing as vidhi-gajra-git\nInitialized MLflow to track repo \u001b[32m\"vidhi-gajra-git/SRL_SOA\"\u001b[0m\nRepository vidhi-gajra-git/SRL_SOA initialized!\n\nScene:  (145, 145, 200)\n\nClassification:\nTraining samples:  512\nTest samples:  9737\n\n\nNumber of bands:  200\n**********  METHOD : SVM **********\n\t\t\t\t\t *****  #RUNS : 6  *****\n2025-02-20 08:00:11.570296: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot (\u001b[94mDot\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 33.8242\nEpoch 1: val_loss improved from inf to 26.18815, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 33.7954 - val_loss: 26.1881\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.7136\nEpoch 2: val_loss improved from 26.18815 to 24.65903, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 25.7125 - val_loss: 24.6590\nEpoch 3/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24.2388\nEpoch 3: val_loss improved from 24.65903 to 24.55090, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 24.2392 - val_loss: 24.5509\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23.7032\nEpoch 4: val_loss did not improve from 24.55090\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 23.7113 - val_loss: 26.0021\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.9306\nEpoch 5: val_loss improved from 24.55090 to 23.79995, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 24.9135 - val_loss: 23.8000\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.0298\nEpoch 6: val_loss improved from 23.79995 to 23.10593, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 24.0245 - val_loss: 23.1059\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23.4318\nEpoch 7: val_loss improved from 23.10593 to 22.16663, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 23.4311 - val_loss: 22.1666\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23.8063\nEpoch 8: val_loss did not improve from 22.16663\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 23.8362 - val_loss: 30.1175\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21.3967\nEpoch 9: val_loss improved from 22.16663 to 19.37409, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 21.3815 - val_loss: 19.3741\nEpoch 10/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20.0713\nEpoch 10: val_loss did not improve from 19.37409\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 20.0718 - val_loss: 21.2347\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.3253\nEpoch 11: val_loss improved from 19.37409 to 17.27854, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 18.3145 - val_loss: 17.2785\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17.2786\nEpoch 12: val_loss did not improve from 17.27854\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 17.3013 - val_loss: 19.5811\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 17.1433\nEpoch 13: val_loss improved from 17.27854 to 16.10706, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 17.1245 - val_loss: 16.1071\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 16.4077\nEpoch 14: val_loss did not improve from 16.10706\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 16.4743 - val_loss: 17.9506\nEpoch 15/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 19.5614\nEpoch 15: val_loss improved from 16.10706 to 15.24318, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 19.5201 - val_loss: 15.2432\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 16.0060\nEpoch 16: val_loss improved from 15.24318 to 14.53605, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 16.0437 - val_loss: 14.5361\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.1034\nEpoch 17: val_loss did not improve from 14.53605\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 15.1007 - val_loss: 14.9467\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.8196\nEpoch 18: val_loss improved from 14.53605 to 12.78306, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 13.8118 - val_loss: 12.7831\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.6479\nEpoch 19: val_loss improved from 12.78306 to 12.43155, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 12.6486 - val_loss: 12.4316\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.1387\nEpoch 20: val_loss improved from 12.43155 to 12.02548, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 12.1384 - val_loss: 12.0255\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.7396\nEpoch 21: val_loss improved from 12.02548 to 11.59134, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 11.7329 - val_loss: 11.5913\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.6897\nEpoch 22: val_loss did not improve from 11.59134\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 11.6892 - val_loss: 11.6268\nEpoch 23/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.3104\nEpoch 23: val_loss did not improve from 11.59134\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 12.4036 - val_loss: 28.7530\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.0358\nEpoch 24: val_loss did not improve from 11.59134\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 13.9875 - val_loss: 12.3531\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.4706\nEpoch 25: val_loss improved from 11.59134 to 9.53281, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 12.4406 - val_loss: 9.5328\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.1160\nEpoch 26: val_loss did not improve from 9.53281\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 10.1414 - val_loss: 9.9627\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.5817\nEpoch 27: val_loss improved from 9.53281 to 9.51355, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 10.6268 - val_loss: 9.5136\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.2134\nEpoch 28: val_loss improved from 9.51355 to 8.83441, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 10.2018 - val_loss: 8.8344\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.7050\nEpoch 29: val_loss improved from 8.83441 to 8.10055, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 8.7105 - val_loss: 8.1006\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.3488\nEpoch 30: val_loss improved from 8.10055 to 7.61963, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 8.3528 - val_loss: 7.6196\nEpoch 31/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.8473\nEpoch 31: val_loss improved from 7.61963 to 7.08412, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 7.8464 - val_loss: 7.0841\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.1786\nEpoch 32: val_loss improved from 7.08412 to 6.69131, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 7.1754 - val_loss: 6.6913\nEpoch 33/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.1062\nEpoch 33: val_loss did not improve from 6.69131\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 7.1069 - val_loss: 7.3042\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.0042\nEpoch 34: val_loss did not improve from 6.69131\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.0574 - val_loss: 11.7955\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.6218\nEpoch 35: val_loss did not improve from 6.69131\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 13.5358 - val_loss: 8.2526\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.4050\nEpoch 36: val_loss did not improve from 6.69131\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 9.5074 - val_loss: 20.2564\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.7745\nEpoch 37: val_loss did not improve from 6.69131\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 9.7326 - val_loss: 8.8775\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.5671\nEpoch 38: val_loss did not improve from 6.69131\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 6.5618 - val_loss: 7.1833\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.0319\nEpoch 39: val_loss improved from 6.69131 to 6.30984, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 6.0400 - val_loss: 6.3098\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.0246\nEpoch 40: val_loss did not improve from 6.30984\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 6.0338 - val_loss: 6.5379\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.0144\nEpoch 41: val_loss did not improve from 6.30984\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 6.0212 - val_loss: 7.2285\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.7967\nEpoch 42: val_loss improved from 6.30984 to 5.92767, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 5.7907 - val_loss: 5.9277\nEpoch 43/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.0224\nEpoch 43: val_loss improved from 5.92767 to 5.42818, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 5.0213 - val_loss: 5.4282\nEpoch 44/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.2119\nEpoch 44: val_loss did not improve from 5.42818\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 5.2146 - val_loss: 8.4801\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.2626\nEpoch 45: val_loss did not improve from 5.42818\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 9.2341 - val_loss: 5.4556\nEpoch 46/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.3738\nEpoch 46: val_loss did not improve from 5.42818\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 9.3615 - val_loss: 7.4989\nEpoch 47/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.9416\nEpoch 47: val_loss did not improve from 5.42818\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 7.9579 - val_loss: 10.8458\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.9469\nEpoch 48: val_loss did not improve from 5.42818\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 6.9280 - val_loss: 6.6784\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.9353\nEpoch 49: val_loss improved from 5.42818 to 4.84503, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 4.9342 - val_loss: 4.8450\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.4200\nEpoch 50: val_loss improved from 4.84503 to 4.66895, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 4.4242 - val_loss: 4.6690\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n2025/02/20 08:03:26 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpo2ijkhyg/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n2025/02/20 08:03:32 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 08:03:40 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpgey_rv_a/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 08:03:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run clean-goat-91 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/a154297474a74cc1b3d6e06016a00b4d\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [97 69 37 58 45 44 48 63 42 43 66 47 67 61 51 38 68 64 57 81 46 62 35 16\n 53]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 1 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      4     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807   120    32     0     2     0  ...    37   354    15     0     0     1     0\n2.0      0   162   364    25     0     2     0  ...    17   184    25     0     0     0     0\n3.0      0    38    73   102     1     0     0  ...     1     4     2     0     0     0     0\n4.0      1     0     9    14   409     1     0  ...     7    12     4     0     3     1     0\n5.0      0     5     0     2     3   646     0  ...     1     2     0     0     2    32     0\n6.0      0     0     0     2     1     0     0  ...     1     2     0     0     0     0     0\n7.0      0     0     0     0    10     0     0  ...     0     1     0     0     0     0     0\n8.0      0    15     0     0     0     2     0  ...     0     0     0     1     2     0     0\n9.0      0    79    37     5     0     4     0  ...   322   446    31     0     0     0     0\n10.0     0   246    83    17    10    10     0  ...   121  1821    17     0     1     2     0\n11.0     0    45    63    19     2     3     0  ...    26   123   285     0     0     1     0\n12.0     0     7     0     0     0     1     0  ...     0     0     0   188     0     0     0\n13.0     0     0     0     0    15     1     0  ...     0     0     1     9  1119    57     0\n14.0     1    29    11     4    32    23     0  ...     1     0     1    24    66   166     0\n15.0     0    12     5     0     0     0     0  ...     0     0     1     0     0     0    69\n\n[16 rows x 16 columns]\n View run abundant-crow-639 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/7521be17ffec4518a1bda7485ab60425\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results0.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.692513          0.573164           0.644891\n\nAverage Performance Over 1 Runs:\nOverall Accuracy: 0.6925\nAverage Accuracy: 0.5732\nKappa Coefficient: 0.6449\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_1 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 35.1243\nEpoch 1: val_loss improved from inf to 37.41661, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 35.0349 - val_loss: 37.4166\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 29.8337\nEpoch 2: val_loss did not improve from 37.41661\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 29.7851 - val_loss: 46.6509\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 35.2970\nEpoch 3: val_loss did not improve from 37.41661\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 35.1756 - val_loss: 53.5075\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 37.2382\nEpoch 4: val_loss did not improve from 37.41661\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 37.0656 - val_loss: 60.2975\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 38.7674\nEpoch 5: val_loss improved from 37.41661 to 29.74991, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 38.5159 - val_loss: 29.7499\nEpoch 6/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 27.8790\nEpoch 6: val_loss improved from 29.74991 to 28.70924, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 27.8175 - val_loss: 28.7092\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 24.8560\nEpoch 7: val_loss improved from 28.70924 to 22.75684, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 24.8171 - val_loss: 22.7568\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.1879\nEpoch 8: val_loss improved from 22.75684 to 22.54060, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 22.1836 - val_loss: 22.5406\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21.3630\nEpoch 9: val_loss improved from 22.54060 to 21.10448, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 21.3540 - val_loss: 21.1045\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20.3905\nEpoch 10: val_loss improved from 21.10448 to 20.46372, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 20.3838 - val_loss: 20.4637\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19.6285\nEpoch 11: val_loss improved from 20.46372 to 19.32144, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 19.6231 - val_loss: 19.3214\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18.9024\nEpoch 12: val_loss improved from 19.32144 to 18.49976, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 18.9007 - val_loss: 18.4998\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.2275\nEpoch 13: val_loss improved from 18.49976 to 17.89063, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 18.2295 - val_loss: 17.8906\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17.6484\nEpoch 14: val_loss improved from 17.89063 to 17.40581, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 17.6493 - val_loss: 17.4058\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16.8681\nEpoch 15: val_loss improved from 17.40581 to 16.95037, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 16.8652 - val_loss: 16.9504\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 16.3283\nEpoch 16: val_loss improved from 16.95037 to 16.36438, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 16.3218 - val_loss: 16.3644\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.6145\nEpoch 17: val_loss did not improve from 16.36438\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 15.6112 - val_loss: 16.8465\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16.2387\nEpoch 18: val_loss improved from 16.36438 to 15.75319, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 16.2572 - val_loss: 15.7532\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.4688\nEpoch 19: val_loss did not improve from 15.75319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 15.4848 - val_loss: 17.1295\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 19.2195\nEpoch 20: val_loss did not improve from 15.75319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 19.3050 - val_loss: 18.8165\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.0294\nEpoch 21: val_loss did not improve from 15.75319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 15.0095 - val_loss: 17.5371\nEpoch 22/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 14.0664\nEpoch 22: val_loss improved from 15.75319 to 13.86436, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 14.0564 - val_loss: 13.8644\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.6315\nEpoch 23: val_loss improved from 13.86436 to 12.76332, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 12.6257 - val_loss: 12.7633\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.2501\nEpoch 24: val_loss did not improve from 12.76332\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 12.2464 - val_loss: 13.0688\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.8686\nEpoch 25: val_loss improved from 12.76332 to 11.29560, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 11.8511 - val_loss: 11.2956\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.7488\nEpoch 26: val_loss did not improve from 11.29560\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 10.7498 - val_loss: 12.2003\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.1924\nEpoch 27: val_loss improved from 11.29560 to 10.62616, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 11.1759 - val_loss: 10.6262\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2014\nEpoch 28: val_loss did not improve from 10.62616\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 10.2181 - val_loss: 25.2347\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.3927\nEpoch 29: val_loss did not improve from 10.62616\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 14.3192 - val_loss: 22.3207\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.7406\nEpoch 30: val_loss did not improve from 10.62616\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 13.6774 - val_loss: 16.4910\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.9752\nEpoch 31: val_loss did not improve from 10.62616\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 12.9294 - val_loss: 16.1728\nEpoch 32/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.3574\nEpoch 32: val_loss improved from 10.62616 to 9.81387, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 10.3407 - val_loss: 9.8139\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.5054\nEpoch 33: val_loss improved from 9.81387 to 9.23233, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 9.4833 - val_loss: 9.2323\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.5547\nEpoch 34: val_loss did not improve from 9.23233\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 8.5754 - val_loss: 11.7481\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.8241\nEpoch 35: val_loss improved from 9.23233 to 8.78109, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 10.8177 - val_loss: 8.7811\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.8599\nEpoch 36: val_loss improved from 8.78109 to 7.52760, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 8.8542 - val_loss: 7.5276\nEpoch 37/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.8701\nEpoch 37: val_loss improved from 7.52760 to 6.93354, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 7.8804 - val_loss: 6.9335\nEpoch 38/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.7001\nEpoch 38: val_loss improved from 6.93354 to 6.73179, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 6.6982 - val_loss: 6.7318\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.5379\nEpoch 39: val_loss did not improve from 6.73179\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 6.5327 - val_loss: 7.0257\nEpoch 40/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2832\nEpoch 40: val_loss improved from 6.73179 to 6.51907, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 6.2702 - val_loss: 6.5191\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.3127\nEpoch 41: val_loss improved from 6.51907 to 5.80433, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 6.3065 - val_loss: 5.8043\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.6603\nEpoch 42: val_loss did not improve from 5.80433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 6.6714 - val_loss: 6.9475\nEpoch 43/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.2440\nEpoch 43: val_loss did not improve from 5.80433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.2586 - val_loss: 8.0782\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.8403\nEpoch 44: val_loss did not improve from 5.80433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 7.8585 - val_loss: 8.1689\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.2322\nEpoch 45: val_loss did not improve from 5.80433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 9.2639 - val_loss: 9.5465\nEpoch 46/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.3061\nEpoch 46: val_loss did not improve from 5.80433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 10.3113 - val_loss: 8.5799\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.7635\nEpoch 47: val_loss did not improve from 5.80433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 7.7630 - val_loss: 9.5267\nEpoch 48/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.7552\nEpoch 48: val_loss did not improve from 5.80433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 7.7405 - val_loss: 5.8271\nEpoch 49/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.7180\nEpoch 49: val_loss improved from 5.80433 to 5.12300, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 5.7178 - val_loss: 5.1230\nEpoch 50/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.0755\nEpoch 50: val_loss improved from 5.12300 to 4.83465, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 5.0714 - val_loss: 4.8346\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n2025/02/20 08:07:35 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmps25ihyx1/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n2025/02/20 08:07:41 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 08:07:49 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpi5s2l10g/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 08:07:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run illustrious-skunk-14 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/bfe6e485cedf4669974f80ad732f6e6d\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [186 123 167 190 168  40  71 157 114  38 151  46  10 133 140 161  41 160\n 176 117 113  43  69  64  37]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 2 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      4     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807   120    32     0     2     0  ...    37   354    15     0     0     1     0\n2.0      0   162   364    25     0     2     0  ...    17   184    25     0     0     0     0\n3.0      0    38    73   102     1     0     0  ...     1     4     2     0     0     0     0\n4.0      1     0     9    14   409     1     0  ...     7    12     4     0     3     1     0\n5.0      0     5     0     2     3   646     0  ...     1     2     0     0     2    32     0\n6.0      0     0     0     2     1     0     0  ...     1     2     0     0     0     0     0\n7.0      0     0     0     0    10     0     0  ...     0     1     0     0     0     0     0\n8.0      0    15     0     0     0     2     0  ...     0     0     0     1     2     0     0\n9.0      0    79    37     5     0     4     0  ...   322   446    31     0     0     0     0\n10.0     0   246    83    17    10    10     0  ...   121  1821    17     0     1     2     0\n11.0     0    45    63    19     2     3     0  ...    26   123   285     0     0     1     0\n12.0     0     7     0     0     0     1     0  ...     0     0     0   188     0     0     0\n13.0     0     0     0     0    15     1     0  ...     0     0     1     9  1119    57     0\n14.0     1    29    11     4    32    23     0  ...     1     0     1    24    66   166     0\n15.0     0    12     5     0     0     0     0  ...     0     0     1     0     0     0    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807    22     5     2     4     0  ...   109   400     4     0     0     0     3\n2.0      0    27   474    25     0     0     0  ...     1   254    13     0     0     0     0\n3.0      0    10    35   158     0    12     1  ...     2     3     0     0     0     0     0\n4.0      0     2     0     5   423    15     1  ...     0     5     1     0     7     0     0\n5.0      0     0     0     0     4   648     0  ...     0     1     0     0     1    35     0\n6.0      0     0     0     0     1     0    22  ...     0     0     0     0     0     0     0\n7.0      3     0     0     0     0     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0   154     1     2    12     2     0  ...   488   261     9     0     0     0     0\n10.0     0   176    65    13     8    13     1  ...    55  1948    36     0     0     5     0\n11.0     0    28    55    21     0     5     0  ...     3    47   404     0     0     1     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    22     4     0  ...     0     0     0     2  1130    49     0\n14.0     0     0     0     2    36    49     0  ...     1     0     0    31    79   168     1\n15.0     0     1     0     0     0     0     0  ...     3     6     2     0     0     0    76\n\n[16 rows x 16 columns]\n View run bustling-elk-457 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/3702b43807d04cc4abfbfa3525fc6e87\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results1.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.692513          0.573164           0.644891\n1    2          0.762247          0.732325           0.726264\n\nAverage Performance Over 2 Runs:\nOverall Accuracy: 0.7274\nAverage Accuracy: 0.6527\nKappa Coefficient: 0.6856\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_2 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 40.4070\nEpoch 1: val_loss improved from inf to 26.37166, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 40.2019 - val_loss: 26.3717\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25.3775\nEpoch 2: val_loss improved from 26.37166 to 24.96305, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 25.3641 - val_loss: 24.9630\nEpoch 3/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24.4648\nEpoch 3: val_loss improved from 24.96305 to 24.92192, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 24.4573 - val_loss: 24.9219\nEpoch 4/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 23.6559\nEpoch 4: val_loss improved from 24.92192 to 23.27113, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 23.6366 - val_loss: 23.2711\nEpoch 5/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 22.3034\nEpoch 5: val_loss did not improve from 23.27113\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 22.3109 - val_loss: 28.9194\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26.2978\nEpoch 6: val_loss improved from 23.27113 to 21.55840, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 26.2591 - val_loss: 21.5584\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26.3964\nEpoch 7: val_loss did not improve from 21.55840\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 26.3436 - val_loss: 22.2718\nEpoch 8/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25.1563\nEpoch 8: val_loss improved from 21.55840 to 20.44299, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 25.1269 - val_loss: 20.4430\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20.2238\nEpoch 9: val_loss improved from 20.44299 to 19.52413, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 20.2022 - val_loss: 19.5241\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19.0069\nEpoch 10: val_loss improved from 19.52413 to 18.47772, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 18.9883 - val_loss: 18.4777\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 17.8540\nEpoch 11: val_loss improved from 18.47772 to 17.84016, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 17.8426 - val_loss: 17.8402\nEpoch 12/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 16.9236\nEpoch 12: val_loss improved from 17.84016 to 17.55180, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 16.9187 - val_loss: 17.5518\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16.0963\nEpoch 13: val_loss improved from 17.55180 to 15.33700, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 16.0843 - val_loss: 15.3370\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.1802\nEpoch 14: val_loss did not improve from 15.33700\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 15.1836 - val_loss: 17.6677\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 15.3777\nEpoch 15: val_loss did not improve from 15.33700\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 15.4203 - val_loss: 23.5900\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18.4360\nEpoch 16: val_loss did not improve from 15.33700\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 18.3862 - val_loss: 16.5149\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16.3438\nEpoch 17: val_loss improved from 15.33700 to 14.64816, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 16.3036 - val_loss: 14.6482\nEpoch 18/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13.4038\nEpoch 18: val_loss improved from 14.64816 to 13.01587, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 13.3991 - val_loss: 13.0159\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.2328\nEpoch 19: val_loss improved from 13.01587 to 11.95449, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 12.2263 - val_loss: 11.9545\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11.6865\nEpoch 20: val_loss improved from 11.95449 to 11.00054, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 11.6807 - val_loss: 11.0005\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.0744\nEpoch 21: val_loss improved from 11.00054 to 10.67217, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 11.0683 - val_loss: 10.6722\nEpoch 22/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.4011\nEpoch 22: val_loss improved from 10.67217 to 10.12607, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 10.3980 - val_loss: 10.1261\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.9134\nEpoch 23: val_loss did not improve from 10.12607\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 9.9227 - val_loss: 12.6673\nEpoch 24/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13.7527\nEpoch 24: val_loss did not improve from 10.12607\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 13.7610 - val_loss: 15.4141\nEpoch 25/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 16.1357\nEpoch 25: val_loss did not improve from 10.12607\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 16.1061 - val_loss: 12.4393\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.4812\nEpoch 26: val_loss improved from 10.12607 to 9.46862, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 11.4392 - val_loss: 9.4686\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.9606\nEpoch 27: val_loss improved from 9.46862 to 8.34812, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 8.9599 - val_loss: 8.3481\nEpoch 28/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.7955\nEpoch 28: val_loss improved from 8.34812 to 8.11386, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 8.7964 - val_loss: 8.1139\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.3934\nEpoch 29: val_loss improved from 8.11386 to 8.06012, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 8.3965 - val_loss: 8.0601\nEpoch 30/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.0720\nEpoch 30: val_loss improved from 8.06012 to 7.74490, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 8.0731 - val_loss: 7.7449\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.9117\nEpoch 31: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.9165 - val_loss: 8.2814\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.7243\nEpoch 32: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.7320 - val_loss: 9.6027\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.6398\nEpoch 33: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 10.6199 - val_loss: 9.2619\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.2165\nEpoch 34: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 12.1362 - val_loss: 10.2507\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.0562\nEpoch 35: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.0449 - val_loss: 10.9417\nEpoch 36/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.2418\nEpoch 36: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.2263 - val_loss: 10.6550\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.8361\nEpoch 37: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 7.8162 - val_loss: 9.6586\nEpoch 38/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.2114\nEpoch 38: val_loss did not improve from 7.74490\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 7.2071 - val_loss: 8.4940\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.6517\nEpoch 39: val_loss improved from 7.74490 to 7.61186, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 6.6455 - val_loss: 7.6119\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.4049\nEpoch 40: val_loss improved from 7.61186 to 7.49319, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 6.4051 - val_loss: 7.4932\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.4843\nEpoch 41: val_loss did not improve from 7.49319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 6.4847 - val_loss: 7.6439\nEpoch 42/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.6268\nEpoch 42: val_loss did not improve from 7.49319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 6.6240 - val_loss: 7.6716\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.5831\nEpoch 43: val_loss improved from 7.49319 to 7.10199, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 6.5585 - val_loss: 7.1020\nEpoch 44/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.9341\nEpoch 44: val_loss improved from 7.10199 to 6.31973, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 5.9253 - val_loss: 6.3197\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.2224\nEpoch 45: val_loss improved from 6.31973 to 5.90838, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 5.2183 - val_loss: 5.9084\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8891\nEpoch 46: val_loss improved from 5.90838 to 5.22592, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 4.8859 - val_loss: 5.2259\nEpoch 47/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.4464\nEpoch 47: val_loss improved from 5.22592 to 5.10601, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 4.4461 - val_loss: 5.1060\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3739\nEpoch 48: val_loss improved from 5.10601 to 4.28635, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 4.3726 - val_loss: 4.2864\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0899\nEpoch 49: val_loss did not improve from 4.28635\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.1035 - val_loss: 9.3197\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.7439\nEpoch 50: val_loss did not improve from 4.28635\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 12.6961 - val_loss: 8.6429\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n2025/02/20 08:11:29 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpvxq4s2j6/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n2025/02/20 08:11:36 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 08:11:44 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmps53a8vef/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 08:11:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run thoughtful-perch-339 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/9ccba731690245888c2ee91e9685fd2d\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [191  49 156 102  76 114  63  37  85  50  52  64  67 112  42  41  44  54\n  46  40  66  62  53  47  68]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 3 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      4     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807   120    32     0     2     0  ...    37   354    15     0     0     1     0\n2.0      0   162   364    25     0     2     0  ...    17   184    25     0     0     0     0\n3.0      0    38    73   102     1     0     0  ...     1     4     2     0     0     0     0\n4.0      1     0     9    14   409     1     0  ...     7    12     4     0     3     1     0\n5.0      0     5     0     2     3   646     0  ...     1     2     0     0     2    32     0\n6.0      0     0     0     2     1     0     0  ...     1     2     0     0     0     0     0\n7.0      0     0     0     0    10     0     0  ...     0     1     0     0     0     0     0\n8.0      0    15     0     0     0     2     0  ...     0     0     0     1     2     0     0\n9.0      0    79    37     5     0     4     0  ...   322   446    31     0     0     0     0\n10.0     0   246    83    17    10    10     0  ...   121  1821    17     0     1     2     0\n11.0     0    45    63    19     2     3     0  ...    26   123   285     0     0     1     0\n12.0     0     7     0     0     0     1     0  ...     0     0     0   188     0     0     0\n13.0     0     0     0     0    15     1     0  ...     0     0     1     9  1119    57     0\n14.0     1    29    11     4    32    23     0  ...     1     0     1    24    66   166     0\n15.0     0    12     5     0     0     0     0  ...     0     0     1     0     0     0    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807    22     5     2     4     0  ...   109   400     4     0     0     0     3\n2.0      0    27   474    25     0     0     0  ...     1   254    13     0     0     0     0\n3.0      0    10    35   158     0    12     1  ...     2     3     0     0     0     0     0\n4.0      0     2     0     5   423    15     1  ...     0     5     1     0     7     0     0\n5.0      0     0     0     0     4   648     0  ...     0     1     0     0     1    35     0\n6.0      0     0     0     0     1     0    22  ...     0     0     0     0     0     0     0\n7.0      3     0     0     0     0     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0   154     1     2    12     2     0  ...   488   261     9     0     0     0     0\n10.0     0   176    65    13     8    13     1  ...    55  1948    36     0     0     5     0\n11.0     0    28    55    21     0     5     0  ...     3    47   404     0     0     1     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    22     4     0  ...     0     0     0     2  1130    49     0\n14.0     0     0     0     2    36    49     0  ...     1     0     0    31    79   168     1\n15.0     0     1     0     0     0     0     0  ...     3     6     2     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     13     0     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   785    33    24     3     5     0  ...    63   401    28     0     0     2     1\n2.0      0   119   328    17     0     3     0  ...    32   223    72     0     0     0     0\n3.0      0    61    10    54     1    28     0  ...     5    39    29     0     0     0     0\n4.0      8     1     0     3   395     9     0  ...     0     4     5     0    21     9     0\n5.0      0     0     0     2    10   631     0  ...     2     3     0     1    15    31     0\n6.0      1     0     0     0     5     0    10  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     0     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     5     0  ...     0     0     0     1     0     2     0\n9.0      0    91    18     3    11     2     0  ...   183   605    11     0     0     1     0\n10.0     0   227    77    14     9    11     1  ...   101  1793    80     0     0    13     4\n11.0     0   163    28    17     0     9     0  ...    14   110   214     0     0     1     0\n12.0     0     0     0     1     0     1     0  ...     0     0     0   185     0     6     0\n13.0     0     0     0     0    19     2     0  ...     0     0     0     4  1161    18     0\n14.0     1     2     0     1    18    79     0  ...     1     1     4    13   116   125     1\n15.0     0     1     7     0     0     1     0  ...     1     5     2     0     0     1    69\n\n[16 rows x 16 columns]\n View run upset-mole-522 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/31af2612736d44ec9cbb47b7c19ec587\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results2.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.692513          0.573164           0.644891\n1    2          0.762247          0.732325           0.726264\n2    3          0.658724          0.602521           0.603915\n\nAverage Performance Over 3 Runs:\nOverall Accuracy: 0.7045\nAverage Accuracy: 0.6360\nKappa Coefficient: 0.6584\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_3 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 45.8529\nEpoch 1: val_loss improved from inf to 26.92711, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 45.6841 - val_loss: 26.9271\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26.6645\nEpoch 2: val_loss improved from 26.92711 to 24.50576, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 26.6582 - val_loss: 24.5058\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.4334\nEpoch 3: val_loss improved from 24.50576 to 23.68552, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 24.4336 - val_loss: 23.6855\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23.8784\nEpoch 4: val_loss did not improve from 23.68552\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 23.8742 - val_loss: 24.9459\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.3458\nEpoch 5: val_loss did not improve from 23.68552\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 24.3469 - val_loss: 26.8533\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.4876\nEpoch 6: val_loss improved from 23.68552 to 23.07998, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 25.4763 - val_loss: 23.0800\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 27.0397\nEpoch 7: val_loss improved from 23.07998 to 20.95987, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 26.9960 - val_loss: 20.9599\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.4802\nEpoch 8: val_loss did not improve from 20.95987\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 22.5169 - val_loss: 23.1907\nEpoch 9/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20.9283\nEpoch 9: val_loss improved from 20.95987 to 19.13032, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 20.9175 - val_loss: 19.1303\nEpoch 10/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19.1636\nEpoch 10: val_loss improved from 19.13032 to 18.75020, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 19.1644 - val_loss: 18.7502\nEpoch 11/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.3399\nEpoch 11: val_loss improved from 18.75020 to 18.18208, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 18.3416 - val_loss: 18.1821\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17.8498\nEpoch 12: val_loss improved from 18.18208 to 17.94146, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 17.8588 - val_loss: 17.9415\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17.6982\nEpoch 13: val_loss improved from 17.94146 to 17.48998, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 17.7098 - val_loss: 17.4900\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 17.8977\nEpoch 14: val_loss improved from 17.48998 to 16.64710, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 17.8997 - val_loss: 16.6471\nEpoch 15/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 16.5615\nEpoch 15: val_loss improved from 16.64710 to 16.03533, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 16.5596 - val_loss: 16.0353\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15.1680\nEpoch 16: val_loss did not improve from 16.03533\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 15.1839 - val_loss: 16.7215\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16.5801\nEpoch 17: val_loss improved from 16.03533 to 14.10261, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 16.6135 - val_loss: 14.1026\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17.8028\nEpoch 18: val_loss improved from 14.10261 to 13.33624, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 17.7355 - val_loss: 13.3362\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.4332\nEpoch 19: val_loss improved from 13.33624 to 12.68122, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 13.4327 - val_loss: 12.6812\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.9776\nEpoch 20: val_loss improved from 12.68122 to 11.85759, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 12.9657 - val_loss: 11.8576\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.1562\nEpoch 21: val_loss improved from 11.85759 to 11.49685, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 12.1543 - val_loss: 11.4969\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.9995\nEpoch 22: val_loss improved from 11.49685 to 11.04361, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 11.9965 - val_loss: 11.0436\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 11.8328\nEpoch 23: val_loss improved from 11.04361 to 10.43983, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 11.8251 - val_loss: 10.4398\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.4076\nEpoch 24: val_loss improved from 10.43983 to 9.91596, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 11.3984 - val_loss: 9.9160\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.8313\nEpoch 25: val_loss improved from 9.91596 to 9.53619, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 10.8239 - val_loss: 9.5362\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.3916\nEpoch 26: val_loss improved from 9.53619 to 9.18866, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 10.3853 - val_loss: 9.1887\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.9642\nEpoch 27: val_loss improved from 9.18866 to 8.80457, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 9.9578 - val_loss: 8.8046\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.5172\nEpoch 28: val_loss improved from 8.80457 to 8.46539, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 9.5113 - val_loss: 8.4654\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.0716\nEpoch 29: val_loss improved from 8.46539 to 8.22216, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 9.0665 - val_loss: 8.2222\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.6364\nEpoch 30: val_loss improved from 8.22216 to 8.04229, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 8.6320 - val_loss: 8.0423\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.1949\nEpoch 31: val_loss improved from 8.04229 to 7.86294, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 8.1908 - val_loss: 7.8629\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.7307\nEpoch 32: val_loss improved from 7.86294 to 7.66937, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 7.7271 - val_loss: 7.6694\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.2820\nEpoch 33: val_loss improved from 7.66937 to 7.49179, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 7.2797 - val_loss: 7.4918\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.2061\nEpoch 34: val_loss did not improve from 7.49179\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 7.2079 - val_loss: 7.9576\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.0414\nEpoch 35: val_loss did not improve from 7.49179\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.0598 - val_loss: 8.9121\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3358\nEpoch 36: val_loss did not improve from 7.49179\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.3401 - val_loss: 9.6290\nEpoch 37/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.4870\nEpoch 37: val_loss improved from 7.49179 to 6.70329, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 9.4768 - val_loss: 6.7033\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.5286\nEpoch 38: val_loss improved from 6.70329 to 5.75820, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 7.5215 - val_loss: 5.7582\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.9158\nEpoch 39: val_loss improved from 5.75820 to 5.37461, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 6.9091 - val_loss: 5.3746\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.0708\nEpoch 40: val_loss did not improve from 5.37461\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 6.0672 - val_loss: 5.6404\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.7376\nEpoch 41: val_loss did not improve from 5.37461\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 5.7340 - val_loss: 5.9175\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.2105\nEpoch 42: val_loss did not improve from 5.37461\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 5.2088 - val_loss: 6.1034\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8352\nEpoch 43: val_loss did not improve from 5.37461\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.8365 - val_loss: 6.0809\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5907\nEpoch 44: val_loss improved from 5.37461 to 5.19066, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.5921 - val_loss: 5.1907\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8533\nEpoch 45: val_loss did not improve from 5.19066\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.8646 - val_loss: 5.2801\nEpoch 46/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.0981\nEpoch 46: val_loss did not improve from 5.19066\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 5.1128 - val_loss: 9.7512\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.3125\nEpoch 47: val_loss did not improve from 5.19066\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 9.3297 - val_loss: 8.1369\nEpoch 48/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.8103\nEpoch 48: val_loss did not improve from 5.19066\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 5.8201 - val_loss: 5.8152\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.6004\nEpoch 49: val_loss improved from 5.19066 to 4.79511, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 6.5914 - val_loss: 4.7951\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.4510\nEpoch 50: val_loss did not improve from 4.79511\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 4.4482 - val_loss: 5.2181\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n2025/02/20 08:15:43 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpy6er0e_3/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n2025/02/20 08:15:50 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 08:15:58 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpsn7_f5m0/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 08:15:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run zealous-mouse-166 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/a91f123bc2d14aa498b00b1ac539172f\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 42  62  71 155 166 190  22 183 174 139 112 148 100  45 106  49  94  66\n  68  54  51  41 152  36  40]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 4 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      4     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807   120    32     0     2     0  ...    37   354    15     0     0     1     0\n2.0      0   162   364    25     0     2     0  ...    17   184    25     0     0     0     0\n3.0      0    38    73   102     1     0     0  ...     1     4     2     0     0     0     0\n4.0      1     0     9    14   409     1     0  ...     7    12     4     0     3     1     0\n5.0      0     5     0     2     3   646     0  ...     1     2     0     0     2    32     0\n6.0      0     0     0     2     1     0     0  ...     1     2     0     0     0     0     0\n7.0      0     0     0     0    10     0     0  ...     0     1     0     0     0     0     0\n8.0      0    15     0     0     0     2     0  ...     0     0     0     1     2     0     0\n9.0      0    79    37     5     0     4     0  ...   322   446    31     0     0     0     0\n10.0     0   246    83    17    10    10     0  ...   121  1821    17     0     1     2     0\n11.0     0    45    63    19     2     3     0  ...    26   123   285     0     0     1     0\n12.0     0     7     0     0     0     1     0  ...     0     0     0   188     0     0     0\n13.0     0     0     0     0    15     1     0  ...     0     0     1     9  1119    57     0\n14.0     1    29    11     4    32    23     0  ...     1     0     1    24    66   166     0\n15.0     0    12     5     0     0     0     0  ...     0     0     1     0     0     0    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807    22     5     2     4     0  ...   109   400     4     0     0     0     3\n2.0      0    27   474    25     0     0     0  ...     1   254    13     0     0     0     0\n3.0      0    10    35   158     0    12     1  ...     2     3     0     0     0     0     0\n4.0      0     2     0     5   423    15     1  ...     0     5     1     0     7     0     0\n5.0      0     0     0     0     4   648     0  ...     0     1     0     0     1    35     0\n6.0      0     0     0     0     1     0    22  ...     0     0     0     0     0     0     0\n7.0      3     0     0     0     0     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0   154     1     2    12     2     0  ...   488   261     9     0     0     0     0\n10.0     0   176    65    13     8    13     1  ...    55  1948    36     0     0     5     0\n11.0     0    28    55    21     0     5     0  ...     3    47   404     0     0     1     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    22     4     0  ...     0     0     0     2  1130    49     0\n14.0     0     0     0     2    36    49     0  ...     1     0     0    31    79   168     1\n15.0     0     1     0     0     0     0     0  ...     3     6     2     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     13     0     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   785    33    24     3     5     0  ...    63   401    28     0     0     2     1\n2.0      0   119   328    17     0     3     0  ...    32   223    72     0     0     0     0\n3.0      0    61    10    54     1    28     0  ...     5    39    29     0     0     0     0\n4.0      8     1     0     3   395     9     0  ...     0     4     5     0    21     9     0\n5.0      0     0     0     2    10   631     0  ...     2     3     0     1    15    31     0\n6.0      1     0     0     0     5     0    10  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     0     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     5     0  ...     0     0     0     1     0     2     0\n9.0      0    91    18     3    11     2     0  ...   183   605    11     0     0     1     0\n10.0     0   227    77    14     9    11     1  ...   101  1793    80     0     0    13     4\n11.0     0   163    28    17     0     9     0  ...    14   110   214     0     0     1     0\n12.0     0     0     0     1     0     1     0  ...     0     0     0   185     0     6     0\n13.0     0     0     0     0    19     2     0  ...     0     0     0     4  1161    18     0\n14.0     1     2     0     1    18    79     0  ...     1     1     4    13   116   125     1\n15.0     0     1     7     0     0     1     0  ...     1     5     2     0     0     1    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     25     0     0     0     0     0     0  ...     0     0     1     0     0     0     0\n1.0      0   910    34    26     2     0     1  ...    97   269    12     1     0     1     0\n2.0      0    97   487    18     0     0     0  ...    18   162    14     0     0     0     0\n3.0      3     8    50   121     0     2     0  ...     6    21    13     0     0     5     0\n4.0     13     0     0     4   362    20     1  ...    10     3     7     0    10    32     0\n5.0      0     0     0    17     5   611     0  ...     5    21     0     0     1    35     0\n6.0      3     0     0     0     0     0    15  ...     0     0     0     0     0     0     0\n7.0     21     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     3     0  ...     0     1     0     1     0    14     0\n9.0      0    93     8     0     0     1     0  ...   694   104    17     0     0     0     0\n10.0     0   215    91     2     1     0     0  ...   221  1753    37     0     0    10     0\n11.0     0    39    37     3     0     0     0  ...    33    52   394     0     0     2     0\n12.0     0     0     0     0     0     0     0  ...     0     2     0   190     0     0     0\n13.0     0     0     0     0    34     1     0  ...     0     0     0     2  1137    28     0\n14.0     0     1     0     0    13    35     0  ...     4     3     3    21    98   186     0\n15.0     0     8     0     0     0     0     0  ...     5     3     1     0     0     0    70\n\n[16 rows x 16 columns]\n View run peaceful-rook-774 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/6347fa32209b49b78952094696d9f06a\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results3.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.692513          0.573164           0.644891\n1    2          0.762247          0.732325           0.726264\n2    3          0.658724          0.602521           0.603915\n3    4          0.758550          0.689539           0.724014\n\nAverage Performance Over 4 Runs:\nOverall Accuracy: 0.7180\nAverage Accuracy: 0.6494\nKappa Coefficient: 0.6748\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_4 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 34.7961\nEpoch 1: val_loss improved from inf to 32.51965, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 34.7511 - val_loss: 32.5196\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 27.7845\nEpoch 2: val_loss improved from 32.51965 to 31.27297, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 27.7773 - val_loss: 31.2730\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 26.6051\nEpoch 3: val_loss improved from 31.27297 to 28.50010, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 26.5909 - val_loss: 28.5001\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.6901\nEpoch 4: val_loss improved from 28.50010 to 25.97332, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 25.6775 - val_loss: 25.9733\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.4936\nEpoch 5: val_loss improved from 25.97332 to 25.27681, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 24.4930 - val_loss: 25.2768\nEpoch 6/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23.7160\nEpoch 6: val_loss did not improve from 25.27681\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 23.7198 - val_loss: 28.3519\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23.3288\nEpoch 7: val_loss improved from 25.27681 to 24.45802, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 23.3262 - val_loss: 24.4580\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.8150\nEpoch 8: val_loss improved from 24.45802 to 22.93473, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 22.8073 - val_loss: 22.9347\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 22.5234\nEpoch 9: val_loss improved from 22.93473 to 21.68092, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 22.5486 - val_loss: 21.6809\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.0876\nEpoch 10: val_loss did not improve from 21.68092\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 22.1180 - val_loss: 26.7673\nEpoch 11/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24.1735\nEpoch 11: val_loss did not improve from 21.68092\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 24.1746 - val_loss: 22.9223\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 26.0326\nEpoch 12: val_loss improved from 21.68092 to 18.85341, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 26.0206 - val_loss: 18.8534\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18.8317\nEpoch 13: val_loss improved from 18.85341 to 18.41088, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 18.8389 - val_loss: 18.4109\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18.1941\nEpoch 14: val_loss improved from 18.41088 to 17.24203, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 18.2002 - val_loss: 17.2420\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 17.0761\nEpoch 15: val_loss improved from 17.24203 to 16.49190, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 17.0793 - val_loss: 16.4919\nEpoch 16/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 16.4298\nEpoch 16: val_loss improved from 16.49190 to 15.65657, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 16.4332 - val_loss: 15.6566\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.6277\nEpoch 17: val_loss improved from 15.65657 to 15.18581, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 15.6274 - val_loss: 15.1858\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.9512\nEpoch 18: val_loss improved from 15.18581 to 15.10944, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 14.9476 - val_loss: 15.1094\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.5006\nEpoch 19: val_loss did not improve from 15.10944\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 14.4953 - val_loss: 16.0375\nEpoch 20/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.4938\nEpoch 20: val_loss did not improve from 15.10944\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 14.4907 - val_loss: 18.8418\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.3726\nEpoch 21: val_loss did not improve from 15.10944\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 14.3579 - val_loss: 17.1268\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.4543\nEpoch 22: val_loss improved from 15.10944 to 14.75201, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 14.4462 - val_loss: 14.7520\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.2392\nEpoch 23: val_loss improved from 14.75201 to 12.47233, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 13.2497 - val_loss: 12.4723\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.7679\nEpoch 24: val_loss did not improve from 12.47233\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 12.7748 - val_loss: 12.7514\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 11.6326\nEpoch 25: val_loss improved from 12.47233 to 12.00260, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 11.6295 - val_loss: 12.0026\nEpoch 26/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.1671\nEpoch 26: val_loss improved from 12.00260 to 11.47907, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 11.1610 - val_loss: 11.4791\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.6370\nEpoch 27: val_loss did not improve from 11.47907\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 10.6303 - val_loss: 12.0104\nEpoch 28/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10.5326\nEpoch 28: val_loss did not improve from 11.47907\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 10.5294 - val_loss: 14.2378\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 11.0906\nEpoch 29: val_loss did not improve from 11.47907\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 11.0718 - val_loss: 13.6877\nEpoch 30/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.6506\nEpoch 30: val_loss improved from 11.47907 to 10.64275, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 10.6541 - val_loss: 10.6428\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.0679\nEpoch 31: val_loss did not improve from 10.64275\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 10.0588 - val_loss: 10.8768\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.1061\nEpoch 32: val_loss improved from 10.64275 to 8.97001, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 10.0864 - val_loss: 8.9700\nEpoch 33/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.5085\nEpoch 33: val_loss improved from 8.97001 to 8.78157, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 8.5071 - val_loss: 8.7816\nEpoch 34/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.0129\nEpoch 34: val_loss improved from 8.78157 to 8.41433, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 8.0129 - val_loss: 8.4143\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.1792\nEpoch 35: val_loss did not improve from 8.41433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.1816 - val_loss: 9.4667\nEpoch 36/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.3414\nEpoch 36: val_loss did not improve from 8.41433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.3575 - val_loss: 18.5097\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.0030\nEpoch 37: val_loss did not improve from 8.41433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 10.9769 - val_loss: 9.3853\nEpoch 38/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.0273\nEpoch 38: val_loss did not improve from 8.41433\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 9.0356 - val_loss: 9.9630\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.1417\nEpoch 39: val_loss improved from 8.41433 to 8.02539, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 8.1441 - val_loss: 8.0254\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.0999\nEpoch 40: val_loss improved from 8.02539 to 6.61366, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 7.0921 - val_loss: 6.6137\nEpoch 41/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.4126\nEpoch 41: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 6.4341 - val_loss: 10.7797\nEpoch 42/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.0783\nEpoch 42: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 8.0511 - val_loss: 7.1838\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.6451\nEpoch 43: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 6.6699 - val_loss: 7.8792\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.0998\nEpoch 44: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 7.1020 - val_loss: 9.7713\nEpoch 45/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.4226\nEpoch 45: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 7.4142 - val_loss: 9.3598\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.0667\nEpoch 46: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.0524 - val_loss: 7.1763\nEpoch 47/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.2592\nEpoch 47: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 6.2730 - val_loss: 6.8878\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.0665\nEpoch 48: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 6.0948 - val_loss: 12.7828\nEpoch 49/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.9082\nEpoch 49: val_loss did not improve from 6.61366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.8983 - val_loss: 6.9925\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.2346\nEpoch 50: val_loss improved from 6.61366 to 6.28121, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 6.2380 - val_loss: 6.2812\nWARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79d19b298a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79d19b298a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n2025/02/20 08:19:45 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpdiyl98or/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n2025/02/20 08:19:52 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 08:20:00 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpp0bnqfuv/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 08:20:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run redolent-turtle-350 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/b66dc262c20c436a95043f6ba4df6e10\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nWARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x79d1f2c0b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x79d1f2c0b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nSelected number of bands:  25\n======Selected band indices ======= \n [120 183 161 128  64 178  43 106  13  70  46  98  69 132 147  51  72  49\n  58  62  63  92  66 188  68]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'kernel': 'rbf'}\nThe model shall evaluate for 5 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      4     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807   120    32     0     2     0  ...    37   354    15     0     0     1     0\n2.0      0   162   364    25     0     2     0  ...    17   184    25     0     0     0     0\n3.0      0    38    73   102     1     0     0  ...     1     4     2     0     0     0     0\n4.0      1     0     9    14   409     1     0  ...     7    12     4     0     3     1     0\n5.0      0     5     0     2     3   646     0  ...     1     2     0     0     2    32     0\n6.0      0     0     0     2     1     0     0  ...     1     2     0     0     0     0     0\n7.0      0     0     0     0    10     0     0  ...     0     1     0     0     0     0     0\n8.0      0    15     0     0     0     2     0  ...     0     0     0     1     2     0     0\n9.0      0    79    37     5     0     4     0  ...   322   446    31     0     0     0     0\n10.0     0   246    83    17    10    10     0  ...   121  1821    17     0     1     2     0\n11.0     0    45    63    19     2     3     0  ...    26   123   285     0     0     1     0\n12.0     0     7     0     0     0     1     0  ...     0     0     0   188     0     0     0\n13.0     0     0     0     0    15     1     0  ...     0     0     1     9  1119    57     0\n14.0     1    29    11     4    32    23     0  ...     1     0     1    24    66   166     0\n15.0     0    12     5     0     0     0     0  ...     0     0     1     0     0     0    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807    22     5     2     4     0  ...   109   400     4     0     0     0     3\n2.0      0    27   474    25     0     0     0  ...     1   254    13     0     0     0     0\n3.0      0    10    35   158     0    12     1  ...     2     3     0     0     0     0     0\n4.0      0     2     0     5   423    15     1  ...     0     5     1     0     7     0     0\n5.0      0     0     0     0     4   648     0  ...     0     1     0     0     1    35     0\n6.0      0     0     0     0     1     0    22  ...     0     0     0     0     0     0     0\n7.0      3     0     0     0     0     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0   154     1     2    12     2     0  ...   488   261     9     0     0     0     0\n10.0     0   176    65    13     8    13     1  ...    55  1948    36     0     0     5     0\n11.0     0    28    55    21     0     5     0  ...     3    47   404     0     0     1     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    22     4     0  ...     0     0     0     2  1130    49     0\n14.0     0     0     0     2    36    49     0  ...     1     0     0    31    79   168     1\n15.0     0     1     0     0     0     0     0  ...     3     6     2     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     13     0     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   785    33    24     3     5     0  ...    63   401    28     0     0     2     1\n2.0      0   119   328    17     0     3     0  ...    32   223    72     0     0     0     0\n3.0      0    61    10    54     1    28     0  ...     5    39    29     0     0     0     0\n4.0      8     1     0     3   395     9     0  ...     0     4     5     0    21     9     0\n5.0      0     0     0     2    10   631     0  ...     2     3     0     1    15    31     0\n6.0      1     0     0     0     5     0    10  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     0     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     5     0  ...     0     0     0     1     0     2     0\n9.0      0    91    18     3    11     2     0  ...   183   605    11     0     0     1     0\n10.0     0   227    77    14     9    11     1  ...   101  1793    80     0     0    13     4\n11.0     0   163    28    17     0     9     0  ...    14   110   214     0     0     1     0\n12.0     0     0     0     1     0     1     0  ...     0     0     0   185     0     6     0\n13.0     0     0     0     0    19     2     0  ...     0     0     0     4  1161    18     0\n14.0     1     2     0     1    18    79     0  ...     1     1     4    13   116   125     1\n15.0     0     1     7     0     0     1     0  ...     1     5     2     0     0     1    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     25     0     0     0     0     0     0  ...     0     0     1     0     0     0     0\n1.0      0   910    34    26     2     0     1  ...    97   269    12     1     0     1     0\n2.0      0    97   487    18     0     0     0  ...    18   162    14     0     0     0     0\n3.0      3     8    50   121     0     2     0  ...     6    21    13     0     0     5     0\n4.0     13     0     0     4   362    20     1  ...    10     3     7     0    10    32     0\n5.0      0     0     0    17     5   611     0  ...     5    21     0     0     1    35     0\n6.0      3     0     0     0     0     0    15  ...     0     0     0     0     0     0     0\n7.0     21     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     3     0  ...     0     1     0     1     0    14     0\n9.0      0    93     8     0     0     1     0  ...   694   104    17     0     0     0     0\n10.0     0   215    91     2     1     0     0  ...   221  1753    37     0     0    10     0\n11.0     0    39    37     3     0     0     0  ...    33    52   394     0     0     2     0\n12.0     0     0     0     0     0     0     0  ...     0     2     0   190     0     0     0\n13.0     0     0     0     0    34     1     0  ...     0     0     0     2  1137    28     0\n14.0     0     1     0     0    13    35     0  ...     4     3     3    21    98   186     0\n15.0     0     8     0     0     0     0     0  ...     5     3     1     0     0     0    70\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     25     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   938    26    25     3     2     0  ...    96   219    41     0     0     0     0\n2.0      0    43   473    28     1     1     0  ...    14   161    69     0     0     0     0\n3.0      0    34    40    76     8    13     0  ...     5    32    18     0     0     0     0\n4.0     10     0     0     8   403     9     1  ...     2     2     7     0    10     2     0\n5.0      0     0     0     0    14   655     0  ...     0     8     0     0     8     8     0\n6.0      1     0     0     0     0     0    19  ...     0     0     0     0     0     0     0\n7.0     22     0     0     1     1     0    52  ...     6     0     0     0     0     0     0\n8.0      0     0     0     0     0     3     0  ...     0     0     0     0     0     0     0\n9.0      1   131    16    14     2     3     0  ...   577   178    11     0     0     0     0\n10.0     1   275    93    11     7     8     1  ...    95  1769    47     0     0     1     0\n11.0     0    34    53    18     2     2     0  ...    16    49   384     0     0     0     0\n12.0     0     0     0     0     0    16     0  ...     0     1     0   179     0     0     0\n13.0     0     0     0     0    31    11     0  ...     0     3     0     3  1114    41     0\n14.0     0     3     0     2    31   112     0  ...     0    11     2    28    85    94     0\n15.0     0     4     4     0     1     0     0  ...     4     5    10     0     0     0    61\n\n[16 rows x 16 columns]\n View run thoughtful-gnu-585 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/7e5981a99fb44d278315f91d7c21a13a\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results4.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.692513          0.573164           0.644891\n1    2          0.762247          0.732325           0.726264\n2    3          0.658724          0.602521           0.603915\n3    4          0.758550          0.689539           0.724014\n4    5          0.735750          0.703752           0.697943\n\nAverage Performance Over 5 Runs:\nOverall Accuracy: 0.7216\nAverage Accuracy: 0.6603\nKappa Coefficient: 0.6794\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_5 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 45.7480\nEpoch 1: val_loss improved from inf to 25.97880, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - loss: 45.5240 - val_loss: 25.9788\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25.7866\nEpoch 2: val_loss improved from 25.97880 to 24.78284, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 25.7840 - val_loss: 24.7828\nEpoch 3/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 24.8213\nEpoch 3: val_loss improved from 24.78284 to 24.22105, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 24.8171 - val_loss: 24.2210\nEpoch 4/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24.0128\nEpoch 4: val_loss improved from 24.22105 to 23.02879, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 24.0086 - val_loss: 23.0288\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 23.2749\nEpoch 5: val_loss did not improve from 23.02879\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 23.2827 - val_loss: 30.5161\nEpoch 6/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 30.9851\nEpoch 6: val_loss did not improve from 23.02879\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 31.0335 - val_loss: 24.4146\nEpoch 7/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 25.4884\nEpoch 7: val_loss improved from 23.02879 to 21.20369, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 25.4788 - val_loss: 21.2037\nEpoch 8/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 21.3839\nEpoch 8: val_loss improved from 21.20369 to 20.40245, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 21.3786 - val_loss: 20.4024\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20.4652\nEpoch 9: val_loss improved from 20.40245 to 19.51162, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 20.4570 - val_loss: 19.5116\nEpoch 10/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 19.5649\nEpoch 10: val_loss improved from 19.51162 to 19.21368, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 19.5631 - val_loss: 19.2137\nEpoch 11/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 18.9006\nEpoch 11: val_loss improved from 19.21368 to 18.28350, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 18.8976 - val_loss: 18.2835\nEpoch 12/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.0922\nEpoch 12: val_loss improved from 18.28350 to 17.55542, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 18.0880 - val_loss: 17.5554\nEpoch 13/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17.3761\nEpoch 13: val_loss improved from 17.55542 to 16.55915, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 17.3771 - val_loss: 16.5591\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 16.8099\nEpoch 14: val_loss did not improve from 16.55915\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 16.8652 - val_loss: 37.8800\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 27.8037\nEpoch 15: val_loss did not improve from 16.55915\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 27.6918 - val_loss: 17.3544\nEpoch 16/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.8251\nEpoch 16: val_loss improved from 16.55915 to 15.50340, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 18.8201 - val_loss: 15.5034\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 15.8616\nEpoch 17: val_loss improved from 15.50340 to 14.49141, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 15.8490 - val_loss: 14.4914\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.6100\nEpoch 18: val_loss improved from 14.49141 to 13.75304, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 14.6050 - val_loss: 13.7530\nEpoch 19/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13.8611\nEpoch 19: val_loss improved from 13.75304 to 13.28921, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 13.8596 - val_loss: 13.2892\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13.0821\nEpoch 20: val_loss improved from 13.28921 to 12.74297, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 13.0788 - val_loss: 12.7430\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.4864\nEpoch 21: val_loss improved from 12.74297 to 11.92174, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 12.4836 - val_loss: 11.9217\nEpoch 22/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.9756\nEpoch 22: val_loss improved from 11.92174 to 11.66687, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 11.9721 - val_loss: 11.6669\nEpoch 23/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 11.5747\nEpoch 23: val_loss did not improve from 11.66687\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 11.5965 - val_loss: 19.6844\nEpoch 24/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.2571\nEpoch 24: val_loss did not improve from 11.66687\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 18.2501 - val_loss: 15.3886\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13.8368\nEpoch 25: val_loss improved from 11.66687 to 11.33516, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 13.8179 - val_loss: 11.3352\nEpoch 26/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.7134\nEpoch 26: val_loss improved from 11.33516 to 10.12238, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 10.7090 - val_loss: 10.1224\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.8827\nEpoch 27: val_loss improved from 10.12238 to 9.93773, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 9.8814 - val_loss: 9.9377\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.6046\nEpoch 28: val_loss improved from 9.93773 to 9.07744, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 9.6068 - val_loss: 9.0774\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.9256\nEpoch 29: val_loss improved from 9.07744 to 8.59510, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 8.9261 - val_loss: 8.5951\nEpoch 30/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.4650\nEpoch 30: val_loss did not improve from 8.59510\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.4663 - val_loss: 8.8193\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.5984\nEpoch 31: val_loss did not improve from 8.59510\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.6044 - val_loss: 11.1784\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.3300\nEpoch 32: val_loss did not improve from 8.59510\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 10.3873 - val_loss: 17.4211\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.3218\nEpoch 33: val_loss did not improve from 8.59510\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 12.3097 - val_loss: 14.9074\nEpoch 34/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2460\nEpoch 34: val_loss improved from 8.59510 to 7.57646, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 10.2208 - val_loss: 7.5765\nEpoch 35/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2782\nEpoch 35: val_loss did not improve from 7.57646\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 7.2828 - val_loss: 9.3998\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.0675\nEpoch 36: val_loss improved from 7.57646 to 7.02979, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 8.0672 - val_loss: 7.0298\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.6913\nEpoch 37: val_loss did not improve from 7.02979\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 6.7077 - val_loss: 10.6509\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.8387\nEpoch 38: val_loss did not improve from 7.02979\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.8422 - val_loss: 9.2819\nEpoch 39/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.8643\nEpoch 39: val_loss did not improve from 7.02979\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 7.8750 - val_loss: 15.0781\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.8400\nEpoch 40: val_loss did not improve from 7.02979\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 9.8085 - val_loss: 7.7164\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.9070\nEpoch 41: val_loss did not improve from 7.02979\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 6.9063 - val_loss: 7.6222\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.0553\nEpoch 42: val_loss improved from 7.02979 to 5.39111, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 6.0472 - val_loss: 5.3911\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.2786\nEpoch 43: val_loss improved from 5.39111 to 4.91555, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 5.2775 - val_loss: 4.9156\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.1894\nEpoch 44: val_loss did not improve from 4.91555\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 5.2315 - val_loss: 15.1840\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 13.2136\nEpoch 45: val_loss did not improve from 4.91555\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 13.1870 - val_loss: 8.7728\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.5021\nEpoch 46: val_loss did not improve from 4.91555\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 8.4611 - val_loss: 6.5142\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.5376\nEpoch 47: val_loss did not improve from 4.91555\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 5.5279 - val_loss: 5.3568\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.6776\nEpoch 48: val_loss improved from 4.91555 to 4.30218, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 4.6750 - val_loss: 4.3022\nEpoch 49/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2847\nEpoch 49: val_loss did not improve from 4.30218\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 4.3038 - val_loss: 7.3385\nEpoch 50/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.1204\nEpoch 50: val_loss did not improve from 4.30218\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 7.1306 - val_loss: 15.3510\nWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79d19b1953a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79d19b1953a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n2025/02/20 08:23:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpw3or0t3n/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n2025/02/20 08:23:58 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 08:24:07 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpnb83cqcf/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 08:24:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run wise-skunk-154 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/d6d4ff2481c34aac97cc5598d2a76cf2\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nWARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x79d1f2c362a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x79d1f2c362a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nSelected number of bands:  25\n======Selected band indices ======= \n [112  23  49 161  29 157 164  18 154 186 178  69 122 175 168  58  64  41\n 132  38  40  65  52  57  42]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 6 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      4     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807   120    32     0     2     0  ...    37   354    15     0     0     1     0\n2.0      0   162   364    25     0     2     0  ...    17   184    25     0     0     0     0\n3.0      0    38    73   102     1     0     0  ...     1     4     2     0     0     0     0\n4.0      1     0     9    14   409     1     0  ...     7    12     4     0     3     1     0\n5.0      0     5     0     2     3   646     0  ...     1     2     0     0     2    32     0\n6.0      0     0     0     2     1     0     0  ...     1     2     0     0     0     0     0\n7.0      0     0     0     0    10     0     0  ...     0     1     0     0     0     0     0\n8.0      0    15     0     0     0     2     0  ...     0     0     0     1     2     0     0\n9.0      0    79    37     5     0     4     0  ...   322   446    31     0     0     0     0\n10.0     0   246    83    17    10    10     0  ...   121  1821    17     0     1     2     0\n11.0     0    45    63    19     2     3     0  ...    26   123   285     0     0     1     0\n12.0     0     7     0     0     0     1     0  ...     0     0     0   188     0     0     0\n13.0     0     0     0     0    15     1     0  ...     0     0     1     9  1119    57     0\n14.0     1    29    11     4    32    23     0  ...     1     0     1    24    66   166     0\n15.0     0    12     5     0     0     0     0  ...     0     0     1     0     0     0    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   807    22     5     2     4     0  ...   109   400     4     0     0     0     3\n2.0      0    27   474    25     0     0     0  ...     1   254    13     0     0     0     0\n3.0      0    10    35   158     0    12     1  ...     2     3     0     0     0     0     0\n4.0      0     2     0     5   423    15     1  ...     0     5     1     0     7     0     0\n5.0      0     0     0     0     4   648     0  ...     0     1     0     0     1    35     0\n6.0      0     0     0     0     1     0    22  ...     0     0     0     0     0     0     0\n7.0      3     0     0     0     0     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    14     0  ...     0     0     0     3     0     2     0\n9.0      0   154     1     2    12     2     0  ...   488   261     9     0     0     0     0\n10.0     0   176    65    13     8    13     1  ...    55  1948    36     0     0     5     0\n11.0     0    28    55    21     0     5     0  ...     3    47   404     0     0     1     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    22     4     0  ...     0     0     0     2  1130    49     0\n14.0     0     0     0     2    36    49     0  ...     1     0     0    31    79   168     1\n15.0     0     1     0     0     0     0     0  ...     3     6     2     0     0     0    76\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     13     0     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   785    33    24     3     5     0  ...    63   401    28     0     0     2     1\n2.0      0   119   328    17     0     3     0  ...    32   223    72     0     0     0     0\n3.0      0    61    10    54     1    28     0  ...     5    39    29     0     0     0     0\n4.0      8     1     0     3   395     9     0  ...     0     4     5     0    21     9     0\n5.0      0     0     0     2    10   631     0  ...     2     3     0     1    15    31     0\n6.0      1     0     0     0     5     0    10  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     0     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     5     0  ...     0     0     0     1     0     2     0\n9.0      0    91    18     3    11     2     0  ...   183   605    11     0     0     1     0\n10.0     0   227    77    14     9    11     1  ...   101  1793    80     0     0    13     4\n11.0     0   163    28    17     0     9     0  ...    14   110   214     0     0     1     0\n12.0     0     0     0     1     0     1     0  ...     0     0     0   185     0     6     0\n13.0     0     0     0     0    19     2     0  ...     0     0     0     4  1161    18     0\n14.0     1     2     0     1    18    79     0  ...     1     1     4    13   116   125     1\n15.0     0     1     7     0     0     1     0  ...     1     5     2     0     0     1    69\n\n[16 rows x 16 columns]\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     25     0     0     0     0     0     0  ...     0     0     1     0     0     0     0\n1.0      0   910    34    26     2     0     1  ...    97   269    12     1     0     1     0\n2.0      0    97   487    18     0     0     0  ...    18   162    14     0     0     0     0\n3.0      3     8    50   121     0     2     0  ...     6    21    13     0     0     5     0\n4.0     13     0     0     4   362    20     1  ...    10     3     7     0    10    32     0\n5.0      0     0     0    17     5   611     0  ...     5    21     0     0     1    35     0\n6.0      3     0     0     0     0     0    15  ...     0     0     0     0     0     0     0\n7.0     21     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     3     0  ...     0     1     0     1     0    14     0\n9.0      0    93     8     0     0     1     0  ...   694   104    17     0     0     0     0\n10.0     0   215    91     2     1     0     0  ...   221  1753    37     0     0    10     0\n11.0     0    39    37     3     0     0     0  ...    33    52   394     0     0     2     0\n12.0     0     0     0     0     0     0     0  ...     0     2     0   190     0     0     0\n13.0     0     0     0     0    34     1     0  ...     0     0     0     2  1137    28     0\n14.0     0     1     0     0    13    35     0  ...     4     3     3    21    98   186     0\n15.0     0     8     0     0     0     0     0  ...     5     3     1     0     0     0    70\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     25     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   938    26    25     3     2     0  ...    96   219    41     0     0     0     0\n2.0      0    43   473    28     1     1     0  ...    14   161    69     0     0     0     0\n3.0      0    34    40    76     8    13     0  ...     5    32    18     0     0     0     0\n4.0     10     0     0     8   403     9     1  ...     2     2     7     0    10     2     0\n5.0      0     0     0     0    14   655     0  ...     0     8     0     0     8     8     0\n6.0      1     0     0     0     0     0    19  ...     0     0     0     0     0     0     0\n7.0     22     0     0     1     1     0    52  ...     6     0     0     0     0     0     0\n8.0      0     0     0     0     0     3     0  ...     0     0     0     0     0     0     0\n9.0      1   131    16    14     2     3     0  ...   577   178    11     0     0     0     0\n10.0     1   275    93    11     7     8     1  ...    95  1769    47     0     0     1     0\n11.0     0    34    53    18     2     2     0  ...    16    49   384     0     0     0     0\n12.0     0     0     0     0     0    16     0  ...     0     1     0   179     0     0     0\n13.0     0     0     0     0    31    11     0  ...     0     3     0     3  1114    41     0\n14.0     0     3     0     2    31   112     0  ...     0    11     2    28    85    94     0\n15.0     0     4     4     0     1     0     0  ...     4     5    10     0     0     0    61\n\n[16 rows x 16 columns]\n\nConfusion Matrix for Run 6:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     40     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n1.0      0   934    21     8     2     8     0  ...   134   249     1     0     0     0     0\n2.0      0    76   482    34     0     0     0  ...     8   160    32     0     0     0     0\n3.0      0    50    27   129     0     9     2  ...     1     5     0     0     0     0     0\n4.0      6     0     0     5   405     7     7  ...     4     6     2     0    16     0     0\n5.0      0     0     0     1     2   672     0  ...     0     1     0     1     4     9     0\n6.0      0     0     0     0     1     0    21  ...     0     0     0     0     0     0     0\n7.0     22     0     0     0     2     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     4     0  ...     0     0     0     0     0     0     0\n9.0      0    66     4     3     0    13     0  ...   551   284     6     0     0     0     0\n10.0     0   193   105    18     5    21     4  ...   112  1830    32     0     0     4     1\n11.0     0    33    26    39     0    16     0  ...    15    63   376     0     0     1     0\n12.0     0     0     0     1     0     3     0  ...     0     0     0   146     0    32     0\n13.0     0     0     0     0    28     9     0  ...     0     2     0     1  1148    12     0\n14.0     0     0     0     1    19    58     1  ...     0    17     0     5   112   150     0\n15.0     0     0     2     0     0     3     0  ...     7     2     3     0     0     0    73\n\n[16 rows x 16 columns]\n View run brawny-sheep-506 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/0b8ccf40e25e43008e3463d1d129a450\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results5.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.692513          0.573164           0.644891\n1    2          0.762247          0.732325           0.726264\n2    3          0.658724          0.602521           0.603915\n3    4          0.758550          0.689539           0.724014\n4    5          0.735750          0.703752           0.697943\n5    6          0.760193          0.763618           0.724874\n\nAverage Performance Over 6 Runs:\nOverall Accuracy: 0.7280\nAverage Accuracy: 0.6775\nKappa Coefficient: 0.6870\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"## Single layer OG","metadata":{}},{"cell_type":"code","source":"%cd ..\n!rm -r SRL-SOA\n!git clone https://github.com/vidhi-gajra-git/SRL-SOA.git\n%cd SRL-SOA\n!mkdir data \n!mkdir results \n!cp /kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/*.mat data/\n\n\n%matplotlib inline\n!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n\n\n#Single layer original q=1->q\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T12:01:02.688372Z","iopub.execute_input":"2025-02-20T12:01:02.688947Z","execution_failed":"2025-02-20T13:12:38.896Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'SRL-SOA'...\nremote: Enumerating objects: 851, done.\u001b[K\nremote: Counting objects: 100% (94/94), done.\u001b[K\nremote: Compressing objects: 100% (63/63), done.\u001b[K\nremote: Total 851 (delta 68), reused 31 (delta 31), pack-reused 757 (from 3)\u001b[K\nReceiving objects: 100% (851/851), 1.12 MiB | 15.44 MiB/s, done.\nResolving deltas: 100% (538/538), done.\n/kaggle/working/SRL-SOA\n2025-02-20 12:01:04.701382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1740052864.730901    3011 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1740052864.740371    3011 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAccessing as vidhi-gajra-git\nInitialized MLflow to track repo \u001b[32m\"vidhi-gajra-git/SRL_SOA\"\u001b[0m\nRepository vidhi-gajra-git/SRL_SOA initialized!\n\nScene:  (145, 145, 200)\n\nClassification:\nTraining samples:  512\nTest samples:  9737\n\n\nNumber of bands:  200\n**********  METHOD : SVM **********\n\t\t\t\t\t *****  #RUNS : 6  *****\n2025-02-20 12:01:13.634935: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n Oper1D (\u001b[94mOper1D\u001b[0m)            (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot (\u001b[94mDot\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  Oper1D[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],          \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.6275\nEpoch 1: val_loss improved from inf to 95.92702, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 14.9257 - val_loss: 95.9270\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0770\nEpoch 2: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0701 - val_loss: 95.9270\nEpoch 3/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6382\nEpoch 3: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6355 - val_loss: 95.9270\nEpoch 4/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4820\nEpoch 4: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4802 - val_loss: 95.9270\nEpoch 5/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2919\nEpoch 5: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2918 - val_loss: 95.9270\nEpoch 6/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1215\nEpoch 6: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1232 - val_loss: 95.9270\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9792\nEpoch 7: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9803 - val_loss: 95.9270\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9306\nEpoch 8: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9302 - val_loss: 95.9270\nEpoch 9/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8272\nEpoch 9: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8276 - val_loss: 95.9270\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8243\nEpoch 10: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8247 - val_loss: 95.9270\nEpoch 11/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7649\nEpoch 11: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7660 - val_loss: 95.9270\nEpoch 12/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7415\nEpoch 12: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7441 - val_loss: 95.9270\nEpoch 13/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7584\nEpoch 13: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7627 - val_loss: 95.9270\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8149\nEpoch 14: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8202 - val_loss: 95.9270\nEpoch 15/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0402\nEpoch 15: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0350 - val_loss: 95.9270\nEpoch 16/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0181\nEpoch 16: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0450 - val_loss: 95.9270\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7932\nEpoch 17: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7866 - val_loss: 95.9270\nEpoch 18/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1114\nEpoch 18: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1390 - val_loss: 95.9270\nEpoch 19/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6241\nEpoch 19: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.6277 - val_loss: 95.9270\nEpoch 20/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1634\nEpoch 20: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.1343 - val_loss: 95.9270\nEpoch 21/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8477\nEpoch 21: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8472 - val_loss: 95.9270\nEpoch 22/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7765\nEpoch 22: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7726 - val_loss: 95.9270\nEpoch 23/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6279\nEpoch 23: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6291 - val_loss: 95.9270\nEpoch 24/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6167\nEpoch 24: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6173 - val_loss: 95.9270\nEpoch 25/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5500\nEpoch 25: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5509 - val_loss: 95.9270\nEpoch 26/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5301\nEpoch 26: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5315 - val_loss: 95.9270\nEpoch 27/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5224\nEpoch 27: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5235 - val_loss: 95.9270\nEpoch 28/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5178\nEpoch 28: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5204 - val_loss: 95.9270\nEpoch 29/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5325\nEpoch 29: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5330 - val_loss: 95.9270\nEpoch 30/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5208\nEpoch 30: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5225 - val_loss: 95.9270\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5938\nEpoch 31: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5950 - val_loss: 95.9270\nEpoch 32/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8542\nEpoch 32: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8715 - val_loss: 95.9270\nEpoch 33/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9696\nEpoch 33: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0343 - val_loss: 95.9270\nEpoch 34/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1599\nEpoch 34: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.0059 - val_loss: 95.9270\nEpoch 35/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9676\nEpoch 35: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9548 - val_loss: 95.9270\nEpoch 36/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5702\nEpoch 36: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5722 - val_loss: 95.9270\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5131\nEpoch 37: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5141 - val_loss: 95.9270\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5127\nEpoch 38: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5142 - val_loss: 95.9270\nEpoch 39/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4914\nEpoch 39: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4937 - val_loss: 95.9270\nEpoch 40/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4647\nEpoch 40: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4675 - val_loss: 95.9270\nEpoch 41/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4484\nEpoch 41: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4517 - val_loss: 95.9270\nEpoch 42/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4448\nEpoch 42: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4455 - val_loss: 95.9270\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4409\nEpoch 43: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4424 - val_loss: 95.9270\nEpoch 44/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4480\nEpoch 44: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4515 - val_loss: 95.9270\nEpoch 45/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5482\nEpoch 45: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5496 - val_loss: 95.9270\nEpoch 46/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7307\nEpoch 46: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7839 - val_loss: 95.9270\nEpoch 47/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3401\nEpoch 47: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.4115 - val_loss: 95.9270\nEpoch 48/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9937\nEpoch 48: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.9700 - val_loss: 95.9270\nEpoch 49/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9942\nEpoch 49: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9863 - val_loss: 95.9270\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6421\nEpoch 50: val_loss did not improve from 95.92702\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6428 - val_loss: 95.9270\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n2025/02/20 12:02:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpcy2136pu/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 12:03:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 12:03:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpddpp3x4m/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 12:03:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run SRL-SOA_run0 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/3dba2a503a45458aa13e847e5f26abe0\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 79  21 119  76 106 149  47  64 116 198 152  75 184  52 172  98 136  10\n 138 124  68  70  46  65 182]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.001, 'kernel': 'rbf'}\nThe model shall evaluate for 1 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   677    10    71     1     3     0  ...   109   478    19     0     0     0     0\n2.0      0    46   391    36     0     0     0  ...    15   239    52     0     0     0     0\n3.0      0    10    24   149     0     8     0  ...     5     9    15     0     0     0     0\n4.0      2     1     0     6   392    13     0  ...     6     1     5     0    14     1     0\n5.0      0     0     0     2    49   597     0  ...     0     1     1     4     3    36     0\n6.0      0     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     2     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     2     0    15     0  ...     0     0     0     3     0     0     0\n9.0      0    78     4     2     1     5     0  ...   503   323     6     0     0     0     0\n10.0     0   154    60    14     4    16     0  ...    71  1952    54     0     0     2     0\n11.0     0    65    90    36     0     3     0  ...    46   164   163     0     0     0     0\n12.0     0     0     0     0     0    12     0  ...     0     0     0   172     0    12     0\n13.0     0     0     0     0    23     7     0  ...     0     0     0     9  1113    48     0\n14.0     0     0     1     0    20    80     0  ...     5     0     6    26    75   144     0\n15.0     0     4     0     0     0     0     0  ...     5     0     0     0     0     0    78\n\n[16 rows x 16 columns]\n View run SRL-SOA_run0 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/3dba2a503a45458aa13e847e5f26abe0\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results0.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.696416          0.571028           0.649053\n/opt/conda/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/opt/conda/lib/python3.12/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n\nAverage Performance Over 1 Runs:\nOverall Accuracy: nan\nAverage Accuracy: nan\nKappa Coefficient: nan\n View run SRL-SOA_run0 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/3dba2a503a45458aa13e847e5f26abe0\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n Oper1D (\u001b[94mOper1D\u001b[0m)            (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_1 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  Oper1D[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],          \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4822\nEpoch 1: val_loss improved from inf to 19.46245, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 7.2256 - val_loss: 19.4624\nEpoch 2/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1327\nEpoch 2: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.1323 - val_loss: 19.4624\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7105\nEpoch 3: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.6810 - val_loss: 19.4624\nEpoch 4/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6386\nEpoch 4: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.5483 - val_loss: 19.4624\nEpoch 5/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7256\nEpoch 5: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7076 - val_loss: 19.4624\nEpoch 6/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7072\nEpoch 6: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6881 - val_loss: 19.4624\nEpoch 7/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3129\nEpoch 7: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2909 - val_loss: 19.4624\nEpoch 8/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0699\nEpoch 8: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0695 - val_loss: 19.4624\nEpoch 9/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2669\nEpoch 9: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2485 - val_loss: 19.4624\nEpoch 10/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0735\nEpoch 10: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0663 - val_loss: 19.4624\nEpoch 11/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3721\nEpoch 11: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3595 - val_loss: 19.4624\nEpoch 12/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0296\nEpoch 12: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0287 - val_loss: 19.4624\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2838\nEpoch 13: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2771 - val_loss: 19.4624\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0466\nEpoch 14: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0451 - val_loss: 19.4624\nEpoch 15/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1873\nEpoch 15: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1834 - val_loss: 19.4624\nEpoch 16/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0331\nEpoch 16: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0321 - val_loss: 19.4624\nEpoch 17/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2924\nEpoch 17: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2900 - val_loss: 19.4624\nEpoch 18/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0724\nEpoch 18: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0713 - val_loss: 19.4624\nEpoch 19/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4227\nEpoch 19: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4171 - val_loss: 19.4624\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3344\nEpoch 20: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3356 - val_loss: 19.4624\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3825\nEpoch 21: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.3620 - val_loss: 19.4624\nEpoch 22/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6950\nEpoch 22: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6724 - val_loss: 19.4624\nEpoch 23/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3329\nEpoch 23: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2671 - val_loss: 19.4624\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1783\nEpoch 24: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1760 - val_loss: 19.4624\nEpoch 25/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8426\nEpoch 25: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.8373 - val_loss: 19.4624\nEpoch 26/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0236\nEpoch 26: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0198 - val_loss: 19.4624\nEpoch 27/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2896\nEpoch 27: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2744 - val_loss: 19.4624\nEpoch 28/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0062\nEpoch 28: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9987 - val_loss: 19.4624\nEpoch 29/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2871\nEpoch 29: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2568 - val_loss: 19.4624\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9968\nEpoch 30: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9966 - val_loss: 19.4624\nEpoch 31/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2695\nEpoch 31: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2665 - val_loss: 19.4624\nEpoch 32/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0705\nEpoch 32: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0706 - val_loss: 19.4624\nEpoch 33/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2883\nEpoch 33: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2812 - val_loss: 19.4624\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9451\nEpoch 34: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9448 - val_loss: 19.4624\nEpoch 35/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1987\nEpoch 35: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1959 - val_loss: 19.4624\nEpoch 36/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9347\nEpoch 36: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9294 - val_loss: 19.4624\nEpoch 37/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0690\nEpoch 37: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0522 - val_loss: 19.4624\nEpoch 38/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9740\nEpoch 38: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9690 - val_loss: 19.4624\nEpoch 39/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9951\nEpoch 39: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9905 - val_loss: 19.4624\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9904\nEpoch 40: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9880 - val_loss: 19.4624\nEpoch 41/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9364\nEpoch 41: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9348 - val_loss: 19.4624\nEpoch 42/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9393\nEpoch 42: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9371 - val_loss: 19.4624\nEpoch 43/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8891\nEpoch 43: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8862 - val_loss: 19.4624\nEpoch 44/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9249\nEpoch 44: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9128 - val_loss: 19.4624\nEpoch 45/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8476\nEpoch 45: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8464 - val_loss: 19.4624\nEpoch 46/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9753\nEpoch 46: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9692 - val_loss: 19.4624\nEpoch 47/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0327\nEpoch 47: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0329 - val_loss: 19.4624\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3235\nEpoch 48: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3176 - val_loss: 19.4624\nEpoch 49/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0268\nEpoch 49: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0253 - val_loss: 19.4624\nEpoch 50/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8617\nEpoch 50: val_loss did not improve from 19.46245\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8638 - val_loss: 19.4624\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n2025/02/20 12:05:03 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp0nui6ht1/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 12:06:12 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 12:06:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp8muwq01o/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 12:06:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run SRL-SOA_run1 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/4d77f856965243809a51cc875fedaffe\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 57 164  10 154  42  74  84  18 101  59 130 148 160 151  65  15 133  63\n 172  78  90 119 188 120   2]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 2 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   677    10    71     1     3     0  ...   109   478    19     0     0     0     0\n2.0      0    46   391    36     0     0     0  ...    15   239    52     0     0     0     0\n3.0      0    10    24   149     0     8     0  ...     5     9    15     0     0     0     0\n4.0      2     1     0     6   392    13     0  ...     6     1     5     0    14     1     0\n5.0      0     0     0     2    49   597     0  ...     0     1     1     4     3    36     0\n6.0      0     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     2     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     2     0    15     0  ...     0     0     0     3     0     0     0\n9.0      0    78     4     2     1     5     0  ...   503   323     6     0     0     0     0\n10.0     0   154    60    14     4    16     0  ...    71  1952    54     0     0     2     0\n11.0     0    65    90    36     0     3     0  ...    46   164   163     0     0     0     0\n12.0     0     0     0     0     0    12     0  ...     0     0     0   172     0    12     0\n13.0     0     0     0     0    23     7     0  ...     0     0     0     9  1113    48     0\n14.0     0     0     1     0    20    80     0  ...     5     0     6    26    75   144     0\n15.0     0     4     0     0     0     0     0  ...     5     0     0     0     0     0    78\n\n[16 rows x 16 columns]\n View run SRL-SOA_run1 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/4d77f856965243809a51cc875fedaffe\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   720     9    29     3     2     0  ...   114   458    18     0     0     0     3\n2.0      0    30   441    14     1     1     0  ...     2   276    29     0     0     0     0\n3.0      0    42    59    93     2    19     0  ...     1     6     0     0     0     0     0\n4.0      0     2     0     6   360    15     3  ...     1     3     0     0    65     2     1\n5.0      0     0     0     0    69   587     0  ...     0     1     0     0     4    28     0\n6.0      0     0     0     0     0     0    22  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     3     0    12  ...     0     3     0     0     0     0     0\n8.0      0     0     0     0     2    16     0  ...     0     0     0     2     0     0     0\n9.0      0    64     5    17     7     4     0  ...   586   239     7     0     0     0     0\n10.0     0   108    67    25    11    20     1  ...    58  1993    36     0     0     0     1\n11.0     0    85    99    41     0     7     0  ...    12    98   222     0     0     0     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    25     2     0  ...     0     0     0     6  1142    32     0\n14.0     2     0     0     4    33    76     0  ...     0     0     0    42    87   120     3\n15.0     0     7     0     0     0     0     0  ...     1     3     1     0     0     0    76\n\n[16 rows x 16 columns]\n View run SRL-SOA_run1 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/4d77f856965243809a51cc875fedaffe\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results1.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.696416          0.571028           0.649053\n1    2          0.718496          0.630997           0.674837\n\nAverage Performance Over 2 Runs:\nOverall Accuracy: 0.6964\nAverage Accuracy: 0.5710\nKappa Coefficient: 0.6491\n View run SRL-SOA_run1 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/4d77f856965243809a51cc875fedaffe\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n Oper1D (\u001b[94mOper1D\u001b[0m)            (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_2 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  Oper1D[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],          \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7541\nEpoch 1: val_loss improved from inf to 23.40342, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.7229 - val_loss: 23.4034\nEpoch 2/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7247\nEpoch 2: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.6882 - val_loss: 23.4034\nEpoch 3/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7838\nEpoch 3: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7766 - val_loss: 23.4034\nEpoch 4/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6516\nEpoch 4: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6432 - val_loss: 23.4034\nEpoch 5/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5530\nEpoch 5: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5443 - val_loss: 23.4034\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3945\nEpoch 6: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3943 - val_loss: 23.4034\nEpoch 7/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2698\nEpoch 7: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2707 - val_loss: 23.4034\nEpoch 8/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1700\nEpoch 8: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1730 - val_loss: 23.4034\nEpoch 9/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0874\nEpoch 9: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0888 - val_loss: 23.4034\nEpoch 10/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0136\nEpoch 10: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0168 - val_loss: 23.4034\nEpoch 11/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9622\nEpoch 11: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9679 - val_loss: 23.4034\nEpoch 12/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9265\nEpoch 12: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9319 - val_loss: 23.4034\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8992\nEpoch 13: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9017 - val_loss: 23.4034\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8704\nEpoch 14: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8736 - val_loss: 23.4034\nEpoch 15/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8473\nEpoch 15: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8498 - val_loss: 23.4034\nEpoch 16/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8152\nEpoch 16: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8182 - val_loss: 23.4034\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8409\nEpoch 17: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8419 - val_loss: 23.4034\nEpoch 18/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7630\nEpoch 18: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7663 - val_loss: 23.4034\nEpoch 19/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8899\nEpoch 19: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8903 - val_loss: 23.4034\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7252\nEpoch 20: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7265 - val_loss: 23.4034\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8105\nEpoch 21: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8107 - val_loss: 23.4034\nEpoch 22/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6755\nEpoch 22: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6775 - val_loss: 23.4034\nEpoch 23/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9422\nEpoch 23: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9423 - val_loss: 23.4034\nEpoch 24/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9383\nEpoch 24: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9485 - val_loss: 23.4034\nEpoch 25/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4139\nEpoch 25: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4102 - val_loss: 23.4034\nEpoch 26/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0374\nEpoch 26: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0357 - val_loss: 23.4034\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7409\nEpoch 27: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7395 - val_loss: 23.4034\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9074\nEpoch 28: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9099 - val_loss: 23.4034\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0297\nEpoch 29: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0350 - val_loss: 23.4034\nEpoch 30/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4925\nEpoch 30: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4909 - val_loss: 23.4034\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3987\nEpoch 31: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4008 - val_loss: 23.4034\nEpoch 32/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8810\nEpoch 32: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.8656 - val_loss: 23.4034\nEpoch 33/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4635\nEpoch 33: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4514 - val_loss: 23.4034\nEpoch 34/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2429\nEpoch 34: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2328 - val_loss: 23.4034\nEpoch 35/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0590\nEpoch 35: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0513 - val_loss: 23.4034\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9259\nEpoch 36: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9215 - val_loss: 23.4034\nEpoch 37/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8215\nEpoch 37: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8124 - val_loss: 23.4034\nEpoch 38/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7215\nEpoch 38: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7113 - val_loss: 23.4034\nEpoch 39/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6318\nEpoch 39: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6312 - val_loss: 23.4034\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5715\nEpoch 40: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5707 - val_loss: 23.4034\nEpoch 41/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5320\nEpoch 41: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5318 - val_loss: 23.4034\nEpoch 42/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5073\nEpoch 42: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5073 - val_loss: 23.4034\nEpoch 43/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4837\nEpoch 43: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4840 - val_loss: 23.4034\nEpoch 44/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4775\nEpoch 44: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4782 - val_loss: 23.4034\nEpoch 45/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5053\nEpoch 45: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5061 - val_loss: 23.4034\nEpoch 46/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6553\nEpoch 46: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6605 - val_loss: 23.4034\nEpoch 47/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3361\nEpoch 47: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3094 - val_loss: 23.4034\nEpoch 48/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9439\nEpoch 48: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9306 - val_loss: 23.4034\nEpoch 49/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7539\nEpoch 49: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7536 - val_loss: 23.4034\nEpoch 50/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6332\nEpoch 50: val_loss did not improve from 23.40342\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6334 - val_loss: 23.4034\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n2025/02/20 12:08:03 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp0w8q38rk/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 12:09:12 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 12:09:20 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpeq0ux5hq/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 12:09:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run SRL-SOA_run2 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/71ad0e2c2cca4b00b004a670c207f6df\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [111  13  33   7  88 151  22  96  11  75  85 103  10  60 105   6  20  43\n 149  21 199  16 120  78 116]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 3 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   677    10    71     1     3     0  ...   109   478    19     0     0     0     0\n2.0      0    46   391    36     0     0     0  ...    15   239    52     0     0     0     0\n3.0      0    10    24   149     0     8     0  ...     5     9    15     0     0     0     0\n4.0      2     1     0     6   392    13     0  ...     6     1     5     0    14     1     0\n5.0      0     0     0     2    49   597     0  ...     0     1     1     4     3    36     0\n6.0      0     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     2     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     2     0    15     0  ...     0     0     0     3     0     0     0\n9.0      0    78     4     2     1     5     0  ...   503   323     6     0     0     0     0\n10.0     0   154    60    14     4    16     0  ...    71  1952    54     0     0     2     0\n11.0     0    65    90    36     0     3     0  ...    46   164   163     0     0     0     0\n12.0     0     0     0     0     0    12     0  ...     0     0     0   172     0    12     0\n13.0     0     0     0     0    23     7     0  ...     0     0     0     9  1113    48     0\n14.0     0     0     1     0    20    80     0  ...     5     0     6    26    75   144     0\n15.0     0     4     0     0     0     0     0  ...     5     0     0     0     0     0    78\n\n[16 rows x 16 columns]\n View run SRL-SOA_run2 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/71ad0e2c2cca4b00b004a670c207f6df\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   720     9    29     3     2     0  ...   114   458    18     0     0     0     3\n2.0      0    30   441    14     1     1     0  ...     2   276    29     0     0     0     0\n3.0      0    42    59    93     2    19     0  ...     1     6     0     0     0     0     0\n4.0      0     2     0     6   360    15     3  ...     1     3     0     0    65     2     1\n5.0      0     0     0     0    69   587     0  ...     0     1     0     0     4    28     0\n6.0      0     0     0     0     0     0    22  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     3     0    12  ...     0     3     0     0     0     0     0\n8.0      0     0     0     0     2    16     0  ...     0     0     0     2     0     0     0\n9.0      0    64     5    17     7     4     0  ...   586   239     7     0     0     0     0\n10.0     0   108    67    25    11    20     1  ...    58  1993    36     0     0     0     1\n11.0     0    85    99    41     0     7     0  ...    12    98   222     0     0     0     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    25     2     0  ...     0     0     0     6  1142    32     0\n14.0     2     0     0     4    33    76     0  ...     0     0     0    42    87   120     3\n15.0     0     7     0     0     0     0     0  ...     1     3     1     0     0     0    76\n\n[16 rows x 16 columns]\n View run SRL-SOA_run2 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/71ad0e2c2cca4b00b004a670c207f6df\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     16     1     0     0     2     0     0  ...     0     0     0     0     0     0     0\n1.0      0   870    28    25     2     3     0  ...    87   249    73     0     0     1     4\n2.0      0   164   294    12     0     0     0  ...    52   242    30     0     0     0     0\n3.0      3    89     7    80     1    17     3  ...     4     8    14     0     0     3     0\n4.0      0     1     0     4   329    26     2  ...     0     2     6     0    60    16     0\n5.0      0     0     0     6    12   630     0  ...    11     1     1     6     3    25     0\n6.0      1     0     0     0     8     0    14  ...     0     0     0     0     0     0     0\n7.0    102     1     0    12     1     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     8     0  ...     0     0     0     5     0     3     0\n9.0      0    92    16     3     5     2     4  ...   513   267    23     0     0     1     0\n10.0     0   320    36     9    15    15     4  ...   126  1737    56     0     0     3     7\n11.0     0   176    39    18     0     3     0  ...    46   108   164     1     0     0     0\n12.0     0     0     0     0     1     2     0  ...     0     0     0   170     0    20     0\n13.0     2     0     0     0    38     5     0  ...     0     2     0     6  1097    54     0\n14.0     0     0     2     0    19    74     0  ...     1     7     3    41   102   117     0\n15.0     0     2     4     0     0     0     0  ...     0     0     7     0     0     0    75\n\n[16 rows x 16 columns]\n View run SRL-SOA_run2 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/71ad0e2c2cca4b00b004a670c207f6df\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results2.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.696416          0.571028           0.649053\n1    2          0.718496          0.630997           0.674837\n2    3          0.662422          0.579924           0.611732\n\nAverage Performance Over 3 Runs:\nOverall Accuracy: 0.7075\nAverage Accuracy: 0.6010\nKappa Coefficient: 0.6619\n View run SRL-SOA_run2 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/71ad0e2c2cca4b00b004a670c207f6df\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n Oper1D (\u001b[94mOper1D\u001b[0m)            (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_3 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  Oper1D[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],          \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9609\nEpoch 1: val_loss improved from inf to 11.60564, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 4.8905 - val_loss: 11.6056\nEpoch 2/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1773\nEpoch 2: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.1642 - val_loss: 11.6056\nEpoch 3/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5168\nEpoch 3: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5106 - val_loss: 11.6056\nEpoch 4/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5595\nEpoch 4: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5513 - val_loss: 11.6056\nEpoch 5/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1714\nEpoch 5: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1737 - val_loss: 11.6056\nEpoch 6/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4828\nEpoch 6: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4793 - val_loss: 11.6056\nEpoch 7/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0917\nEpoch 7: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0901 - val_loss: 11.6056\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2213\nEpoch 8: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2179 - val_loss: 11.6056\nEpoch 9/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2075\nEpoch 9: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1975 - val_loss: 11.6056\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3993\nEpoch 10: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3929 - val_loss: 11.6056\nEpoch 11/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9687\nEpoch 11: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9449 - val_loss: 11.6056\nEpoch 12/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1301\nEpoch 12: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.1048 - val_loss: 11.6056\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4087\nEpoch 13: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3988 - val_loss: 11.6056\nEpoch 14/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9836\nEpoch 14: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9958 - val_loss: 11.6056\nEpoch 15/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0557\nEpoch 15: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0840 - val_loss: 11.6056\nEpoch 16/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9473\nEpoch 16: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9429 - val_loss: 11.6056\nEpoch 17/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9542\nEpoch 17: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9620 - val_loss: 11.6056\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0105\nEpoch 18: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0070 - val_loss: 11.6056\nEpoch 19/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0168\nEpoch 19: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0097 - val_loss: 11.6056\nEpoch 20/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0018\nEpoch 20: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9927 - val_loss: 11.6056\nEpoch 21/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0329\nEpoch 21: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0268 - val_loss: 11.6056\nEpoch 22/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0890\nEpoch 22: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0712 - val_loss: 11.6056\nEpoch 23/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0947\nEpoch 23: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0848 - val_loss: 11.6056\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0331\nEpoch 24: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0297 - val_loss: 11.6056\nEpoch 25/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9364\nEpoch 25: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9337 - val_loss: 11.6056\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8497\nEpoch 26: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8468 - val_loss: 11.6056\nEpoch 27/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7971\nEpoch 27: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7940 - val_loss: 11.6056\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7719\nEpoch 28: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7702 - val_loss: 11.6056\nEpoch 29/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7836\nEpoch 29: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7782 - val_loss: 11.6056\nEpoch 30/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8050\nEpoch 30: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8046 - val_loss: 11.6056\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8603\nEpoch 31: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8582 - val_loss: 11.6056\nEpoch 32/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9676\nEpoch 32: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9627 - val_loss: 11.6056\nEpoch 33/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9838\nEpoch 33: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9802 - val_loss: 11.6056\nEpoch 34/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0161\nEpoch 34: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0073 - val_loss: 11.6056\nEpoch 35/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8332\nEpoch 35: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8279 - val_loss: 11.6056\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7852\nEpoch 36: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7834 - val_loss: 11.6056\nEpoch 37/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7592\nEpoch 37: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7588 - val_loss: 11.6056\nEpoch 38/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7793\nEpoch 38: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7792 - val_loss: 11.6056\nEpoch 39/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8475\nEpoch 39: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8488 - val_loss: 11.6056\nEpoch 40/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1303\nEpoch 40: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1302 - val_loss: 11.6056\nEpoch 41/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9640\nEpoch 41: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9349 - val_loss: 11.6056\nEpoch 42/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2031\nEpoch 42: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1929 - val_loss: 11.6056\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4107\nEpoch 43: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4379 - val_loss: 11.6056\nEpoch 44/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6309\nEpoch 44: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.5713 - val_loss: 11.6056\nEpoch 45/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8927\nEpoch 45: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8909 - val_loss: 11.6056\nEpoch 46/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9023\nEpoch 46: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9021 - val_loss: 11.6056\nEpoch 47/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9512\nEpoch 47: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9508 - val_loss: 11.6056\nEpoch 48/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0133\nEpoch 48: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0245 - val_loss: 11.6056\nEpoch 49/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9470\nEpoch 49: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9447 - val_loss: 11.6056\nEpoch 50/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9482\nEpoch 50: val_loss did not improve from 11.60564\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9437 - val_loss: 11.6056\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n2025/02/20 12:11:10 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpv5m4xu9y/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \nWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dagshub.com. Connection pool size: 10\n2025/02/20 12:12:19 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 12:12:27 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmps89mb7vz/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 12:12:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run SRL-SOA_run3 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/495210cb95a24b93a95dab1744149181\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 83 158 140  75  55 182 132 199 102  49  19 115  60  72  15  37 180  36\n 101 127   8  34 154 137  28]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 4 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   677    10    71     1     3     0  ...   109   478    19     0     0     0     0\n2.0      0    46   391    36     0     0     0  ...    15   239    52     0     0     0     0\n3.0      0    10    24   149     0     8     0  ...     5     9    15     0     0     0     0\n4.0      2     1     0     6   392    13     0  ...     6     1     5     0    14     1     0\n5.0      0     0     0     2    49   597     0  ...     0     1     1     4     3    36     0\n6.0      0     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     2     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     2     0    15     0  ...     0     0     0     3     0     0     0\n9.0      0    78     4     2     1     5     0  ...   503   323     6     0     0     0     0\n10.0     0   154    60    14     4    16     0  ...    71  1952    54     0     0     2     0\n11.0     0    65    90    36     0     3     0  ...    46   164   163     0     0     0     0\n12.0     0     0     0     0     0    12     0  ...     0     0     0   172     0    12     0\n13.0     0     0     0     0    23     7     0  ...     0     0     0     9  1113    48     0\n14.0     0     0     1     0    20    80     0  ...     5     0     6    26    75   144     0\n15.0     0     4     0     0     0     0     0  ...     5     0     0     0     0     0    78\n\n[16 rows x 16 columns]\n View run SRL-SOA_run3 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/495210cb95a24b93a95dab1744149181\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   720     9    29     3     2     0  ...   114   458    18     0     0     0     3\n2.0      0    30   441    14     1     1     0  ...     2   276    29     0     0     0     0\n3.0      0    42    59    93     2    19     0  ...     1     6     0     0     0     0     0\n4.0      0     2     0     6   360    15     3  ...     1     3     0     0    65     2     1\n5.0      0     0     0     0    69   587     0  ...     0     1     0     0     4    28     0\n6.0      0     0     0     0     0     0    22  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     3     0    12  ...     0     3     0     0     0     0     0\n8.0      0     0     0     0     2    16     0  ...     0     0     0     2     0     0     0\n9.0      0    64     5    17     7     4     0  ...   586   239     7     0     0     0     0\n10.0     0   108    67    25    11    20     1  ...    58  1993    36     0     0     0     1\n11.0     0    85    99    41     0     7     0  ...    12    98   222     0     0     0     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    25     2     0  ...     0     0     0     6  1142    32     0\n14.0     2     0     0     4    33    76     0  ...     0     0     0    42    87   120     3\n15.0     0     7     0     0     0     0     0  ...     1     3     1     0     0     0    76\n\n[16 rows x 16 columns]\n View run SRL-SOA_run3 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/495210cb95a24b93a95dab1744149181\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     16     1     0     0     2     0     0  ...     0     0     0     0     0     0     0\n1.0      0   870    28    25     2     3     0  ...    87   249    73     0     0     1     4\n2.0      0   164   294    12     0     0     0  ...    52   242    30     0     0     0     0\n3.0      3    89     7    80     1    17     3  ...     4     8    14     0     0     3     0\n4.0      0     1     0     4   329    26     2  ...     0     2     6     0    60    16     0\n5.0      0     0     0     6    12   630     0  ...    11     1     1     6     3    25     0\n6.0      1     0     0     0     8     0    14  ...     0     0     0     0     0     0     0\n7.0    102     1     0    12     1     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     8     0  ...     0     0     0     5     0     3     0\n9.0      0    92    16     3     5     2     4  ...   513   267    23     0     0     1     0\n10.0     0   320    36     9    15    15     4  ...   126  1737    56     0     0     3     7\n11.0     0   176    39    18     0     3     0  ...    46   108   164     1     0     0     0\n12.0     0     0     0     0     1     2     0  ...     0     0     0   170     0    20     0\n13.0     2     0     0     0    38     5     0  ...     0     2     0     6  1097    54     0\n14.0     0     0     2     0    19    74     0  ...     1     7     3    41   102   117     0\n15.0     0     2     4     0     0     0     0  ...     0     0     7     0     0     0    75\n\n[16 rows x 16 columns]\n View run SRL-SOA_run3 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/495210cb95a24b93a95dab1744149181\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     24     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   831    24    19     1     2     0  ...   130   312    32     0     0     1     0\n2.0      0    59   432     4     0     1     0  ...     9   238    53     0     0     0     0\n3.0      0    34    76    47     0     5     0  ...     4    20    40     0     0     0     0\n4.0     12     3     0     1   321    16     0  ...     6     6     8     0    31    61     0\n5.0      0     0     0     1     2   624     0  ...     1    17     1     0     9    40     0\n6.0      1     0     0     0     0     0    17  ...     0     0     0     0     0     0     0\n7.0      6     0     0     0     0     0     3  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0    14     0  ...     0     0     0     2     0     4     0\n9.0      0    48     9     5     0     1     4  ...   618   220    12     0     0     0     0\n10.0     0   153    85     9     0     9     1  ...   120  1886    59     0     0     8     0\n11.0     0    37    78     3     0     0     0  ...    48    80   313     0     0     1     0\n12.0     0     0     0     0     0     4     0  ...     0     0     0   187     0     1     0\n13.0     0     0     0     0    51     2     0  ...     0     0     0     5  1121    23     0\n14.0     0     2     2     0    13    36     0  ...     3     0     4    32   104   168     0\n15.0     0     0     0     0     0     0     0  ...     8     5     3     0     0     0    71\n\n[16 rows x 16 columns]\n View run SRL-SOA_run3 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/495210cb95a24b93a95dab1744149181\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results3.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.696416          0.571028           0.649053\n1    2          0.718496          0.630997           0.674837\n2    3          0.662422          0.579924           0.611732\n3    4          0.729485          0.647031           0.688786\n\nAverage Performance Over 4 Runs:\nOverall Accuracy: 0.6924\nAverage Accuracy: 0.5940\nKappa Coefficient: 0.6452\n View run SRL-SOA_run3 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/495210cb95a24b93a95dab1744149181\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n Oper1D (\u001b[94mOper1D\u001b[0m)            (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_4 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  Oper1D[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],          \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2534\nEpoch 1: val_loss improved from inf to 10.38084, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 8.0505 - val_loss: 10.3808\nEpoch 2/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0801\nEpoch 2: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.0652 - val_loss: 10.3808\nEpoch 3/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4445\nEpoch 3: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4533 - val_loss: 10.3808\nEpoch 4/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4136\nEpoch 4: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4243 - val_loss: 10.3808\nEpoch 5/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4491\nEpoch 5: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4496 - val_loss: 10.3808\nEpoch 6/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4152\nEpoch 6: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4154 - val_loss: 10.3808\nEpoch 7/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3921\nEpoch 7: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3920 - val_loss: 10.3808\nEpoch 8/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3919\nEpoch 8: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3913 - val_loss: 10.3808\nEpoch 9/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4075\nEpoch 9: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4021 - val_loss: 10.3808\nEpoch 10/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4193\nEpoch 10: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4138 - val_loss: 10.3808\nEpoch 11/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4295\nEpoch 11: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4234 - val_loss: 10.3808\nEpoch 12/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4475\nEpoch 12: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4316 - val_loss: 10.3808\nEpoch 13/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4552\nEpoch 13: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4382 - val_loss: 10.3808\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4550\nEpoch 14: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4474 - val_loss: 10.3808\nEpoch 15/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4755\nEpoch 15: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4602 - val_loss: 10.3808\nEpoch 16/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4682\nEpoch 16: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4641 - val_loss: 10.3808\nEpoch 17/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4717\nEpoch 17: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4536 - val_loss: 10.3808\nEpoch 18/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4617\nEpoch 18: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4473 - val_loss: 10.3808\nEpoch 19/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4793\nEpoch 19: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4659 - val_loss: 10.3808\nEpoch 20/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5119\nEpoch 20: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4886 - val_loss: 10.3808\nEpoch 21/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4761\nEpoch 21: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4569 - val_loss: 10.3808\nEpoch 22/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3991\nEpoch 22: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3879 - val_loss: 10.3808\nEpoch 23/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3054\nEpoch 23: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3029 - val_loss: 10.3808\nEpoch 24/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2251\nEpoch 24: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2231 - val_loss: 10.3808\nEpoch 25/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1724\nEpoch 25: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1625 - val_loss: 10.3808\nEpoch 26/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0821\nEpoch 26: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0730 - val_loss: 10.3808\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0724\nEpoch 27: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0691 - val_loss: 10.3808\nEpoch 28/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9780\nEpoch 28: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9749 - val_loss: 10.3808\nEpoch 29/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0733\nEpoch 29: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0688 - val_loss: 10.3808\nEpoch 30/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0092\nEpoch 30: val_loss did not improve from 10.38084\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0169 - val_loss: 10.3808\nEpoch 31/50\n\u001b[1m  1/103\u001b[0m \u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.33922025/02/20 12:15:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2025/02/20 12:15:41 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpzc9_or1u/model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n\u001b[31m2025/02/20 12:15:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n View run SRL-SOA_run4 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/ea5651e30c0c49f980a52c6f049e8f60\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 37  55  93  41 192  66 189 177  74  56  87 178 191  83 119  65  95  92\n 122 114  99 176  50 101 116]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'kernel': 'rbf'}\nThe model shall evaluate for 5 times\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     1     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   677    10    71     1     3     0  ...   109   478    19     0     0     0     0\n2.0      0    46   391    36     0     0     0  ...    15   239    52     0     0     0     0\n3.0      0    10    24   149     0     8     0  ...     5     9    15     0     0     0     0\n4.0      2     1     0     6   392    13     0  ...     6     1     5     0    14     1     0\n5.0      0     0     0     2    49   597     0  ...     0     1     1     4     3    36     0\n6.0      0     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     2     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     2     0    15     0  ...     0     0     0     3     0     0     0\n9.0      0    78     4     2     1     5     0  ...   503   323     6     0     0     0     0\n10.0     0   154    60    14     4    16     0  ...    71  1952    54     0     0     2     0\n11.0     0    65    90    36     0     3     0  ...    46   164   163     0     0     0     0\n12.0     0     0     0     0     0    12     0  ...     0     0     0   172     0    12     0\n13.0     0     0     0     0    23     7     0  ...     0     0     0     9  1113    48     0\n14.0     0     0     1     0    20    80     0  ...     5     0     6    26    75   144     0\n15.0     0     4     0     0     0     0     0  ...     5     0     0     0     0     0    78\n\n[16 rows x 16 columns]\n View run SRL-SOA_run4 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/ea5651e30c0c49f980a52c6f049e8f60\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   720     9    29     3     2     0  ...   114   458    18     0     0     0     3\n2.0      0    30   441    14     1     1     0  ...     2   276    29     0     0     0     0\n3.0      0    42    59    93     2    19     0  ...     1     6     0     0     0     0     0\n4.0      0     2     0     6   360    15     3  ...     1     3     0     0    65     2     1\n5.0      0     0     0     0    69   587     0  ...     0     1     0     0     4    28     0\n6.0      0     0     0     0     0     0    22  ...     0     0     0     0     0     0     0\n7.0      1     0     0     0     3     0    12  ...     0     3     0     0     0     0     0\n8.0      0     0     0     0     2    16     0  ...     0     0     0     2     0     0     0\n9.0      0    64     5    17     7     4     0  ...   586   239     7     0     0     0     0\n10.0     0   108    67    25    11    20     1  ...    58  1993    36     0     0     0     1\n11.0     0    85    99    41     0     7     0  ...    12    98   222     0     0     0     4\n12.0     0     0     0     0     1     0     0  ...     0     0     0   191     0     0     0\n13.0     0     0     0     0    25     2     0  ...     0     0     0     6  1142    32     0\n14.0     2     0     0     4    33    76     0  ...     0     0     0    42    87   120     3\n15.0     0     7     0     0     0     0     0  ...     1     3     1     0     0     0    76\n\n[16 rows x 16 columns]\n View run SRL-SOA_run4 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/ea5651e30c0c49f980a52c6f049e8f60\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     16     1     0     0     2     0     0  ...     0     0     0     0     0     0     0\n1.0      0   870    28    25     2     3     0  ...    87   249    73     0     0     1     4\n2.0      0   164   294    12     0     0     0  ...    52   242    30     0     0     0     0\n3.0      3    89     7    80     1    17     3  ...     4     8    14     0     0     3     0\n4.0      0     1     0     4   329    26     2  ...     0     2     6     0    60    16     0\n5.0      0     0     0     6    12   630     0  ...    11     1     1     6     3    25     0\n6.0      1     0     0     0     8     0    14  ...     0     0     0     0     0     0     0\n7.0    102     1     0    12     1     0     1  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     8     0  ...     0     0     0     5     0     3     0\n9.0      0    92    16     3     5     2     4  ...   513   267    23     0     0     1     0\n10.0     0   320    36     9    15    15     4  ...   126  1737    56     0     0     3     7\n11.0     0   176    39    18     0     3     0  ...    46   108   164     1     0     0     0\n12.0     0     0     0     0     1     2     0  ...     0     0     0   170     0    20     0\n13.0     2     0     0     0    38     5     0  ...     0     2     0     6  1097    54     0\n14.0     0     0     2     0    19    74     0  ...     1     7     3    41   102   117     0\n15.0     0     2     4     0     0     0     0  ...     0     0     7     0     0     0    75\n\n[16 rows x 16 columns]\n View run SRL-SOA_run4 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/ea5651e30c0c49f980a52c6f049e8f60\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     24     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   831    24    19     1     2     0  ...   130   312    32     0     0     1     0\n2.0      0    59   432     4     0     1     0  ...     9   238    53     0     0     0     0\n3.0      0    34    76    47     0     5     0  ...     4    20    40     0     0     0     0\n4.0     12     3     0     1   321    16     0  ...     6     6     8     0    31    61     0\n5.0      0     0     0     1     2   624     0  ...     1    17     1     0     9    40     0\n6.0      1     0     0     0     0     0    17  ...     0     0     0     0     0     0     0\n7.0      6     0     0     0     0     0     3  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0    14     0  ...     0     0     0     2     0     4     0\n9.0      0    48     9     5     0     1     4  ...   618   220    12     0     0     0     0\n10.0     0   153    85     9     0     9     1  ...   120  1886    59     0     0     8     0\n11.0     0    37    78     3     0     0     0  ...    48    80   313     0     0     1     0\n12.0     0     0     0     0     0     4     0  ...     0     0     0   187     0     1     0\n13.0     0     0     0     0    51     2     0  ...     0     0     0     5  1121    23     0\n14.0     0     2     2     0    13    36     0  ...     3     0     4    32   104   168     0\n15.0     0     0     0     0     0     0     0  ...     8     5     3     0     0     0    71\n\n[16 rows x 16 columns]\n View run SRL-SOA_run4 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/ea5651e30c0c49f980a52c6f049e8f60\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      4     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   916    81     9     5     3     0  ...    76   221    39     0     0     0     0\n2.0      0   103   485    14     0     2     0  ...    12   115    59     0     0     0     0\n3.0      0    31    29    58     4    15     0  ...     4    42    43     0     0     0     0\n4.0      5     2     0     4   404    13     5  ...     5     4     3     0     7     1     0\n5.0      0     0     0     0    14   642     0  ...     0     5     0     0    19    11     0\n6.0      0     0     0     0     2     0    14  ...     2     0     0     0     0     0     0\n7.0      2     0     0     2     2     0    56  ...    13     6     0     0     0     0     0\n8.0      0     0     0     0     0     6     0  ...     0     0     0     0     0     0     0\n9.0      4   123    45    15     2     6     0  ...   405   323    10     0     0     0     0\n10.0     1   393   190    20     8     6     1  ...   185  1474    24     0     0     1     0\n11.0     1    60    63    29     1     2     0  ...    38    53   310     0     0     0     1\n12.0     0     0     0     0     0    15     0  ...     0     1     0   179     0     0     0\n13.0     0     0     0     0    37    10     0  ...     0     5     0     1  1125    25     0\n14.0     0     0     0     0    35   120     1  ...     0    13     1    30    90    80     0\n15.0     0     7    12     0     0     3     0  ...     2    13     0     0     0     0    52\n\n[16 rows x 16 columns]\n View run SRL-SOA_run4 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/ea5651e30c0c49f980a52c6f049e8f60\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\nPerformance results saved to: results/performance_results4.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.696416          0.571028           0.649053\n1    2          0.718496          0.630997           0.674837\n2    3          0.662422          0.579924           0.611732\n3    4          0.729485          0.647031           0.688786\n4    5          0.671973          0.609020           0.625393\n\nAverage Performance Over 5 Runs:\nOverall Accuracy: 0.7017\nAverage Accuracy: 0.6072\nKappa Coefficient: 0.6561\n View run SRL-SOA_run4 at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0/runs/ea5651e30c0c49f980a52c6f049e8f60\n View experiment at: https://dagshub.com/vidhi-gajra-git/SRL_SOA.mlflow/#/experiments/0\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n Oper1D (\u001b[94mOper1D\u001b[0m)            (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_5 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  Oper1D[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],          \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2739\nEpoch 1: val_loss improved from inf to 6.42319, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.2551 - val_loss: 6.4232\nEpoch 2/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9605\nEpoch 2: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.9064 - val_loss: 6.4232\nEpoch 3/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2579\nEpoch 3: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.2553 - val_loss: 6.4232\nEpoch 4/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9525\nEpoch 4: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9575 - val_loss: 6.4232\nEpoch 5/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7362\nEpoch 5: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7427 - val_loss: 6.4232\nEpoch 6/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7445\nEpoch 6: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7480 - val_loss: 6.4232\nEpoch 7/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7143\nEpoch 7: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7158 - val_loss: 6.4232\nEpoch 8/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6616\nEpoch 8: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6619 - val_loss: 6.4232\nEpoch 9/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6081\nEpoch 9: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6085 - val_loss: 6.4232\nEpoch 10/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5557\nEpoch 10: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5581 - val_loss: 6.4232\nEpoch 11/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5010\nEpoch 11: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5075 - val_loss: 6.4232\nEpoch 12/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4589\nEpoch 12: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4597 - val_loss: 6.4232\nEpoch 13/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4078\nEpoch 13: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4133 - val_loss: 6.4232\nEpoch 14/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3740\nEpoch 14: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3802 - val_loss: 6.4232\nEpoch 15/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3301\nEpoch 15: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3353 - val_loss: 6.4232\nEpoch 16/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3634\nEpoch 16: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3688 - val_loss: 6.4232\nEpoch 17/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2616\nEpoch 17: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2729 - val_loss: 6.4232\nEpoch 18/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2762\nEpoch 18: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2850 - val_loss: 6.4232\nEpoch 19/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2414\nEpoch 19: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2541 - val_loss: 6.4232\nEpoch 20/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2193\nEpoch 20: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2307 - val_loss: 6.4232\nEpoch 21/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2000\nEpoch 21: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2121 - val_loss: 6.4232\nEpoch 22/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1904\nEpoch 22: val_loss did not improve from 6.42319\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1952 - val_loss: 6.4232\nEpoch 23/50\n\u001b[1m 64/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0585","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"%cd ..\n!rm -r SRL-SOA\n!git clone https://github.com/vidhi-gajra-git/SRL-SOA.git\n\n%cd SRL-SOA\n!mkdir data \n!cp /kaggle/input/hyperspectral-image-sensing-dataset-ground-truth/*.mat data/\n\n%matplotlib inline\n!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n# with kernel initializer , multi layer \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T16:14:38.001987Z","iopub.execute_input":"2025-02-20T16:14:38.002456Z","iopub.status.idle":"2025-02-20T16:15:04.260328Z","shell.execute_reply.started":"2025-02-20T16:14:38.002420Z","shell.execute_reply":"2025-02-20T16:15:04.258837Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"/kaggle\nrm: cannot remove 'SRL-SOA': No such file or directory\nCloning into 'SRL-SOA'...\nremote: Enumerating objects: 881, done.\u001b[K\nremote: Counting objects: 100% (124/124), done.\u001b[K\nremote: Compressing objects: 100% (93/93), done.\u001b[K\nremote: Total 881 (delta 87), reused 31 (delta 31), pack-reused 757 (from 3)\u001b[K\nReceiving objects: 100% (881/881), 1.13 MiB | 20.97 MiB/s, done.\nResolving deltas: 100% (557/557), done.\n/kaggle/SRL-SOA\n2025-02-20 16:14:43.754493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-20 16:14:44.026936: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-20 16:14:44.103740: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nTraceback (most recent call last):\n  File \"/kaggle/SRL-SOA/main.py\", line 10, in <module>\n    import utils\n  File \"/kaggle/SRL-SOA/utils.py\", line 18, in <module>\n    import mlflow\nModuleNotFoundError: No module named 'mlflow'\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T07:23:23.079845Z","iopub.execute_input":"2025-02-19T07:23:23.080181Z","iopub.status.idle":"2025-02-19T07:23:23.197187Z","shell.execute_reply.started":"2025-02-19T07:23:23.080154Z","shell.execute_reply":"2025-02-19T07:23:23.196180Z"}},"outputs":[{"name":"stdout","text":"/kaggle/SRL-SOA\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%matplotlib inline\n!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n# a constant added ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:13:14.435514Z","iopub.execute_input":"2025-02-19T14:13:14.436115Z","iopub.status.idle":"2025-02-19T14:18:05.301407Z","shell.execute_reply.started":"2025-02-19T14:13:14.436044Z","shell.execute_reply":"2025-02-19T14:18:05.299919Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"2025-02-19 14:13:15.190310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-19 14:13:15.218237: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-19 14:13:15.226299: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\nScene:  (145, 145, 200)\n\nClassification:\nTraining samples:  512\nTest samples:  9737\n\n\nNumber of bands:  200\n**********  METHOD : SVM **********\n\t\t\t\t\t *****  #RUNS : 6  *****\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot (\u001b[94mDot\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2807\nEpoch 1: val_loss improved from inf to 4.12400, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.2694 - val_loss: 4.1240\nEpoch 2/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6890\nEpoch 2: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6795 - val_loss: 4.1240\nEpoch 3/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5003\nEpoch 3: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5087 - val_loss: 4.1240\nEpoch 4/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5876\nEpoch 4: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5833 - val_loss: 4.1240\nEpoch 5/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4070\nEpoch 5: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4091 - val_loss: 4.1240\nEpoch 6/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4314\nEpoch 6: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4311 - val_loss: 4.1240\nEpoch 7/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5006\nEpoch 7: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5021 - val_loss: 4.1240\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3748\nEpoch 8: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3748 - val_loss: 4.1240\nEpoch 9/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4777\nEpoch 9: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4839 - val_loss: 4.1240\nEpoch 10/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3994\nEpoch 10: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3962 - val_loss: 4.1240\nEpoch 11/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4516\nEpoch 11: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4544 - val_loss: 4.1240\nEpoch 12/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3505\nEpoch 12: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3524 - val_loss: 4.1240\nEpoch 13/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3724\nEpoch 13: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3731 - val_loss: 4.1240\nEpoch 14/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3492\nEpoch 14: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3512 - val_loss: 4.1240\nEpoch 15/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3367\nEpoch 15: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3381 - val_loss: 4.1240\nEpoch 16/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3176\nEpoch 16: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3206 - val_loss: 4.1240\nEpoch 17/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3201\nEpoch 17: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3227 - val_loss: 4.1240\nEpoch 18/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3311\nEpoch 18: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3308 - val_loss: 4.1240\nEpoch 19/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3155\nEpoch 19: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3174 - val_loss: 4.1240\nEpoch 20/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3163\nEpoch 20: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3190 - val_loss: 4.1240\nEpoch 21/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3163\nEpoch 21: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3191 - val_loss: 4.1240\nEpoch 22/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3229\nEpoch 22: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3261 - val_loss: 4.1240\nEpoch 23/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3211\nEpoch 23: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3237 - val_loss: 4.1240\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3156\nEpoch 24: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3168 - val_loss: 4.1240\nEpoch 25/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3234\nEpoch 25: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3254 - val_loss: 4.1240\nEpoch 26/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3262\nEpoch 26: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3269 - val_loss: 4.1240\nEpoch 27/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2831\nEpoch 27: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2850 - val_loss: 4.1240\nEpoch 28/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3454\nEpoch 28: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3453 - val_loss: 4.1240\nEpoch 29/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3109\nEpoch 29: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3158 - val_loss: 4.1240\nEpoch 30/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4116\nEpoch 30: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4117 - val_loss: 4.1240\nEpoch 31/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3631\nEpoch 31: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3675 - val_loss: 4.1240\nEpoch 32/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4081\nEpoch 32: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4118 - val_loss: 4.1240\nEpoch 33/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3476\nEpoch 33: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3471 - val_loss: 4.1240\nEpoch 34/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2716\nEpoch 34: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2719 - val_loss: 4.1240\nEpoch 35/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3855\nEpoch 35: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3847 - val_loss: 4.1240\nEpoch 36/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2808\nEpoch 36: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2843 - val_loss: 4.1240\nEpoch 37/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3334\nEpoch 37: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3337 - val_loss: 4.1240\nEpoch 38/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3714\nEpoch 38: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3717 - val_loss: 4.1240\nEpoch 39/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2931\nEpoch 39: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2958 - val_loss: 4.1240\nEpoch 40/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2651\nEpoch 40: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2668 - val_loss: 4.1240\nEpoch 41/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5366\nEpoch 41: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5390 - val_loss: 4.1240\nEpoch 42/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3562\nEpoch 42: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3546 - val_loss: 4.1240\nEpoch 43/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4895\nEpoch 43: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4937 - val_loss: 4.1240\nEpoch 44/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3391\nEpoch 44: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3391 - val_loss: 4.1240\nEpoch 45/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3182\nEpoch 45: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3203 - val_loss: 4.1240\nEpoch 46/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2859\nEpoch 46: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2873 - val_loss: 4.1240\nEpoch 47/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2628\nEpoch 47: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2625 - val_loss: 4.1240\nEpoch 48/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2715\nEpoch 48: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2707 - val_loss: 4.1240\nEpoch 49/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2531\nEpoch 49: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2538 - val_loss: 4.1240\nEpoch 50/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2953\nEpoch 50: val_loss did not improve from 4.12400\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3005 - val_loss: 4.1240\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [188   0 162 100 179  11  35  91 175 144 127 133 122 138 120  52  64 110\n 185 150  61  53  40  70 118]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 1 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   737    20    82     0     2     0  ...   139   375    13     0     0     0     0\n2.0      0    97   404    36     0     2     0  ...    15   192    33     0     0     0     0\n3.0      0    33    37   129     0     1     0  ...     4     3    13     0     0     1     0\n4.0      2     1     2     4   389     7     0  ...    10    10     2     0     8     7     0\n5.0      0     2     0     2    11   654     0  ...     1     1     0     0     3    19     0\n6.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0      3     3     0     0     1     0     0  ...     0     4     0     0     0     0     0\n8.0      0     2     0     0     1    14     0  ...     0     0     0     0     0     3     0\n9.0      0    53     6     6     2     3     0  ...   503   330    20     0     0     0     0\n10.0     0   163    57    25     4     9     0  ...   123  1904    36     0     0     5     0\n11.0     0    60    77    44     1     1     0  ...    42   159   183     0     0     0     0\n12.0     0     1     0     0     0     7     0  ...     0     0     0   174     0    14     0\n13.0     0     0     0     0    19     1     0  ...     0     0     0     3  1107    72     0\n14.0     2     3     1     0    24    51     0  ...     3     0     1    33    82   160     0\n15.0     0     4     0     0     0     0     0  ...     9     2     0     0     0     0    72\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results0.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.704221          0.572424           0.658924\n\nAverage Performance Over 1 Runs:\nOverall Accuracy: 0.7042\nAverage Accuracy: 0.5724\nKappa Coefficient: 0.6589\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_1 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1650\nEpoch 1: val_loss improved from inf to 2.61901, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 1.1534 - val_loss: 2.6190\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6052\nEpoch 2: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6036 - val_loss: 2.6190\nEpoch 3/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5587\nEpoch 3: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5559 - val_loss: 2.6190\nEpoch 4/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5492\nEpoch 4: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5457 - val_loss: 2.6190\nEpoch 5/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4646\nEpoch 5: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4634 - val_loss: 2.6190\nEpoch 6/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5255\nEpoch 6: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5246 - val_loss: 2.6190\nEpoch 7/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4892\nEpoch 7: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4885 - val_loss: 2.6190\nEpoch 8/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5026\nEpoch 8: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5015 - val_loss: 2.6190\nEpoch 9/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5074\nEpoch 9: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5040 - val_loss: 2.6190\nEpoch 10/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3861\nEpoch 10: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3966 - val_loss: 2.6190\nEpoch 11/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5552\nEpoch 11: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5486 - val_loss: 2.6190\nEpoch 12/50\n\u001b[1m 91/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4661\nEpoch 12: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4629 - val_loss: 2.6190\nEpoch 13/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4472\nEpoch 13: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4459 - val_loss: 2.6190\nEpoch 14/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4438\nEpoch 14: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4479 - val_loss: 2.6190\nEpoch 15/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4331\nEpoch 15: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4327 - val_loss: 2.6190\nEpoch 16/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3991\nEpoch 16: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4003 - val_loss: 2.6190\nEpoch 17/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4169\nEpoch 17: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4168 - val_loss: 2.6190\nEpoch 18/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4609\nEpoch 18: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4628 - val_loss: 2.6190\nEpoch 19/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4686\nEpoch 19: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4653 - val_loss: 2.6190\nEpoch 20/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3887\nEpoch 20: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3889 - val_loss: 2.6190\nEpoch 21/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4704\nEpoch 21: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4680 - val_loss: 2.6190\nEpoch 22/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4089\nEpoch 22: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4109 - val_loss: 2.6190\nEpoch 23/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4887\nEpoch 23: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4849 - val_loss: 2.6190\nEpoch 24/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4502\nEpoch 24: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4495 - val_loss: 2.6190\nEpoch 25/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4514\nEpoch 25: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4510 - val_loss: 2.6190\nEpoch 26/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4346\nEpoch 26: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4347 - val_loss: 2.6190\nEpoch 27/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5061\nEpoch 27: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5065 - val_loss: 2.6190\nEpoch 28/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5197\nEpoch 28: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5182 - val_loss: 2.6190\nEpoch 29/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4435\nEpoch 29: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4424 - val_loss: 2.6190\nEpoch 30/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4859\nEpoch 30: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4827 - val_loss: 2.6190\nEpoch 31/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4345\nEpoch 31: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4328 - val_loss: 2.6190\nEpoch 32/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4448\nEpoch 32: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4432 - val_loss: 2.6190\nEpoch 33/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3731\nEpoch 33: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3717 - val_loss: 2.6190\nEpoch 34/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3766\nEpoch 34: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3768 - val_loss: 2.6190\nEpoch 35/50\n\u001b[1m 91/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3297\nEpoch 35: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3291 - val_loss: 2.6190\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3053\nEpoch 36: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3062 - val_loss: 2.6190\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3273\nEpoch 37: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3277 - val_loss: 2.6190\nEpoch 38/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3293\nEpoch 38: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3304 - val_loss: 2.6190\nEpoch 39/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3453\nEpoch 39: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3451 - val_loss: 2.6190\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3731\nEpoch 40: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3737 - val_loss: 2.6190\nEpoch 41/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3613\nEpoch 41: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3604 - val_loss: 2.6190\nEpoch 42/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3427\nEpoch 42: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3436 - val_loss: 2.6190\nEpoch 43/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3367\nEpoch 43: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3363 - val_loss: 2.6190\nEpoch 44/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3352\nEpoch 44: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3365 - val_loss: 2.6190\nEpoch 45/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3679\nEpoch 45: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3659 - val_loss: 2.6190\nEpoch 46/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3651\nEpoch 46: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3659 - val_loss: 2.6190\nEpoch 47/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3964\nEpoch 47: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3923 - val_loss: 2.6190\nEpoch 48/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3334\nEpoch 48: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3335 - val_loss: 2.6190\nEpoch 49/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3440\nEpoch 49: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3420 - val_loss: 2.6190\nEpoch 50/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3283\nEpoch 50: val_loss did not improve from 2.61901\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3284 - val_loss: 2.6190\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [123 147  92  73   9 134 191 146  19  14 106 102  50 142  21 137 107 196\n 100 130  37  15  33 163  63]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 2 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   737    20    82     0     2     0  ...   139   375    13     0     0     0     0\n2.0      0    97   404    36     0     2     0  ...    15   192    33     0     0     0     0\n3.0      0    33    37   129     0     1     0  ...     4     3    13     0     0     1     0\n4.0      2     1     2     4   389     7     0  ...    10    10     2     0     8     7     0\n5.0      0     2     0     2    11   654     0  ...     1     1     0     0     3    19     0\n6.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0      3     3     0     0     1     0     0  ...     0     4     0     0     0     0     0\n8.0      0     2     0     0     1    14     0  ...     0     0     0     0     0     3     0\n9.0      0    53     6     6     2     3     0  ...   503   330    20     0     0     0     0\n10.0     0   163    57    25     4     9     0  ...   123  1904    36     0     0     5     0\n11.0     0    60    77    44     1     1     0  ...    42   159   183     0     0     0     0\n12.0     0     1     0     0     0     7     0  ...     0     0     0   174     0    14     0\n13.0     0     0     0     0    19     1     0  ...     0     0     0     3  1107    72     0\n14.0     2     3     1     0    24    51     0  ...     3     0     1    33    82   160     0\n15.0     0     4     0     0     0     0     0  ...     9     2     0     0     0     0    72\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      8     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   779    28    13     2     2     0  ...    73   421    36     0     0     0     2\n2.0      0    31   429    18     0     2     0  ...     4   272    38     0     0     0     0\n3.0      0    35    32   134     1     7     0  ...     4     8     0     0     0     0     0\n4.0      0     4     0     4   398     9     0  ...     0     3     0     0    36     1     0\n5.0      0     0     0     0    14   634     0  ...     0     2     0     1     0    38     0\n6.0      0     0     0     0     2     0     7  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     1     0     6  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    17     0  ...     0     0     0     2     0     0     0\n9.0      0    66     5     8     3     4     0  ...   561   270    10     0     0     0     1\n10.0     0   139    50     7     9    13     2  ...    68  1971    53     0     0     6     1\n11.0     0    61    45    20     0     7     0  ...    28   166   237     0     0     0     4\n12.0     0     0     0     0     1     4     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     1    22     2     0  ...     0     0     0     1  1144    37     0\n14.0     3     0     0     2    29    56     0  ...     1     0     0    36    89   146     5\n15.0     0     2     0     0     0     0     0  ...     0     4     6     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results1.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.704221          0.572424           0.658924\n1    2          0.735339          0.624800           0.694008\n\nAverage Performance Over 2 Runs:\nOverall Accuracy: 0.7198\nAverage Accuracy: 0.5986\nKappa Coefficient: 0.6765\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_2 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4062\nEpoch 1: val_loss improved from inf to 3.27366, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.4023 - val_loss: 3.2737\nEpoch 2/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7567\nEpoch 2: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7510 - val_loss: 3.2737\nEpoch 3/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5728\nEpoch 3: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5707 - val_loss: 3.2737\nEpoch 4/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5386\nEpoch 4: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5346 - val_loss: 3.2737\nEpoch 5/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6316\nEpoch 5: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6223 - val_loss: 3.2737\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3724\nEpoch 6: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3722 - val_loss: 3.2737\nEpoch 7/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4228\nEpoch 7: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4219 - val_loss: 3.2737\nEpoch 8/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3667\nEpoch 8: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3663 - val_loss: 3.2737\nEpoch 9/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3389\nEpoch 9: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3406 - val_loss: 3.2737\nEpoch 10/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3552\nEpoch 10: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3537 - val_loss: 3.2737\nEpoch 11/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3268\nEpoch 11: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3273 - val_loss: 3.2737\nEpoch 12/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4451\nEpoch 12: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4445 - val_loss: 3.2737\nEpoch 13/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5226\nEpoch 13: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5225 - val_loss: 3.2737\nEpoch 14/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4584\nEpoch 14: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4559 - val_loss: 3.2737\nEpoch 15/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2867\nEpoch 15: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2855 - val_loss: 3.2737\nEpoch 16/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2837\nEpoch 16: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2829 - val_loss: 3.2737\nEpoch 17/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3189\nEpoch 17: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3170 - val_loss: 3.2737\nEpoch 18/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3371\nEpoch 18: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3364 - val_loss: 3.2737\nEpoch 19/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5995\nEpoch 19: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5910 - val_loss: 3.2737\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3835\nEpoch 20: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3831 - val_loss: 3.2737\nEpoch 21/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5163\nEpoch 21: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5072 - val_loss: 3.2737\nEpoch 22/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3917\nEpoch 22: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3904 - val_loss: 3.2737\nEpoch 23/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2803\nEpoch 23: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2807 - val_loss: 3.2737\nEpoch 24/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3290\nEpoch 24: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3274 - val_loss: 3.2737\nEpoch 25/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3591\nEpoch 25: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3595 - val_loss: 3.2737\nEpoch 26/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5902\nEpoch 26: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5863 - val_loss: 3.2737\nEpoch 27/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4303\nEpoch 27: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4291 - val_loss: 3.2737\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4858\nEpoch 28: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4840 - val_loss: 3.2737\nEpoch 29/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3462\nEpoch 29: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3476 - val_loss: 3.2737\nEpoch 30/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3611\nEpoch 30: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3612 - val_loss: 3.2737\nEpoch 31/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3973\nEpoch 31: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3965 - val_loss: 3.2737\nEpoch 32/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3947\nEpoch 32: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3928 - val_loss: 3.2737\nEpoch 33/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3090\nEpoch 33: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3104 - val_loss: 3.2737\nEpoch 34/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3210\nEpoch 34: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3215 - val_loss: 3.2737\nEpoch 35/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3199\nEpoch 35: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3202 - val_loss: 3.2737\nEpoch 36/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3272\nEpoch 36: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3275 - val_loss: 3.2737\nEpoch 37/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3352\nEpoch 37: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3347 - val_loss: 3.2737\nEpoch 38/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3374\nEpoch 38: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3368 - val_loss: 3.2737\nEpoch 39/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3392\nEpoch 39: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3381 - val_loss: 3.2737\nEpoch 40/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3366\nEpoch 40: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3344 - val_loss: 3.2737\nEpoch 41/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3311\nEpoch 41: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3299 - val_loss: 3.2737\nEpoch 42/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3284\nEpoch 42: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3281 - val_loss: 3.2737\nEpoch 43/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3328\nEpoch 43: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3328 - val_loss: 3.2737\nEpoch 44/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3984\nEpoch 44: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3995 - val_loss: 3.2737\nEpoch 45/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9993\nEpoch 45: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9755 - val_loss: 3.2737\nEpoch 46/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6846\nEpoch 46: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6706 - val_loss: 3.2737\nEpoch 47/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6715\nEpoch 47: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6556 - val_loss: 3.2737\nEpoch 48/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5673\nEpoch 48: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5610 - val_loss: 3.2737\nEpoch 49/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5856\nEpoch 49: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5792 - val_loss: 3.2737\nEpoch 50/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5434\nEpoch 50: val_loss did not improve from 3.27366\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5333 - val_loss: 3.2737\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [165 182  59 153 141 113  82 110  17 185  55  34  89 172   0 139   5 192\n 195  67 124 116 101 164  69]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 3 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   737    20    82     0     2     0  ...   139   375    13     0     0     0     0\n2.0      0    97   404    36     0     2     0  ...    15   192    33     0     0     0     0\n3.0      0    33    37   129     0     1     0  ...     4     3    13     0     0     1     0\n4.0      2     1     2     4   389     7     0  ...    10    10     2     0     8     7     0\n5.0      0     2     0     2    11   654     0  ...     1     1     0     0     3    19     0\n6.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0      3     3     0     0     1     0     0  ...     0     4     0     0     0     0     0\n8.0      0     2     0     0     1    14     0  ...     0     0     0     0     0     3     0\n9.0      0    53     6     6     2     3     0  ...   503   330    20     0     0     0     0\n10.0     0   163    57    25     4     9     0  ...   123  1904    36     0     0     5     0\n11.0     0    60    77    44     1     1     0  ...    42   159   183     0     0     0     0\n12.0     0     1     0     0     0     7     0  ...     0     0     0   174     0    14     0\n13.0     0     0     0     0    19     1     0  ...     0     0     0     3  1107    72     0\n14.0     2     3     1     0    24    51     0  ...     3     0     1    33    82   160     0\n15.0     0     4     0     0     0     0     0  ...     9     2     0     0     0     0    72\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      8     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   779    28    13     2     2     0  ...    73   421    36     0     0     0     2\n2.0      0    31   429    18     0     2     0  ...     4   272    38     0     0     0     0\n3.0      0    35    32   134     1     7     0  ...     4     8     0     0     0     0     0\n4.0      0     4     0     4   398     9     0  ...     0     3     0     0    36     1     0\n5.0      0     0     0     0    14   634     0  ...     0     2     0     1     0    38     0\n6.0      0     0     0     0     2     0     7  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     1     0     6  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    17     0  ...     0     0     0     2     0     0     0\n9.0      0    66     5     8     3     4     0  ...   561   270    10     0     0     0     1\n10.0     0   139    50     7     9    13     2  ...    68  1971    53     0     0     6     1\n11.0     0    61    45    20     0     7     0  ...    28   166   237     0     0     0     4\n12.0     0     0     0     0     1     4     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     1    22     2     0  ...     0     0     0     1  1144    37     0\n14.0     3     0     0     2    29    56     0  ...     1     0     0    36    89   146     5\n15.0     0     2     0     0     0     0     0  ...     0     4     6     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      9     0     0     0     0     0     0  ...     0     1     0     0     0     0     0\n1.0      0   907     9    14     4     5     0  ...   119   261    25     0     0     0     0\n2.0      0    62   374     9     0     3     0  ...     8   261    77     0     0     0     0\n3.0      0    44    13    71     2    22     0  ...     3    35    37     0     0     0     0\n4.0      1     0     0     3   370    27     0  ...     2     1     3     0    36     3     0\n5.0      0     0     0     0     7   665     0  ...     3     0     0     7     1    13     0\n6.0      0     0     0     0     8     0     6  ...     0     0     0     0     0     0     0\n7.0     26     0     0     0    13     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0    12     0  ...     0     0     0     6     0     0     0\n9.0      0    43    15     1     9     3     0  ...   553   291    10     0     0     1     0\n10.0     0   165    49     2    13    21     0  ...    90  1939    44     0     0     1     4\n11.0     0    81    56    11     1     4     0  ...    19   144   238     0     0     2     0\n12.0     0     0     0     0     0     1     0  ...     0     0     0   192     0     0     0\n13.0     2     0     0     0    43     2     0  ...     0     0     0     4  1132    21     0\n14.0     1     2     0     0    10    51     0  ...     0     0     1    48   123   130     0\n15.0     0     3     1     0     1     0     0  ...     4     0     2     0     0     2    75\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results2.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.704221          0.572424           0.658924\n1    2          0.735339          0.624800           0.694008\n2    3          0.727329          0.600676           0.685136\n\nAverage Performance Over 3 Runs:\nOverall Accuracy: 0.7223\nAverage Accuracy: 0.5993\nKappa Coefficient: 0.6794\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_3 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0604\nEpoch 1: val_loss improved from inf to 2.56886, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.0401 - val_loss: 2.5689\nEpoch 2/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5865\nEpoch 2: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5852 - val_loss: 2.5689\nEpoch 3/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5836\nEpoch 3: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5833 - val_loss: 2.5689\nEpoch 4/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4376\nEpoch 4: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4373 - val_loss: 2.5689\nEpoch 5/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5328\nEpoch 5: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5337 - val_loss: 2.5689\nEpoch 6/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3754\nEpoch 6: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3757 - val_loss: 2.5689\nEpoch 7/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4987\nEpoch 7: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4982 - val_loss: 2.5689\nEpoch 8/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4903\nEpoch 8: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4884 - val_loss: 2.5689\nEpoch 9/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3951\nEpoch 9: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3937 - val_loss: 2.5689\nEpoch 10/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3889\nEpoch 10: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3881 - val_loss: 2.5689\nEpoch 11/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3505\nEpoch 11: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3499 - val_loss: 2.5689\nEpoch 12/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3499\nEpoch 12: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3494 - val_loss: 2.5689\nEpoch 13/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3654\nEpoch 13: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3692 - val_loss: 2.5689\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5541\nEpoch 14: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5526 - val_loss: 2.5689\nEpoch 15/50\n\u001b[1m 91/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3703\nEpoch 15: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3679 - val_loss: 2.5689\nEpoch 16/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3157\nEpoch 16: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3176 - val_loss: 2.5689\nEpoch 17/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3028\nEpoch 17: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3031 - val_loss: 2.5689\nEpoch 18/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3078\nEpoch 18: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.3076 - val_loss: 2.5689\nEpoch 19/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4983\nEpoch 19: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4947 - val_loss: 2.5689\nEpoch 20/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2865\nEpoch 20: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2874 - val_loss: 2.5689\nEpoch 21/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5022\nEpoch 21: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4998 - val_loss: 2.5689\nEpoch 22/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2790\nEpoch 22: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2789 - val_loss: 2.5689\nEpoch 23/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4034\nEpoch 23: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4002 - val_loss: 2.5689\nEpoch 24/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2776\nEpoch 24: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2786 - val_loss: 2.5689\nEpoch 25/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5275\nEpoch 25: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5257 - val_loss: 2.5689\nEpoch 26/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2731\nEpoch 26: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2729 - val_loss: 2.5689\nEpoch 27/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3313\nEpoch 27: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3283 - val_loss: 2.5689\nEpoch 28/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2864\nEpoch 28: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2853 - val_loss: 2.5689\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2646\nEpoch 29: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2647 - val_loss: 2.5689\nEpoch 30/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2762\nEpoch 30: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2774 - val_loss: 2.5689\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3218\nEpoch 31: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3238 - val_loss: 2.5689\nEpoch 32/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5557\nEpoch 32: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5464 - val_loss: 2.5689\nEpoch 33/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3680\nEpoch 33: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3671 - val_loss: 2.5689\nEpoch 34/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2944\nEpoch 34: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2976 - val_loss: 2.5689\nEpoch 35/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4812\nEpoch 35: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4783 - val_loss: 2.5689\nEpoch 36/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2936\nEpoch 36: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2958 - val_loss: 2.5689\nEpoch 37/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4714\nEpoch 37: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4651 - val_loss: 2.5689\nEpoch 38/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2664\nEpoch 38: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2645 - val_loss: 2.5689\nEpoch 39/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2635\nEpoch 39: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2617 - val_loss: 2.5689\nEpoch 40/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2551\nEpoch 40: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2539 - val_loss: 2.5689\nEpoch 41/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2575\nEpoch 41: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2628 - val_loss: 2.5689\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6204\nEpoch 42: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6158 - val_loss: 2.5689\nEpoch 43/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2547\nEpoch 43: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2577 - val_loss: 2.5689\nEpoch 44/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2876\nEpoch 44: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2939 - val_loss: 2.5689\nEpoch 45/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4557\nEpoch 45: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4506 - val_loss: 2.5689\nEpoch 46/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3031\nEpoch 46: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3064 - val_loss: 2.5689\nEpoch 47/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4767\nEpoch 47: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4721 - val_loss: 2.5689\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2680\nEpoch 48: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2674 - val_loss: 2.5689\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2614\nEpoch 49: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2634 - val_loss: 2.5689\nEpoch 50/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5494\nEpoch 50: val_loss did not improve from 2.56886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5408 - val_loss: 2.5689\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 15  23  71  98  22   2 112 185 194 114 157 167  34   0  55 189 129  37\n  42 162  40 106  73  63 109]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 4 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   737    20    82     0     2     0  ...   139   375    13     0     0     0     0\n2.0      0    97   404    36     0     2     0  ...    15   192    33     0     0     0     0\n3.0      0    33    37   129     0     1     0  ...     4     3    13     0     0     1     0\n4.0      2     1     2     4   389     7     0  ...    10    10     2     0     8     7     0\n5.0      0     2     0     2    11   654     0  ...     1     1     0     0     3    19     0\n6.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0      3     3     0     0     1     0     0  ...     0     4     0     0     0     0     0\n8.0      0     2     0     0     1    14     0  ...     0     0     0     0     0     3     0\n9.0      0    53     6     6     2     3     0  ...   503   330    20     0     0     0     0\n10.0     0   163    57    25     4     9     0  ...   123  1904    36     0     0     5     0\n11.0     0    60    77    44     1     1     0  ...    42   159   183     0     0     0     0\n12.0     0     1     0     0     0     7     0  ...     0     0     0   174     0    14     0\n13.0     0     0     0     0    19     1     0  ...     0     0     0     3  1107    72     0\n14.0     2     3     1     0    24    51     0  ...     3     0     1    33    82   160     0\n15.0     0     4     0     0     0     0     0  ...     9     2     0     0     0     0    72\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      8     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   779    28    13     2     2     0  ...    73   421    36     0     0     0     2\n2.0      0    31   429    18     0     2     0  ...     4   272    38     0     0     0     0\n3.0      0    35    32   134     1     7     0  ...     4     8     0     0     0     0     0\n4.0      0     4     0     4   398     9     0  ...     0     3     0     0    36     1     0\n5.0      0     0     0     0    14   634     0  ...     0     2     0     1     0    38     0\n6.0      0     0     0     0     2     0     7  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     1     0     6  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    17     0  ...     0     0     0     2     0     0     0\n9.0      0    66     5     8     3     4     0  ...   561   270    10     0     0     0     1\n10.0     0   139    50     7     9    13     2  ...    68  1971    53     0     0     6     1\n11.0     0    61    45    20     0     7     0  ...    28   166   237     0     0     0     4\n12.0     0     0     0     0     1     4     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     1    22     2     0  ...     0     0     0     1  1144    37     0\n14.0     3     0     0     2    29    56     0  ...     1     0     0    36    89   146     5\n15.0     0     2     0     0     0     0     0  ...     0     4     6     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      9     0     0     0     0     0     0  ...     0     1     0     0     0     0     0\n1.0      0   907     9    14     4     5     0  ...   119   261    25     0     0     0     0\n2.0      0    62   374     9     0     3     0  ...     8   261    77     0     0     0     0\n3.0      0    44    13    71     2    22     0  ...     3    35    37     0     0     0     0\n4.0      1     0     0     3   370    27     0  ...     2     1     3     0    36     3     0\n5.0      0     0     0     0     7   665     0  ...     3     0     0     7     1    13     0\n6.0      0     0     0     0     8     0     6  ...     0     0     0     0     0     0     0\n7.0     26     0     0     0    13     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0    12     0  ...     0     0     0     6     0     0     0\n9.0      0    43    15     1     9     3     0  ...   553   291    10     0     0     1     0\n10.0     0   165    49     2    13    21     0  ...    90  1939    44     0     0     1     4\n11.0     0    81    56    11     1     4     0  ...    19   144   238     0     0     2     0\n12.0     0     0     0     0     0     1     0  ...     0     0     0   192     0     0     0\n13.0     2     0     0     0    43     2     0  ...     0     0     0     4  1132    21     0\n14.0     1     2     0     0    10    51     0  ...     0     0     1    48   123   130     0\n15.0     0     3     1     0     1     0     0  ...     4     0     2     0     0     2    75\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      7     0     0     0     0     0     0  ...     0     0     1     0     0     0     0\n1.0      0   800    21    16     1     3     0  ...   149   349    14     0     0     0     0\n2.0      0   106   394    16     0     0     0  ...    37   218    25     0     0     0     0\n3.0      1    38    49   108     0     6     0  ...     6     7    12     0     0     0     0\n4.0     13     3     0     2   370    25     0  ...     7     6     8     0    12    20     0\n5.0      0     1     0     7     2   615     0  ...     1    26     0     0     3    40     0\n6.0      1     0     0     0     0     0     3  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     1     0    15     0  ...     0     0     0     3     0     1     0\n9.0      0    96     9     2     0     1     0  ...   657   140    12     0     0     0     0\n10.0     0   202    64     9     1     9     0  ...   156  1835    50     0     0     3     0\n11.0     0    55    33     2     0     0     0  ...    79    92   297     0     0     1     1\n12.0     0     0     0     0     0     0     0  ...     0     2     0   186     0     4     0\n13.0     0     0     0     0    12     2     0  ...     0     0     0     5  1166    17     0\n14.0     0     0     0     0    12    57     0  ...     3     0     7    32    87   166     0\n15.0     0     1     0     0     0     0     0  ...     5     6     2     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results3.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.704221          0.572424           0.658924\n1    2          0.735339          0.624800           0.694008\n2    3          0.727329          0.600676           0.685136\n3    4          0.732156          0.611152           0.692033\n\nAverage Performance Over 4 Runs:\nOverall Accuracy: 0.7248\nAverage Accuracy: 0.6023\nKappa Coefficient: 0.6825\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_4 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0298\nEpoch 1: val_loss improved from inf to 1.90886, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.0128 - val_loss: 1.9089\nEpoch 2/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5678\nEpoch 2: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5652 - val_loss: 1.9089\nEpoch 3/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5558\nEpoch 3: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5540 - val_loss: 1.9089\nEpoch 4/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4949\nEpoch 4: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4939 - val_loss: 1.9089\nEpoch 5/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4702\nEpoch 5: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4683 - val_loss: 1.9089\nEpoch 6/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4621\nEpoch 6: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4653 - val_loss: 1.9089\nEpoch 7/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5684\nEpoch 7: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5659 - val_loss: 1.9089\nEpoch 8/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4463\nEpoch 8: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4451 - val_loss: 1.9089\nEpoch 9/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6071\nEpoch 9: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6037 - val_loss: 1.9089\nEpoch 10/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5467\nEpoch 10: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5440 - val_loss: 1.9089\nEpoch 11/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4690\nEpoch 11: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4648 - val_loss: 1.9089\nEpoch 12/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3499\nEpoch 12: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3503 - val_loss: 1.9089\nEpoch 13/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3953\nEpoch 13: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3939 - val_loss: 1.9089\nEpoch 14/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3745\nEpoch 14: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3747 - val_loss: 1.9089\nEpoch 15/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4231\nEpoch 15: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4280 - val_loss: 1.9089\nEpoch 16/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6581\nEpoch 16: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6539 - val_loss: 1.9089\nEpoch 17/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4957\nEpoch 17: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4885 - val_loss: 1.9089\nEpoch 18/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3495\nEpoch 18: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3521 - val_loss: 1.9089\nEpoch 19/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4299\nEpoch 19: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4285 - val_loss: 1.9089\nEpoch 20/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3611\nEpoch 20: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3613 - val_loss: 1.9089\nEpoch 21/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3772\nEpoch 21: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3770 - val_loss: 1.9089\nEpoch 22/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3540\nEpoch 22: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3546 - val_loss: 1.9089\nEpoch 23/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4184\nEpoch 23: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4188 - val_loss: 1.9089\nEpoch 24/50\n\u001b[1m 91/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5952\nEpoch 24: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5872 - val_loss: 1.9089\nEpoch 25/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4994\nEpoch 25: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4967 - val_loss: 1.9089\nEpoch 26/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3899\nEpoch 26: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3902 - val_loss: 1.9089\nEpoch 27/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4170\nEpoch 27: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4171 - val_loss: 1.9089\nEpoch 28/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3920\nEpoch 28: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3921 - val_loss: 1.9089\nEpoch 29/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4944\nEpoch 29: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4919 - val_loss: 1.9089\nEpoch 30/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4115\nEpoch 30: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4102 - val_loss: 1.9089\nEpoch 31/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4466\nEpoch 31: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4444 - val_loss: 1.9089\nEpoch 32/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3716\nEpoch 32: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3699 - val_loss: 1.9089\nEpoch 33/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3172\nEpoch 33: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3160 - val_loss: 1.9089\nEpoch 34/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3173\nEpoch 34: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3163 - val_loss: 1.9089\nEpoch 35/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3339\nEpoch 35: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3329 - val_loss: 1.9089\nEpoch 36/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3190\nEpoch 36: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3183 - val_loss: 1.9089\nEpoch 37/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3429\nEpoch 37: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3413 - val_loss: 1.9089\nEpoch 38/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3349\nEpoch 38: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3342 - val_loss: 1.9089\nEpoch 39/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3518\nEpoch 39: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3500 - val_loss: 1.9089\nEpoch 40/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3644\nEpoch 40: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3632 - val_loss: 1.9089\nEpoch 41/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3506\nEpoch 41: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3489 - val_loss: 1.9089\nEpoch 42/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3683\nEpoch 42: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3688 - val_loss: 1.9089\nEpoch 43/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3992\nEpoch 43: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4047 - val_loss: 1.9089\nEpoch 44/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4400\nEpoch 44: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4394 - val_loss: 1.9089\nEpoch 45/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3034\nEpoch 45: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3036 - val_loss: 1.9089\nEpoch 46/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3117\nEpoch 46: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3107 - val_loss: 1.9089\nEpoch 47/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3092\nEpoch 47: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3086 - val_loss: 1.9089\nEpoch 48/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3330\nEpoch 48: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3295 - val_loss: 1.9089\nEpoch 49/50\n\u001b[1m 93/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3340\nEpoch 49: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3324 - val_loss: 1.9089\nEpoch 50/50\n\u001b[1m 91/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3310\nEpoch 50: val_loss did not improve from 1.90886\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3305 - val_loss: 1.9089\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [181 162  27  12 170 135 176  37  48 144  25  14  76 192  53 120 131 184\n 199  45 113  79  22 180  29]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 5 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   737    20    82     0     2     0  ...   139   375    13     0     0     0     0\n2.0      0    97   404    36     0     2     0  ...    15   192    33     0     0     0     0\n3.0      0    33    37   129     0     1     0  ...     4     3    13     0     0     1     0\n4.0      2     1     2     4   389     7     0  ...    10    10     2     0     8     7     0\n5.0      0     2     0     2    11   654     0  ...     1     1     0     0     3    19     0\n6.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0      3     3     0     0     1     0     0  ...     0     4     0     0     0     0     0\n8.0      0     2     0     0     1    14     0  ...     0     0     0     0     0     3     0\n9.0      0    53     6     6     2     3     0  ...   503   330    20     0     0     0     0\n10.0     0   163    57    25     4     9     0  ...   123  1904    36     0     0     5     0\n11.0     0    60    77    44     1     1     0  ...    42   159   183     0     0     0     0\n12.0     0     1     0     0     0     7     0  ...     0     0     0   174     0    14     0\n13.0     0     0     0     0    19     1     0  ...     0     0     0     3  1107    72     0\n14.0     2     3     1     0    24    51     0  ...     3     0     1    33    82   160     0\n15.0     0     4     0     0     0     0     0  ...     9     2     0     0     0     0    72\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      8     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   779    28    13     2     2     0  ...    73   421    36     0     0     0     2\n2.0      0    31   429    18     0     2     0  ...     4   272    38     0     0     0     0\n3.0      0    35    32   134     1     7     0  ...     4     8     0     0     0     0     0\n4.0      0     4     0     4   398     9     0  ...     0     3     0     0    36     1     0\n5.0      0     0     0     0    14   634     0  ...     0     2     0     1     0    38     0\n6.0      0     0     0     0     2     0     7  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     1     0     6  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    17     0  ...     0     0     0     2     0     0     0\n9.0      0    66     5     8     3     4     0  ...   561   270    10     0     0     0     1\n10.0     0   139    50     7     9    13     2  ...    68  1971    53     0     0     6     1\n11.0     0    61    45    20     0     7     0  ...    28   166   237     0     0     0     4\n12.0     0     0     0     0     1     4     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     1    22     2     0  ...     0     0     0     1  1144    37     0\n14.0     3     0     0     2    29    56     0  ...     1     0     0    36    89   146     5\n15.0     0     2     0     0     0     0     0  ...     0     4     6     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      9     0     0     0     0     0     0  ...     0     1     0     0     0     0     0\n1.0      0   907     9    14     4     5     0  ...   119   261    25     0     0     0     0\n2.0      0    62   374     9     0     3     0  ...     8   261    77     0     0     0     0\n3.0      0    44    13    71     2    22     0  ...     3    35    37     0     0     0     0\n4.0      1     0     0     3   370    27     0  ...     2     1     3     0    36     3     0\n5.0      0     0     0     0     7   665     0  ...     3     0     0     7     1    13     0\n6.0      0     0     0     0     8     0     6  ...     0     0     0     0     0     0     0\n7.0     26     0     0     0    13     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0    12     0  ...     0     0     0     6     0     0     0\n9.0      0    43    15     1     9     3     0  ...   553   291    10     0     0     1     0\n10.0     0   165    49     2    13    21     0  ...    90  1939    44     0     0     1     4\n11.0     0    81    56    11     1     4     0  ...    19   144   238     0     0     2     0\n12.0     0     0     0     0     0     1     0  ...     0     0     0   192     0     0     0\n13.0     2     0     0     0    43     2     0  ...     0     0     0     4  1132    21     0\n14.0     1     2     0     0    10    51     0  ...     0     0     1    48   123   130     0\n15.0     0     3     1     0     1     0     0  ...     4     0     2     0     0     2    75\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      7     0     0     0     0     0     0  ...     0     0     1     0     0     0     0\n1.0      0   800    21    16     1     3     0  ...   149   349    14     0     0     0     0\n2.0      0   106   394    16     0     0     0  ...    37   218    25     0     0     0     0\n3.0      1    38    49   108     0     6     0  ...     6     7    12     0     0     0     0\n4.0     13     3     0     2   370    25     0  ...     7     6     8     0    12    20     0\n5.0      0     1     0     7     2   615     0  ...     1    26     0     0     3    40     0\n6.0      1     0     0     0     0     0     3  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     1     0    15     0  ...     0     0     0     3     0     1     0\n9.0      0    96     9     2     0     1     0  ...   657   140    12     0     0     0     0\n10.0     0   202    64     9     1     9     0  ...   156  1835    50     0     0     3     0\n11.0     0    55    33     2     0     0     0  ...    79    92   297     0     0     1     1\n12.0     0     0     0     0     0     0     0  ...     0     2     0   186     0     4     0\n13.0     0     0     0     0    12     2     0  ...     0     0     0     5  1166    17     0\n14.0     0     0     0     0    12    57     0  ...     3     0     7    32    87   166     0\n15.0     0     1     0     0     0     0     0  ...     5     6     2     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     19     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   936    44     5     3     4     0  ...    85   238    35     0     0     0     0\n2.0      0    76   477    20     0     2     0  ...    16   179    20     0     0     0     0\n3.0      4    28    51    91     5    23     0  ...     5     5    15     0     0     0     0\n4.0      8     7     0     1   379    19     9  ...     9     0     0     0    15    12     0\n5.0      0     1     0     0    33   647     0  ...     0     0     0     0     3     7     0\n6.0      2     0     0     0     2     0     7  ...     0     0     0     0     0     0     0\n7.0      7     0     0     0     4     3     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     8     0  ...     0     0     0     0     0     0     0\n9.0      1   147     9    12     2     2     0  ...   557   194     9     0     0     0     0\n10.0     4   290   104    17     7     9     1  ...    58  1743    72     0     0     2     0\n11.0     0    49    59    14     1     3     0  ...    42    63   327     0     0     0     0\n12.0     0     0     0     0     0    17     0  ...     0     1     0   176     0     0     0\n13.0     0     0     0     0    50     6     0  ...     0     0     0     1  1087    59     0\n14.0     0     0     0     3    79    65     2  ...     2     1     1    33    70   116     0\n15.0     0     2     0     0     0     0     0  ...     6     3     8     0     0     0    70\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results4.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.704221          0.572424           0.658924\n1    2          0.735339          0.624800           0.694008\n2    3          0.727329          0.600676           0.685136\n3    4          0.732156          0.611152           0.692033\n4    5          0.728048          0.653811           0.689050\n\nAverage Performance Over 5 Runs:\nOverall Accuracy: 0.7254\nAverage Accuracy: 0.6126\nKappa Coefficient: 0.6838\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n  (\u001b[94mOper1D\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                 \u001b[32m2,400\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n dot_5 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  [\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    \n\n\u001b[1m Total params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,400\u001b[0m (9.38 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0863\nEpoch 1: val_loss improved from inf to 1.97521, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.0630 - val_loss: 1.9752\nEpoch 2/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5166\nEpoch 2: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5167 - val_loss: 1.9752\nEpoch 3/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4446\nEpoch 3: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4459 - val_loss: 1.9752\nEpoch 4/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3742\nEpoch 4: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3757 - val_loss: 1.9752\nEpoch 5/50\n\u001b[1m 92/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4018\nEpoch 5: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4013 - val_loss: 1.9752\nEpoch 6/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3390\nEpoch 6: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3396 - val_loss: 1.9752\nEpoch 7/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3671\nEpoch 7: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3690 - val_loss: 1.9752\nEpoch 8/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4285\nEpoch 8: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4288 - val_loss: 1.9752\nEpoch 9/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4124\nEpoch 9: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4106 - val_loss: 1.9752\nEpoch 10/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3220\nEpoch 10: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3227 - val_loss: 1.9752\nEpoch 11/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3058\nEpoch 11: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3060 - val_loss: 1.9752\nEpoch 12/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4829\nEpoch 12: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4798 - val_loss: 1.9752\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3466\nEpoch 13: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3468 - val_loss: 1.9752\nEpoch 14/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3079\nEpoch 14: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3083 - val_loss: 1.9752\nEpoch 15/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3475\nEpoch 15: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3487 - val_loss: 1.9752\nEpoch 16/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3663\nEpoch 16: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3655 - val_loss: 1.9752\nEpoch 17/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4034\nEpoch 17: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4035 - val_loss: 1.9752\nEpoch 18/50\n\u001b[1m 91/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5092\nEpoch 18: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5124 - val_loss: 1.9752\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3451\nEpoch 19: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3473 - val_loss: 1.9752\nEpoch 20/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4478\nEpoch 20: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4463 - val_loss: 1.9752\nEpoch 21/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3459\nEpoch 21: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3463 - val_loss: 1.9752\nEpoch 22/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5272\nEpoch 22: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5273 - val_loss: 1.9752\nEpoch 23/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3504\nEpoch 23: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3548 - val_loss: 1.9752\nEpoch 24/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3138\nEpoch 24: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3184 - val_loss: 1.9752\nEpoch 25/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3197\nEpoch 25: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3190 - val_loss: 1.9752\nEpoch 26/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3650\nEpoch 26: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3645 - val_loss: 1.9752\nEpoch 27/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3035\nEpoch 27: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3064 - val_loss: 1.9752\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4005\nEpoch 28: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4001 - val_loss: 1.9752\nEpoch 29/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3140\nEpoch 29: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3135 - val_loss: 1.9752\nEpoch 30/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3183\nEpoch 30: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3221 - val_loss: 1.9752\nEpoch 31/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3944\nEpoch 31: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3904 - val_loss: 1.9752\nEpoch 32/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2997\nEpoch 32: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3022 - val_loss: 1.9752\nEpoch 33/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2710\nEpoch 33: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2721 - val_loss: 1.9752\nEpoch 34/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5372\nEpoch 34: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5364 - val_loss: 1.9752\nEpoch 35/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3937\nEpoch 35: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3926 - val_loss: 1.9752\nEpoch 36/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3245\nEpoch 36: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3239 - val_loss: 1.9752\nEpoch 37/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4910\nEpoch 37: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4905 - val_loss: 1.9752\nEpoch 38/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3290\nEpoch 38: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3281 - val_loss: 1.9752\nEpoch 39/50\n\u001b[1m 94/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4342\nEpoch 39: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4342 - val_loss: 1.9752\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2627\nEpoch 40: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2628 - val_loss: 1.9752\nEpoch 41/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2732\nEpoch 41: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2773 - val_loss: 1.9752\nEpoch 42/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3117\nEpoch 42: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3143 - val_loss: 1.9752\nEpoch 43/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2972\nEpoch 43: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3002 - val_loss: 1.9752\nEpoch 44/50\n\u001b[1m 96/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2914\nEpoch 44: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2924 - val_loss: 1.9752\nEpoch 45/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2549\nEpoch 45: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2563 - val_loss: 1.9752\nEpoch 46/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3437\nEpoch 46: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3445 - val_loss: 1.9752\nEpoch 47/50\n\u001b[1m 97/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3568\nEpoch 47: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3543 - val_loss: 1.9752\nEpoch 48/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2529\nEpoch 48: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2533 - val_loss: 1.9752\nEpoch 49/50\n\u001b[1m 98/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2857\nEpoch 49: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2845 - val_loss: 1.9752\nEpoch 50/50\n\u001b[1m 95/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2657\nEpoch 50: val_loss did not improve from 1.97521\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2670 - val_loss: 1.9752\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 98 177  11   5  99 149   1   4  68  19  13 106 152  12  76  36 130  30\n 115  54  56 107 134 192  38]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 10, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'kernel': 'rbf'}\nThe model shall evaluate for 6 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      0     0     0     1     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   737    20    82     0     2     0  ...   139   375    13     0     0     0     0\n2.0      0    97   404    36     0     2     0  ...    15   192    33     0     0     0     0\n3.0      0    33    37   129     0     1     0  ...     4     3    13     0     0     1     0\n4.0      2     1     2     4   389     7     0  ...    10    10     2     0     8     7     0\n5.0      0     2     0     2    11   654     0  ...     1     1     0     0     3    19     0\n6.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0      3     3     0     0     1     0     0  ...     0     4     0     0     0     0     0\n8.0      0     2     0     0     1    14     0  ...     0     0     0     0     0     3     0\n9.0      0    53     6     6     2     3     0  ...   503   330    20     0     0     0     0\n10.0     0   163    57    25     4     9     0  ...   123  1904    36     0     0     5     0\n11.0     0    60    77    44     1     1     0  ...    42   159   183     0     0     0     0\n12.0     0     1     0     0     0     7     0  ...     0     0     0   174     0    14     0\n13.0     0     0     0     0    19     1     0  ...     0     0     0     3  1107    72     0\n14.0     2     3     1     0    24    51     0  ...     3     0     1    33    82   160     0\n15.0     0     4     0     0     0     0     0  ...     9     2     0     0     0     0    72\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      8     1     0     0     1     0     0  ...     0     0     0     0     0     0     0\n1.0      0   779    28    13     2     2     0  ...    73   421    36     0     0     0     2\n2.0      0    31   429    18     0     2     0  ...     4   272    38     0     0     0     0\n3.0      0    35    32   134     1     7     0  ...     4     8     0     0     0     0     0\n4.0      0     4     0     4   398     9     0  ...     0     3     0     0    36     1     0\n5.0      0     0     0     0    14   634     0  ...     0     2     0     1     0    38     0\n6.0      0     0     0     0     2     0     7  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     1     0     6  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1    17     0  ...     0     0     0     2     0     0     0\n9.0      0    66     5     8     3     4     0  ...   561   270    10     0     0     0     1\n10.0     0   139    50     7     9    13     2  ...    68  1971    53     0     0     6     1\n11.0     0    61    45    20     0     7     0  ...    28   166   237     0     0     0     4\n12.0     0     0     0     0     1     4     0  ...     0     0     0   187     0     0     0\n13.0     0     0     0     1    22     2     0  ...     0     0     0     1  1144    37     0\n14.0     3     0     0     2    29    56     0  ...     1     0     0    36    89   146     5\n15.0     0     2     0     0     0     0     0  ...     0     4     6     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      9     0     0     0     0     0     0  ...     0     1     0     0     0     0     0\n1.0      0   907     9    14     4     5     0  ...   119   261    25     0     0     0     0\n2.0      0    62   374     9     0     3     0  ...     8   261    77     0     0     0     0\n3.0      0    44    13    71     2    22     0  ...     3    35    37     0     0     0     0\n4.0      1     0     0     3   370    27     0  ...     2     1     3     0    36     3     0\n5.0      0     0     0     0     7   665     0  ...     3     0     0     7     1    13     0\n6.0      0     0     0     0     8     0     6  ...     0     0     0     0     0     0     0\n7.0     26     0     0     0    13     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0    12     0  ...     0     0     0     6     0     0     0\n9.0      0    43    15     1     9     3     0  ...   553   291    10     0     0     1     0\n10.0     0   165    49     2    13    21     0  ...    90  1939    44     0     0     1     4\n11.0     0    81    56    11     1     4     0  ...    19   144   238     0     0     2     0\n12.0     0     0     0     0     0     1     0  ...     0     0     0   192     0     0     0\n13.0     2     0     0     0    43     2     0  ...     0     0     0     4  1132    21     0\n14.0     1     2     0     0    10    51     0  ...     0     0     1    48   123   130     0\n15.0     0     3     1     0     1     0     0  ...     4     0     2     0     0     2    75\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      7     0     0     0     0     0     0  ...     0     0     1     0     0     0     0\n1.0      0   800    21    16     1     3     0  ...   149   349    14     0     0     0     0\n2.0      0   106   394    16     0     0     0  ...    37   218    25     0     0     0     0\n3.0      1    38    49   108     0     6     0  ...     6     7    12     0     0     0     0\n4.0     13     3     0     2   370    25     0  ...     7     6     8     0    12    20     0\n5.0      0     1     0     7     2   615     0  ...     1    26     0     0     3    40     0\n6.0      1     0     0     0     0     0     3  ...     0     0     0     0     0     0     0\n7.0      0     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     1     0    15     0  ...     0     0     0     3     0     1     0\n9.0      0    96     9     2     0     1     0  ...   657   140    12     0     0     0     0\n10.0     0   202    64     9     1     9     0  ...   156  1835    50     0     0     3     0\n11.0     0    55    33     2     0     0     0  ...    79    92   297     0     0     1     1\n12.0     0     0     0     0     0     0     0  ...     0     2     0   186     0     4     0\n13.0     0     0     0     0    12     2     0  ...     0     0     0     5  1166    17     0\n14.0     0     0     0     0    12    57     0  ...     3     0     7    32    87   166     0\n15.0     0     1     0     0     0     0     0  ...     5     6     2     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     19     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   936    44     5     3     4     0  ...    85   238    35     0     0     0     0\n2.0      0    76   477    20     0     2     0  ...    16   179    20     0     0     0     0\n3.0      4    28    51    91     5    23     0  ...     5     5    15     0     0     0     0\n4.0      8     7     0     1   379    19     9  ...     9     0     0     0    15    12     0\n5.0      0     1     0     0    33   647     0  ...     0     0     0     0     3     7     0\n6.0      2     0     0     0     2     0     7  ...     0     0     0     0     0     0     0\n7.0      7     0     0     0     4     3     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     1     8     0  ...     0     0     0     0     0     0     0\n9.0      1   147     9    12     2     2     0  ...   557   194     9     0     0     0     0\n10.0     4   290   104    17     7     9     1  ...    58  1743    72     0     0     2     0\n11.0     0    49    59    14     1     3     0  ...    42    63   327     0     0     0     0\n12.0     0     0     0     0     0    17     0  ...     0     1     0   176     0     0     0\n13.0     0     0     0     0    50     6     0  ...     0     0     0     1  1087    59     0\n14.0     0     0     0     3    79    65     2  ...     2     1     1    33    70   116     0\n15.0     0     2     0     0     0     0     0  ...     6     3     8     0     0     0    70\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 6:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     22     0     0     0     1     0     0  ...     1     0     0     0     0     0     0\n1.0      0   960    19    42     2     1     0  ...    72   211    49     0     0     0     0\n2.0      0   116   315    23     0     1     0  ...    14   266    57     0     0     0     0\n3.0      0    83     4    87     3     2     1  ...     5    38     0     0     0     0     0\n4.0      0     6     0     6   403     6     0  ...     3     6     1     0    13    13     0\n5.0      0     0     0    15    11   653     0  ...     0     0     0     0     1    11     0\n6.0      0     0     0     0     1     0    22  ...     0     0     0     0     0     0     0\n7.0      6     0     0     2     0     0     2  ...     0     1     0     0     0     0     0\n8.0      0     0     0     0     0     6     0  ...     0     0     0     0     0     0     0\n9.0      0   125     5    10     0     0     0  ...   587   195     5     0     0     0     0\n10.0     0   187    37    28     7     7     0  ...   110  1900    43     0     0     4     1\n11.0     0   196    42    27     0     1     0  ...    25    82   196     0     0     0     0\n12.0     0     1     0     0     0     0     0  ...     0     0     0   170     0     8     0\n13.0     0     0     0     0    13     5     0  ...     0     0     0     1  1170    11     0\n14.0     0     2     3     1    10    63     0  ...     0    13     0    13   108   147     0\n15.0     0     2     3     0     0     0     0  ...     0    33     0     0     0     0    52\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results5.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.704221          0.572424           0.658924\n1    2          0.735339          0.624800           0.694008\n2    3          0.727329          0.600676           0.685136\n3    4          0.732156          0.611152           0.692033\n4    5          0.728048          0.653811           0.689050\n5    6          0.733388          0.687444           0.692483\n\nAverage Performance Over 6 Runs:\nOverall Accuracy: 0.7267\nAverage Accuracy: 0.6251\nKappa Coefficient: 0.6853\nFigure(800x500)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%matplotlib inline\n!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n\n# [3] with attention\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T16:00:38.387539Z","iopub.execute_input":"2025-02-19T16:00:38.388088Z","iopub.status.idle":"2025-02-19T16:14:59.663866Z","shell.execute_reply.started":"2025-02-19T16:00:38.388030Z","shell.execute_reply":"2025-02-19T16:14:59.662427Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"2025-02-19 16:00:39.092128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-19 16:00:39.117081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-19 16:00:39.124746: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\nScene:  (145, 145, 200)\n\nClassification:\nTraining samples:  512\nTest samples:  9737\n\n\nNumber of bands:  200\n**********  METHOD : SVM **********\n\t\t\t\t\t *****  #RUNS : 6  *****\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot (\u001b[94mDot\u001b[0m)                  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 33.4752\nEpoch 1: val_loss improved from inf to 25.38056, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 33.4312 - val_loss: 25.3806\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 26.1390\nEpoch 2: val_loss improved from 25.38056 to 24.55471, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 26.1473 - val_loss: 24.5547\nEpoch 3/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.6003\nEpoch 3: val_loss improved from 24.55471 to 23.80293, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 25.6113 - val_loss: 23.8029\nEpoch 4/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26.2240\nEpoch 4: val_loss did not improve from 23.80293\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 26.2803 - val_loss: 24.8458\nEpoch 5/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.9143\nEpoch 5: val_loss improved from 23.80293 to 23.05680, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 25.9245 - val_loss: 23.0568\nEpoch 6/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23.0173\nEpoch 6: val_loss improved from 23.05680 to 21.67834, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 23.0147 - val_loss: 21.6783\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.1825\nEpoch 7: val_loss improved from 21.67834 to 20.56856, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 21.1902 - val_loss: 20.5686\nEpoch 8/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.1150\nEpoch 8: val_loss improved from 20.56856 to 19.66222, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 20.1256 - val_loss: 19.6622\nEpoch 9/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19.1927\nEpoch 9: val_loss improved from 19.66222 to 18.40226, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 19.1944 - val_loss: 18.4023\nEpoch 10/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18.2167\nEpoch 10: val_loss improved from 18.40226 to 17.45225, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 18.2211 - val_loss: 17.4522\nEpoch 11/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 17.3560\nEpoch 11: val_loss improved from 17.45225 to 16.69582, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 17.3601 - val_loss: 16.6958\nEpoch 12/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.5343\nEpoch 12: val_loss improved from 16.69582 to 15.60261, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 16.5337 - val_loss: 15.6026\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.6085\nEpoch 13: val_loss did not improve from 15.60261\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 15.6219 - val_loss: 16.2538\nEpoch 14/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.8201\nEpoch 14: val_loss did not improve from 15.60261\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 16.8699 - val_loss: 22.2272\nEpoch 15/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.1538\nEpoch 15: val_loss improved from 15.60261 to 15.36665, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 22.1197 - val_loss: 15.3666\nEpoch 16/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.1677\nEpoch 16: val_loss improved from 15.36665 to 15.19090, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 15.1583 - val_loss: 15.1909\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.0050\nEpoch 17: val_loss improved from 15.19090 to 13.36689, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 13.9955 - val_loss: 13.3669\nEpoch 18/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.9937\nEpoch 18: val_loss improved from 13.36689 to 12.82938, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.9922 - val_loss: 12.8294\nEpoch 19/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.4268\nEpoch 19: val_loss improved from 12.82938 to 12.52713, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.4292 - val_loss: 12.5271\nEpoch 20/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.1778\nEpoch 20: val_loss improved from 12.52713 to 12.01036, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 12.1802 - val_loss: 12.0104\nEpoch 21/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.7293\nEpoch 21: val_loss improved from 12.01036 to 11.06619, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 11.7269 - val_loss: 11.0662\nEpoch 22/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.8190\nEpoch 22: val_loss improved from 11.06619 to 10.10030, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.8120 - val_loss: 10.1003\nEpoch 23/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.9660\nEpoch 23: val_loss improved from 10.10030 to 9.48093, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.9649 - val_loss: 9.4809\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.3726\nEpoch 24: val_loss improved from 9.48093 to 9.41955, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 9.3759 - val_loss: 9.4195\nEpoch 25/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.3691\nEpoch 25: val_loss did not improve from 9.41955\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 10.4837 - val_loss: 12.6013\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.8616\nEpoch 26: val_loss did not improve from 9.41955\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 14.8381 - val_loss: 10.3161\nEpoch 27/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.4939\nEpoch 27: val_loss did not improve from 9.41955\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 10.4984 - val_loss: 10.8826\nEpoch 28/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.4547\nEpoch 28: val_loss improved from 9.41955 to 8.64689, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.4339 - val_loss: 8.6469\nEpoch 29/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.2654\nEpoch 29: val_loss improved from 8.64689 to 8.35759, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.2690 - val_loss: 8.3576\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.3334\nEpoch 30: val_loss did not improve from 8.35759\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.3594 - val_loss: 10.4602\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.3683\nEpoch 31: val_loss did not improve from 8.35759\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.3639 - val_loss: 9.6591\nEpoch 32/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.6738\nEpoch 32: val_loss improved from 8.35759 to 8.05464, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.6921 - val_loss: 8.0546\nEpoch 33/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.3552\nEpoch 33: val_loss improved from 8.05464 to 7.90084, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.3664 - val_loss: 7.9008\nEpoch 34/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.1023\nEpoch 34: val_loss improved from 7.90084 to 7.29707, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.0992 - val_loss: 7.2971\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7737\nEpoch 35: val_loss did not improve from 7.29707\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.7658 - val_loss: 7.6994\nEpoch 36/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9054\nEpoch 36: val_loss did not improve from 7.29707\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 6.8914 - val_loss: 7.6721\nEpoch 37/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.4163\nEpoch 37: val_loss improved from 7.29707 to 6.71938, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.4141 - val_loss: 6.7194\nEpoch 38/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.9382\nEpoch 38: val_loss improved from 6.71938 to 5.66067, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.9339 - val_loss: 5.6607\nEpoch 39/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4801\nEpoch 39: val_loss did not improve from 5.66067\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.4871 - val_loss: 6.6042\nEpoch 40/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.4356\nEpoch 40: val_loss did not improve from 5.66067\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.5002 - val_loss: 14.6485\nEpoch 41/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.0372\nEpoch 41: val_loss did not improve from 5.66067\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.0360 - val_loss: 9.8492\nEpoch 42/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.1929\nEpoch 42: val_loss did not improve from 5.66067\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.1921 - val_loss: 7.6431\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.4595\nEpoch 43: val_loss did not improve from 5.66067\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.4688 - val_loss: 5.9686\nEpoch 44/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.8214\nEpoch 44: val_loss improved from 5.66067 to 5.28041, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.8195 - val_loss: 5.2804\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1893\nEpoch 45: val_loss did not improve from 5.28041\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5.1968 - val_loss: 5.5842\nEpoch 46/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.9797\nEpoch 46: val_loss did not improve from 5.28041\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.0144 - val_loss: 7.2048\nEpoch 47/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.9733\nEpoch 47: val_loss did not improve from 5.28041\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 7.9749 - val_loss: 6.5757\nEpoch 48/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.5054\nEpoch 48: val_loss did not improve from 5.28041\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5.5130 - val_loss: 5.8197\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1341\nEpoch 49: val_loss improved from 5.28041 to 4.91196, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run0.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 5.1334 - val_loss: 4.9120\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5323\nEpoch 50: val_loss did not improve from 4.91196\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 4.5424 - val_loss: 5.6308\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 46 197 140  91  72 152 182  47 177  66 133 137  37  49  68  94  65  69\n  43  57  63  48  58  40  81]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 1 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   749    33    27     0     2     0  ...    86   450    21     0     0     0     0\n2.0      0    75   394    16     0     0     0  ...    18   211    65     0     0     0     0\n3.0      0    17    47   105     1     2     0  ...     3    18    28     0     0     0     0\n4.0      5     5     0     2   396    11     0  ...     3    14     5     0     7     0     0\n5.0      0     0     0     8     4   626     0  ...     0     1     0     1     8    45     0\n6.0      1     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0     15    18     0     0     0     0     0  ...     0     2     0     0     0     0     0\n8.0      0    16     0     0     0     0     0  ...     0     0     0     1     0     3     0\n9.0      0    76     6     4     0     3     0  ...   380   438    16     0     0     0     0\n10.0     0   173    76    12     2    13     0  ...   195  1822    27     0     0     6     1\n11.0     0    19   121    32     1     1     0  ...    11    57   322     0     0     1     2\n12.0     0     1     0     0     0     1     0  ...     0     1     0   192     0     1     0\n13.0     0     0     0     0    23     3     0  ...     0     0     0    10  1090    76     0\n14.0     4     8     5     6    21    37     0  ...     0     0     0    23    55   202     0\n15.0     0     3     4     0     0     0     0  ...     9     4     0     0     0     0    67\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results0.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.695081          0.582247           0.648307\n\nAverage Performance Over 1 Runs:\nOverall Accuracy: 0.6951\nAverage Accuracy: 0.5822\nKappa Coefficient: 0.6483\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_1 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 32.5203\nEpoch 1: val_loss improved from inf to 34.15582, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 32.4250 - val_loss: 34.1558\nEpoch 2/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.6111\nEpoch 2: val_loss improved from 34.15582 to 33.57347, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 30.6231 - val_loss: 33.5735\nEpoch 3/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 27.7766\nEpoch 3: val_loss improved from 33.57347 to 25.77802, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 27.7344 - val_loss: 25.7780\nEpoch 4/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25.7986\nEpoch 4: val_loss did not improve from 25.77802\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 25.8203 - val_loss: 25.9244\nEpoch 5/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23.5171\nEpoch 5: val_loss did not improve from 25.77802\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 23.5153 - val_loss: 29.8975\nEpoch 6/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.9163\nEpoch 6: val_loss improved from 25.77802 to 22.50282, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 23.8871 - val_loss: 22.5028\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.3567\nEpoch 7: val_loss did not improve from 22.50282\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 22.3517 - val_loss: 35.2041\nEpoch 8/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.6653\nEpoch 8: val_loss did not improve from 22.50282\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 25.6479 - val_loss: 30.0672\nEpoch 9/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.9382\nEpoch 9: val_loss did not improve from 22.50282\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 25.8696 - val_loss: 23.2986\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.4164\nEpoch 10: val_loss improved from 22.50282 to 21.28776, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 23.3963 - val_loss: 21.2878\nEpoch 11/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.6042\nEpoch 11: val_loss did not improve from 21.28776\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 20.5884 - val_loss: 21.9505\nEpoch 12/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 19.6214\nEpoch 12: val_loss improved from 21.28776 to 18.46066, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 19.5963 - val_loss: 18.4607\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19.4593\nEpoch 13: val_loss did not improve from 18.46066\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 19.4622 - val_loss: 25.4767\nEpoch 14/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19.7064\nEpoch 14: val_loss did not improve from 18.46066\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 19.6787 - val_loss: 20.3940\nEpoch 15/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19.7746\nEpoch 15: val_loss did not improve from 18.46066\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 19.7580 - val_loss: 21.5168\nEpoch 16/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 18.2145\nEpoch 16: val_loss improved from 18.46066 to 17.88660, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 18.1990 - val_loss: 17.8866\nEpoch 17/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.5627\nEpoch 17: val_loss improved from 17.88660 to 15.40263, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 16.5592 - val_loss: 15.4026\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.9904\nEpoch 18: val_loss improved from 15.40263 to 14.55886, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 14.9902 - val_loss: 14.5589\nEpoch 19/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 14.2276\nEpoch 19: val_loss improved from 14.55886 to 13.73911, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 14.2270 - val_loss: 13.7391\nEpoch 20/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.4601\nEpoch 20: val_loss improved from 13.73911 to 12.94038, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 13.4588 - val_loss: 12.9404\nEpoch 21/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.7328\nEpoch 21: val_loss improved from 12.94038 to 12.64833, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 12.7305 - val_loss: 12.6483\nEpoch 22/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.1221\nEpoch 22: val_loss improved from 12.64833 to 12.08128, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.1186 - val_loss: 12.0813\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.4933\nEpoch 23: val_loss improved from 12.08128 to 11.66550, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 11.4910 - val_loss: 11.6655\nEpoch 24/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 10.9584\nEpoch 24: val_loss improved from 11.66550 to 11.54885, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.9580 - val_loss: 11.5488\nEpoch 25/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.5912\nEpoch 25: val_loss did not improve from 11.54885\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 10.5942 - val_loss: 12.7541\nEpoch 26/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.8261\nEpoch 26: val_loss improved from 11.54885 to 11.23996, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 10.8352 - val_loss: 11.2400\nEpoch 27/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.2804\nEpoch 27: val_loss improved from 11.23996 to 10.02445, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 10.2750 - val_loss: 10.0245\nEpoch 28/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.4108\nEpoch 28: val_loss improved from 10.02445 to 9.02870, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.4087 - val_loss: 9.0287\nEpoch 29/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.7574\nEpoch 29: val_loss improved from 9.02870 to 8.26323, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.7561 - val_loss: 8.2632\nEpoch 30/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.4107\nEpoch 30: val_loss improved from 8.26323 to 7.64243, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.4086 - val_loss: 7.6424\nEpoch 31/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.4927\nEpoch 31: val_loss did not improve from 7.64243\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.4945 - val_loss: 9.7002\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.3119\nEpoch 32: val_loss did not improve from 7.64243\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 13.3468 - val_loss: 11.6155\nEpoch 33/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.1542\nEpoch 33: val_loss did not improve from 7.64243\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 11.1328 - val_loss: 9.0031\nEpoch 34/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5607\nEpoch 34: val_loss did not improve from 7.64243\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 8.5549 - val_loss: 10.3724\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6801\nEpoch 35: val_loss improved from 7.64243 to 6.50430, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.6684 - val_loss: 6.5043\nEpoch 36/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3855\nEpoch 36: val_loss did not improve from 6.50430\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.3889 - val_loss: 8.9121\nEpoch 37/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9533\nEpoch 37: val_loss improved from 6.50430 to 6.17590, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.9475 - val_loss: 6.1759\nEpoch 38/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.4116\nEpoch 38: val_loss did not improve from 6.17590\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.4224 - val_loss: 8.6363\nEpoch 39/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.2479\nEpoch 39: val_loss improved from 6.17590 to 5.77488, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.2375 - val_loss: 5.7749\nEpoch 40/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.5466\nEpoch 40: val_loss improved from 5.77488 to 5.52586, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.5346 - val_loss: 5.5259\nEpoch 41/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0821\nEpoch 41: val_loss improved from 5.52586 to 4.82277, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run1.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 5.0828 - val_loss: 4.8228\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.0778\nEpoch 42: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5.0838 - val_loss: 11.5915\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.8091\nEpoch 43: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 9.7917 - val_loss: 13.4186\nEpoch 44/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.0583\nEpoch 44: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 11.1601 - val_loss: 11.5508\nEpoch 45/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.3699\nEpoch 45: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 11.3673 - val_loss: 10.7484\nEpoch 46/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.0354\nEpoch 46: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 8.0290 - val_loss: 7.8241\nEpoch 47/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.2824\nEpoch 47: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.2658 - val_loss: 8.2308\nEpoch 48/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.2478\nEpoch 48: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.2436 - val_loss: 5.2567\nEpoch 49/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.2147\nEpoch 49: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.2092 - val_loss: 7.4175\nEpoch 50/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.5690\nEpoch 50: val_loss did not improve from 4.82277\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5.5694 - val_loss: 4.9989\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [114 140  40 152 189  42 160 108 130 112 126 164 107 118  92 125 178 113\n  43 170  13  53  44 177 134]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 2 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   749    33    27     0     2     0  ...    86   450    21     0     0     0     0\n2.0      0    75   394    16     0     0     0  ...    18   211    65     0     0     0     0\n3.0      0    17    47   105     1     2     0  ...     3    18    28     0     0     0     0\n4.0      5     5     0     2   396    11     0  ...     3    14     5     0     7     0     0\n5.0      0     0     0     8     4   626     0  ...     0     1     0     1     8    45     0\n6.0      1     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0     15    18     0     0     0     0     0  ...     0     2     0     0     0     0     0\n8.0      0    16     0     0     0     0     0  ...     0     0     0     1     0     3     0\n9.0      0    76     6     4     0     3     0  ...   380   438    16     0     0     0     0\n10.0     0   173    76    12     2    13     0  ...   195  1822    27     0     0     6     1\n11.0     0    19   121    32     1     1     0  ...    11    57   322     0     0     1     2\n12.0     0     1     0     0     0     1     0  ...     0     1     0   192     0     1     0\n13.0     0     0     0     0    23     3     0  ...     0     0     0    10  1090    76     0\n14.0     4     8     5     6    21    37     0  ...     0     0     0    23    55   202     0\n15.0     0     3     4     0     0     0     0  ...     9     4     0     0     0     0    67\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   778    16    15     2     2     0  ...   110   421    11     0     0     0     1\n2.0      0    22   416    53     0     0     0  ...     0   274    29     0     0     0     0\n3.0      0     5    21   181     1     4     0  ...     2     6     1     0     0     0     0\n4.0      0     2     0     2   380    15     1  ...     0     7     0     0    51     0     0\n5.0      0     0     0     0    15   621     0  ...     0     1     0     0     1    51     0\n6.0      0     0     0     0     1     0    10  ...     0     0     0     0     0     0     0\n7.0      9     0     0     0     1     0     5  ...     0     0     0     0     0     0     0\n8.0      0     0     0     5     5     4     0  ...     0     0     0     5     0     1     0\n9.0      0   135     1     4    11     3     0  ...   497   272     6     0     0     0     0\n10.0     0   182    36    30     9    14     1  ...    68  1935    41     0     0     3     1\n11.0     0    26    55    25     0     5     0  ...     3    77   373     0     0     0     4\n12.0     0     0     0     2     0     0     0  ...     0     0     0   190     0     0     0\n13.0     0     0     0     0    30     3     0  ...     0     0     0     4  1109    61     0\n14.0     0     0     1     0    37    88     0  ...     0     0     0    30    71   138     2\n15.0     0     3     0     0     0     0     0  ...     1     5     3     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results1.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.695081          0.582247           0.648307\n1    2          0.737291          0.684670           0.697336\n\nAverage Performance Over 2 Runs:\nOverall Accuracy: 0.7162\nAverage Accuracy: 0.6335\nKappa Coefficient: 0.6728\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_2 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 31.1366\nEpoch 1: val_loss improved from inf to 25.73653, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 31.0882 - val_loss: 25.7365\nEpoch 2/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.9034\nEpoch 2: val_loss improved from 25.73653 to 24.51036, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 25.8997 - val_loss: 24.5104\nEpoch 3/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.8443\nEpoch 3: val_loss improved from 24.51036 to 23.78682, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 24.8285 - val_loss: 23.7868\nEpoch 4/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 27.1538\nEpoch 4: val_loss did not improve from 23.78682\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 27.1714 - val_loss: 24.9626\nEpoch 5/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 26.5651\nEpoch 5: val_loss improved from 23.78682 to 21.68315, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 26.4558 - val_loss: 21.6831\nEpoch 6/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.1758\nEpoch 6: val_loss improved from 21.68315 to 21.03993, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 22.1674 - val_loss: 21.0399\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21.3473\nEpoch 7: val_loss improved from 21.03993 to 20.49067, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 21.3353 - val_loss: 20.4907\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.1699\nEpoch 8: val_loss improved from 20.49067 to 20.15569, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 21.1525 - val_loss: 20.1557\nEpoch 9/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.8073\nEpoch 9: val_loss improved from 20.15569 to 19.54175, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 20.8011 - val_loss: 19.5417\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19.8680\nEpoch 10: val_loss improved from 19.54175 to 18.66121, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 19.8561 - val_loss: 18.6612\nEpoch 11/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18.4243\nEpoch 11: val_loss improved from 18.66121 to 18.25475, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 18.4215 - val_loss: 18.2547\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 17.3952\nEpoch 12: val_loss did not improve from 18.25475\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 17.4028 - val_loss: 18.3472\nEpoch 13/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.0836\nEpoch 13: val_loss did not improve from 18.25475\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 17.0900 - val_loss: 18.5318\nEpoch 14/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.5545\nEpoch 14: val_loss improved from 18.25475 to 16.37577, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 17.5514 - val_loss: 16.3758\nEpoch 15/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.3324\nEpoch 15: val_loss improved from 16.37577 to 14.62854, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 17.3156 - val_loss: 14.6285\nEpoch 16/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.2892\nEpoch 16: val_loss did not improve from 14.62854\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 17.2541 - val_loss: 15.2267\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.9226\nEpoch 17: val_loss improved from 14.62854 to 14.06667, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 16.8978 - val_loss: 14.0667\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.9364\nEpoch 18: val_loss improved from 14.06667 to 13.45039, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 13.9225 - val_loss: 13.4504\nEpoch 19/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.5474\nEpoch 19: val_loss improved from 13.45039 to 12.52386, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 12.5360 - val_loss: 12.5239\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.8039\nEpoch 20: val_loss improved from 12.52386 to 11.65321, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 11.8016 - val_loss: 11.6532\nEpoch 21/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.1638\nEpoch 21: val_loss improved from 11.65321 to 10.92826, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 11.1627 - val_loss: 10.9283\nEpoch 22/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.5259\nEpoch 22: val_loss improved from 10.92826 to 10.25225, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.5261 - val_loss: 10.2523\nEpoch 23/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.8681\nEpoch 23: val_loss improved from 10.25225 to 9.66172, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.8702 - val_loss: 9.6617\nEpoch 24/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.4265\nEpoch 24: val_loss improved from 9.66172 to 9.30513, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.4282 - val_loss: 9.3051\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.9508\nEpoch 25: val_loss improved from 9.30513 to 9.04561, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.9500 - val_loss: 9.0456\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.6430\nEpoch 26: val_loss did not improve from 9.04561\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 8.6489 - val_loss: 10.6285\nEpoch 27/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.5001\nEpoch 27: val_loss improved from 9.04561 to 8.72454, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.4650 - val_loss: 8.7245\nEpoch 28/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2790\nEpoch 28: val_loss did not improve from 8.72454\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.3076 - val_loss: 10.2380\nEpoch 29/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.6527\nEpoch 29: val_loss did not improve from 8.72454\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.7346 - val_loss: 15.0212\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.6311\nEpoch 30: val_loss did not improve from 8.72454\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 14.5205 - val_loss: 11.0256\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.8600\nEpoch 31: val_loss did not improve from 8.72454\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.8380 - val_loss: 10.0940\nEpoch 32/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.8359\nEpoch 32: val_loss did not improve from 8.72454\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 8.8150 - val_loss: 9.2848\nEpoch 33/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.7638\nEpoch 33: val_loss improved from 8.72454 to 8.47986, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.7433 - val_loss: 8.4799\nEpoch 34/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.2012\nEpoch 34: val_loss improved from 8.47986 to 7.95284, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 7.1886 - val_loss: 7.9528\nEpoch 35/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.8320\nEpoch 35: val_loss improved from 7.95284 to 7.68189, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.8220 - val_loss: 7.6819\nEpoch 36/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.3869\nEpoch 36: val_loss improved from 7.68189 to 7.65671, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 6.3835 - val_loss: 7.6567\nEpoch 37/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.0764\nEpoch 37: val_loss improved from 7.65671 to 6.11361, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 6.0630 - val_loss: 6.1136\nEpoch 38/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.9343\nEpoch 38: val_loss improved from 6.11361 to 5.26749, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.9247 - val_loss: 5.2675\nEpoch 39/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4243\nEpoch 39: val_loss improved from 5.26749 to 5.04147, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.4177 - val_loss: 5.0415\nEpoch 40/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1226\nEpoch 40: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.1120 - val_loss: 5.7462\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.7473\nEpoch 41: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.7773 - val_loss: 19.3826\nEpoch 42/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5216\nEpoch 42: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 8.5028 - val_loss: 6.1711\nEpoch 43/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.9803\nEpoch 43: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.9348 - val_loss: 6.5248\nEpoch 44/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6116\nEpoch 44: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.6201 - val_loss: 8.0634\nEpoch 45/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.9239\nEpoch 45: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 5.9061 - val_loss: 5.3701\nEpoch 46/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.3330\nEpoch 46: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.3317 - val_loss: 7.5407\nEpoch 47/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.1919\nEpoch 47: val_loss did not improve from 5.04147\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 8.1807 - val_loss: 5.1095\nEpoch 48/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.5860\nEpoch 48: val_loss improved from 5.04147 to 4.27961, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 5.5684 - val_loss: 4.2796\nEpoch 49/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.7061\nEpoch 49: val_loss improved from 4.27961 to 4.04611, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run2.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 5.6959 - val_loss: 4.0461\nEpoch 50/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.8385\nEpoch 50: val_loss did not improve from 4.04611\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.8355 - val_loss: 4.7355\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [131  37 147 162  68  71 168  42 106  69  80  48  38 101  47  50  64 166\n  52  66  40  53  49  59  46]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 3 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   749    33    27     0     2     0  ...    86   450    21     0     0     0     0\n2.0      0    75   394    16     0     0     0  ...    18   211    65     0     0     0     0\n3.0      0    17    47   105     1     2     0  ...     3    18    28     0     0     0     0\n4.0      5     5     0     2   396    11     0  ...     3    14     5     0     7     0     0\n5.0      0     0     0     8     4   626     0  ...     0     1     0     1     8    45     0\n6.0      1     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0     15    18     0     0     0     0     0  ...     0     2     0     0     0     0     0\n8.0      0    16     0     0     0     0     0  ...     0     0     0     1     0     3     0\n9.0      0    76     6     4     0     3     0  ...   380   438    16     0     0     0     0\n10.0     0   173    76    12     2    13     0  ...   195  1822    27     0     0     6     1\n11.0     0    19   121    32     1     1     0  ...    11    57   322     0     0     1     2\n12.0     0     1     0     0     0     1     0  ...     0     1     0   192     0     1     0\n13.0     0     0     0     0    23     3     0  ...     0     0     0    10  1090    76     0\n14.0     4     8     5     6    21    37     0  ...     0     0     0    23    55   202     0\n15.0     0     3     4     0     0     0     0  ...     9     4     0     0     0     0    67\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   778    16    15     2     2     0  ...   110   421    11     0     0     0     1\n2.0      0    22   416    53     0     0     0  ...     0   274    29     0     0     0     0\n3.0      0     5    21   181     1     4     0  ...     2     6     1     0     0     0     0\n4.0      0     2     0     2   380    15     1  ...     0     7     0     0    51     0     0\n5.0      0     0     0     0    15   621     0  ...     0     1     0     0     1    51     0\n6.0      0     0     0     0     1     0    10  ...     0     0     0     0     0     0     0\n7.0      9     0     0     0     1     0     5  ...     0     0     0     0     0     0     0\n8.0      0     0     0     5     5     4     0  ...     0     0     0     5     0     1     0\n9.0      0   135     1     4    11     3     0  ...   497   272     6     0     0     0     0\n10.0     0   182    36    30     9    14     1  ...    68  1935    41     0     0     3     1\n11.0     0    26    55    25     0     5     0  ...     3    77   373     0     0     0     4\n12.0     0     0     0     2     0     0     0  ...     0     0     0   190     0     0     0\n13.0     0     0     0     0    30     3     0  ...     0     0     0     4  1109    61     0\n14.0     0     0     1     0    37    88     0  ...     0     0     0    30    71   138     2\n15.0     0     3     0     0     0     0     0  ...     1     5     3     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     1     0     0  ...     0     0     1     0     0     0     0\n1.0      0   846    24    31     5     5     0  ...    50   376     8     0     0     0     0\n2.0      0   106   393    15     2     2     0  ...    17   201    57     0     0     1     0\n3.0      3    73     8    55     1    29     0  ...     2    25    33     0     0     0     0\n4.0     12     0     1     8   406     6     1  ...     0     4     3     0    10     7     0\n5.0      0     0     0     0    13   660     0  ...     5     0     0     1     3    14     0\n6.0      1     0     0     0     5     0    16  ...     0     0     0     0     0     0     0\n7.0     11     0     0     0     1     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     6     0  ...     0     0     0     1     0     1     0\n9.0      0    80    10     5    10     2     0  ...   261   543    13     0     0     2     0\n10.0     0   186    78    11    19    13     1  ...    80  1866    73     0     0     3     1\n11.0     0    59    35    31     0     9     0  ...     4    49   369     0     0     0     0\n12.0     0     0     0     1     0     0     0  ...     0     0     0   192     0     0     0\n13.0     0     0     0     2    43     2     0  ...     0     2     0     2  1120    33     0\n14.0     1     0     0     0    13    44     0  ...     0     3     3    10    89   203     2\n15.0     0     0     6     1     0     0     0  ...     2     0     5     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results2.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.695081          0.582247           0.648307\n1    2          0.737291          0.684670           0.697336\n2    3          0.711821          0.670818           0.666978\n\nAverage Performance Over 3 Runs:\nOverall Accuracy: 0.7147\nAverage Accuracy: 0.6459\nKappa Coefficient: 0.6709\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_3 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 56.8435\nEpoch 1: val_loss improved from inf to 26.55679, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 56.3855 - val_loss: 26.5568\nEpoch 2/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26.0891\nEpoch 2: val_loss improved from 26.55679 to 26.00789, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 26.0957 - val_loss: 26.0079\nEpoch 3/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.2747\nEpoch 3: val_loss improved from 26.00789 to 24.12273, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 25.2723 - val_loss: 24.1227\nEpoch 4/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.8823\nEpoch 4: val_loss improved from 24.12273 to 23.31990, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 23.8807 - val_loss: 23.3199\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.2442\nEpoch 5: val_loss improved from 23.31990 to 22.99453, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 23.2412 - val_loss: 22.9945\nEpoch 6/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.7783\nEpoch 6: val_loss did not improve from 22.99453\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 22.7939 - val_loss: 23.7303\nEpoch 7/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.4877\nEpoch 7: val_loss did not improve from 22.99453\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 22.4874 - val_loss: 24.0015\nEpoch 8/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 22.6978\nEpoch 8: val_loss improved from 22.99453 to 22.76166, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 22.7025 - val_loss: 22.7617\nEpoch 9/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.4450\nEpoch 9: val_loss improved from 22.76166 to 20.96401, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 23.4259 - val_loss: 20.9640\nEpoch 10/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.0593\nEpoch 10: val_loss improved from 20.96401 to 20.16770, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 21.0652 - val_loss: 20.1677\nEpoch 11/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.1540\nEpoch 11: val_loss improved from 20.16770 to 18.96096, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 21.1708 - val_loss: 18.9610\nEpoch 12/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.3142\nEpoch 12: val_loss did not improve from 18.96096\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 22.2958 - val_loss: 19.7707\nEpoch 13/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18.2640\nEpoch 13: val_loss improved from 18.96096 to 16.88167, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 18.2390 - val_loss: 16.8817\nEpoch 14/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.4191\nEpoch 14: val_loss did not improve from 16.88167\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 17.4250 - val_loss: 17.1310\nEpoch 15/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.6325\nEpoch 15: val_loss improved from 16.88167 to 15.98992, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 16.6321 - val_loss: 15.9899\nEpoch 16/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.4108\nEpoch 16: val_loss improved from 15.98992 to 15.90486, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 16.4157 - val_loss: 15.9049\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.1922\nEpoch 17: val_loss improved from 15.90486 to 15.26686, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 16.1943 - val_loss: 15.2669\nEpoch 18/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.9405\nEpoch 18: val_loss improved from 15.26686 to 14.86798, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 15.9316 - val_loss: 14.8680\nEpoch 19/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.5743\nEpoch 19: val_loss improved from 14.86798 to 13.90415, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 14.5608 - val_loss: 13.9042\nEpoch 20/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.5176\nEpoch 20: val_loss improved from 13.90415 to 13.19728, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 13.5111 - val_loss: 13.1973\nEpoch 21/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.6862\nEpoch 21: val_loss improved from 13.19728 to 12.52589, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 12.6821 - val_loss: 12.5259\nEpoch 22/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.0205\nEpoch 22: val_loss improved from 12.52589 to 11.91251, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.0198 - val_loss: 11.9125\nEpoch 23/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.4734\nEpoch 23: val_loss improved from 11.91251 to 11.52921, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 11.4759 - val_loss: 11.5292\nEpoch 24/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.9212\nEpoch 24: val_loss improved from 11.52921 to 11.08641, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.9223 - val_loss: 11.0864\nEpoch 25/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 10.3692\nEpoch 25: val_loss improved from 11.08641 to 10.67837, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.3717 - val_loss: 10.6784\nEpoch 26/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.8913\nEpoch 26: val_loss improved from 10.67837 to 10.29320, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.8931 - val_loss: 10.2932\nEpoch 27/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.6662\nEpoch 27: val_loss did not improve from 10.29320\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.6971 - val_loss: 12.9254\nEpoch 28/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.4808\nEpoch 28: val_loss did not improve from 10.29320\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.4772 - val_loss: 11.2275\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.6494\nEpoch 29: val_loss improved from 10.29320 to 9.43809, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 11.6401 - val_loss: 9.4381\nEpoch 30/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.0615\nEpoch 30: val_loss improved from 9.43809 to 9.33013, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.1028 - val_loss: 9.3301\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.7325\nEpoch 31: val_loss improved from 9.33013 to 8.34910, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.7497 - val_loss: 8.3491\nEpoch 32/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.7253\nEpoch 32: val_loss improved from 8.34910 to 7.49886, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.7037 - val_loss: 7.4989\nEpoch 33/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6599\nEpoch 33: val_loss improved from 7.49886 to 6.84512, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 7.6601 - val_loss: 6.8451\nEpoch 34/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3608\nEpoch 34: val_loss did not improve from 6.84512\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 7.3596 - val_loss: 7.5569\nEpoch 35/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7973\nEpoch 35: val_loss improved from 6.84512 to 6.38410, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 6.7924 - val_loss: 6.3841\nEpoch 36/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.6022\nEpoch 36: val_loss did not improve from 6.38410\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.5941 - val_loss: 6.4434\nEpoch 37/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.0160\nEpoch 37: val_loss did not improve from 6.38410\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.0204 - val_loss: 9.0162\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7143\nEpoch 38: val_loss improved from 6.38410 to 6.03019, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.7071 - val_loss: 6.0302\nEpoch 39/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.2559\nEpoch 39: val_loss did not improve from 6.03019\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 7.3437 - val_loss: 11.8602\nEpoch 40/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.5087\nEpoch 40: val_loss did not improve from 6.03019\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 11.4841 - val_loss: 6.4970\nEpoch 41/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.3678\nEpoch 41: val_loss improved from 6.03019 to 5.78185, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.3450 - val_loss: 5.7818\nEpoch 42/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.6844\nEpoch 42: val_loss did not improve from 5.78185\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.6748 - val_loss: 5.8329\nEpoch 43/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.2914\nEpoch 43: val_loss did not improve from 5.78185\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.2951 - val_loss: 6.2314\nEpoch 44/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.3379\nEpoch 44: val_loss did not improve from 5.78185\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.3429 - val_loss: 6.4327\nEpoch 45/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7638\nEpoch 45: val_loss improved from 5.78185 to 5.52268, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.7506 - val_loss: 5.5227\nEpoch 46/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.1713\nEpoch 46: val_loss improved from 5.52268 to 4.49518, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 7.1672 - val_loss: 4.4952\nEpoch 47/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.8186\nEpoch 47: val_loss improved from 4.49518 to 4.24765, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run3.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 5.8184 - val_loss: 4.2476\nEpoch 48/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1495\nEpoch 48: val_loss did not improve from 4.24765\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.1452 - val_loss: 4.3407\nEpoch 49/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.6238\nEpoch 49: val_loss did not improve from 4.24765\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 4.6283 - val_loss: 5.1907\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.3721\nEpoch 50: val_loss did not improve from 4.24765\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4.3776 - val_loss: 5.0152\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 13  38  22 113 182 120 118  15 185 141 158 137 128  42  43  71  51 171\n  23 124 151  64 132 111 180]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\n/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n  warnings.warn(\nSVM Train Finished.\n\nBest paramters:{'C': 10, 'decision_function_shape': 'ovo', 'kernel': 'linear'}\nThe model shall evaluate for 4 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   749    33    27     0     2     0  ...    86   450    21     0     0     0     0\n2.0      0    75   394    16     0     0     0  ...    18   211    65     0     0     0     0\n3.0      0    17    47   105     1     2     0  ...     3    18    28     0     0     0     0\n4.0      5     5     0     2   396    11     0  ...     3    14     5     0     7     0     0\n5.0      0     0     0     8     4   626     0  ...     0     1     0     1     8    45     0\n6.0      1     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0     15    18     0     0     0     0     0  ...     0     2     0     0     0     0     0\n8.0      0    16     0     0     0     0     0  ...     0     0     0     1     0     3     0\n9.0      0    76     6     4     0     3     0  ...   380   438    16     0     0     0     0\n10.0     0   173    76    12     2    13     0  ...   195  1822    27     0     0     6     1\n11.0     0    19   121    32     1     1     0  ...    11    57   322     0     0     1     2\n12.0     0     1     0     0     0     1     0  ...     0     1     0   192     0     1     0\n13.0     0     0     0     0    23     3     0  ...     0     0     0    10  1090    76     0\n14.0     4     8     5     6    21    37     0  ...     0     0     0    23    55   202     0\n15.0     0     3     4     0     0     0     0  ...     9     4     0     0     0     0    67\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   778    16    15     2     2     0  ...   110   421    11     0     0     0     1\n2.0      0    22   416    53     0     0     0  ...     0   274    29     0     0     0     0\n3.0      0     5    21   181     1     4     0  ...     2     6     1     0     0     0     0\n4.0      0     2     0     2   380    15     1  ...     0     7     0     0    51     0     0\n5.0      0     0     0     0    15   621     0  ...     0     1     0     0     1    51     0\n6.0      0     0     0     0     1     0    10  ...     0     0     0     0     0     0     0\n7.0      9     0     0     0     1     0     5  ...     0     0     0     0     0     0     0\n8.0      0     0     0     5     5     4     0  ...     0     0     0     5     0     1     0\n9.0      0   135     1     4    11     3     0  ...   497   272     6     0     0     0     0\n10.0     0   182    36    30     9    14     1  ...    68  1935    41     0     0     3     1\n11.0     0    26    55    25     0     5     0  ...     3    77   373     0     0     0     4\n12.0     0     0     0     2     0     0     0  ...     0     0     0   190     0     0     0\n13.0     0     0     0     0    30     3     0  ...     0     0     0     4  1109    61     0\n14.0     0     0     1     0    37    88     0  ...     0     0     0    30    71   138     2\n15.0     0     3     0     0     0     0     0  ...     1     5     3     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     1     0     0  ...     0     0     1     0     0     0     0\n1.0      0   846    24    31     5     5     0  ...    50   376     8     0     0     0     0\n2.0      0   106   393    15     2     2     0  ...    17   201    57     0     0     1     0\n3.0      3    73     8    55     1    29     0  ...     2    25    33     0     0     0     0\n4.0     12     0     1     8   406     6     1  ...     0     4     3     0    10     7     0\n5.0      0     0     0     0    13   660     0  ...     5     0     0     1     3    14     0\n6.0      1     0     0     0     5     0    16  ...     0     0     0     0     0     0     0\n7.0     11     0     0     0     1     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     6     0  ...     0     0     0     1     0     1     0\n9.0      0    80    10     5    10     2     0  ...   261   543    13     0     0     2     0\n10.0     0   186    78    11    19    13     1  ...    80  1866    73     0     0     3     1\n11.0     0    59    35    31     0     9     0  ...     4    49   369     0     0     0     0\n12.0     0     0     0     1     0     0     0  ...     0     0     0   192     0     0     0\n13.0     0     0     0     2    43     2     0  ...     0     2     0     2  1120    33     0\n14.0     1     0     0     0    13    44     0  ...     0     3     3    10    89   203     2\n15.0     0     0     6     1     0     0     0  ...     2     0     5     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     30     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   855    10    23     1     2     0  ...    79   370    13     0     0     0     0\n2.0      0    57   435     8     0     0     0  ...     1   220    75     0     0     0     0\n3.0      1     5    75   113     0     8     0  ...     7    10    10     0     0     0     0\n4.0     13     2     1     5   334    30     2  ...     5     4     6     0    26    36     0\n5.0      0     3     0     7     5   581     0  ...     3    23     2     0     4    67     0\n6.0      0     0     0     0     1     0    24  ...     0     0     0     0     0     0     0\n7.0      7     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     1     0    15     0  ...     0     0     0     0     0     4     0\n9.0      0   126     8     4     1     0     0  ...   584   185     9     0     0     0     0\n10.0     1   242    85    14     2     1     0  ...    75  1788   111     0     0    10     0\n11.0     0    17    58     6     0     0     0  ...    17    82   379     0     0     1     0\n12.0     0     0     1     0     0     4     0  ...     0     0     0   186     0     1     0\n13.0     0     0     0     0    18     2     0  ...     0     0     0     6  1152    24     0\n14.0     0     0     1     0    12    56     0  ...     3     0     5    36    90   161     0\n15.0     0     2     0     0     0     0     0  ...     7     0     7     0     0     0    71\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results3.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.695081          0.582247           0.648307\n1    2          0.737291          0.684670           0.697336\n2    3          0.711821          0.670818           0.666978\n3    4          0.732977          0.692036           0.693421\n\nAverage Performance Over 4 Runs:\nOverall Accuracy: 0.7193\nAverage Accuracy: 0.6574\nKappa Coefficient: 0.6765\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_4 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 40.8833\nEpoch 1: val_loss improved from inf to 25.83064, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 40.8232 - val_loss: 25.8306\nEpoch 2/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26.0735\nEpoch 2: val_loss improved from 25.83064 to 24.80719, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 26.0774 - val_loss: 24.8072\nEpoch 3/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 25.8611\nEpoch 3: val_loss improved from 24.80719 to 24.64030, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 25.8716 - val_loss: 24.6403\nEpoch 4/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.1235\nEpoch 4: val_loss improved from 24.64030 to 22.87881, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 24.1167 - val_loss: 22.8788\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23.0952\nEpoch 5: val_loss improved from 22.87881 to 21.98920, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 23.0894 - val_loss: 21.9892\nEpoch 6/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.9326\nEpoch 6: val_loss improved from 21.98920 to 21.03850, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 21.9285 - val_loss: 21.0385\nEpoch 7/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.6102\nEpoch 7: val_loss did not improve from 21.03850\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 22.6547 - val_loss: 26.7567\nEpoch 8/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 28.7267\nEpoch 8: val_loss did not improve from 21.03850\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 28.8368 - val_loss: 36.7838\nEpoch 9/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 27.4696\nEpoch 9: val_loss did not improve from 21.03850\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 27.4333 - val_loss: 21.1464\nEpoch 10/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23.6540\nEpoch 10: val_loss improved from 21.03850 to 20.25050, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 23.6525 - val_loss: 20.2505\nEpoch 11/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.1499\nEpoch 11: val_loss improved from 20.25050 to 18.13911, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 20.1447 - val_loss: 18.1391\nEpoch 12/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19.4665\nEpoch 12: val_loss improved from 18.13911 to 17.87720, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 19.4613 - val_loss: 17.8772\nEpoch 13/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18.6679\nEpoch 13: val_loss improved from 17.87720 to 16.95597, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 18.6656 - val_loss: 16.9560\nEpoch 14/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.6296\nEpoch 14: val_loss improved from 16.95597 to 16.30966, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 17.6250 - val_loss: 16.3097\nEpoch 15/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.7425\nEpoch 15: val_loss improved from 16.30966 to 15.70782, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 16.7363 - val_loss: 15.7078\nEpoch 16/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.9073\nEpoch 16: val_loss improved from 15.70782 to 15.07167, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 15.8991 - val_loss: 15.0717\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.0899\nEpoch 17: val_loss improved from 15.07167 to 14.44814, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 15.0844 - val_loss: 14.4481\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.3419\nEpoch 18: val_loss improved from 14.44814 to 13.88682, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 14.3367 - val_loss: 13.8868\nEpoch 19/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.7078\nEpoch 19: val_loss improved from 13.88682 to 13.59295, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 13.7033 - val_loss: 13.5930\nEpoch 20/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.2423\nEpoch 20: val_loss did not improve from 13.59295\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 13.2412 - val_loss: 13.9032\nEpoch 21/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.8997\nEpoch 21: val_loss improved from 13.59295 to 12.72140, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.8973 - val_loss: 12.7214\nEpoch 22/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 12.2892\nEpoch 22: val_loss did not improve from 12.72140\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.2956 - val_loss: 13.5423\nEpoch 23/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.4541\nEpoch 23: val_loss did not improve from 12.72140\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 14.5061 - val_loss: 20.0285\nEpoch 24/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.4228\nEpoch 24: val_loss did not improve from 12.72140\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 15.4153 - val_loss: 13.2536\nEpoch 25/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.3744\nEpoch 25: val_loss improved from 12.72140 to 12.58683, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 14.3537 - val_loss: 12.5868\nEpoch 26/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.0656\nEpoch 26: val_loss improved from 12.58683 to 10.97353, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 11.0815 - val_loss: 10.9735\nEpoch 27/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.3899\nEpoch 27: val_loss improved from 10.97353 to 9.68294, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.3869 - val_loss: 9.6829\nEpoch 28/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.4875\nEpoch 28: val_loss improved from 9.68294 to 9.66606, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.4868 - val_loss: 9.6661\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.3425\nEpoch 29: val_loss did not improve from 9.66606\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.3426 - val_loss: 9.9202\nEpoch 30/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.3080\nEpoch 30: val_loss did not improve from 9.66606\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.3067 - val_loss: 10.2398\nEpoch 31/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.2949\nEpoch 31: val_loss improved from 9.66606 to 9.53007, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 9.2878 - val_loss: 9.5301\nEpoch 32/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.5922\nEpoch 32: val_loss improved from 9.53007 to 8.41641, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 8.5810 - val_loss: 8.4164\nEpoch 33/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.7861\nEpoch 33: val_loss improved from 8.41641 to 7.54774, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.7806 - val_loss: 7.5477\nEpoch 34/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.2436\nEpoch 34: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.2435 - val_loss: 8.2727\nEpoch 35/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.0911\nEpoch 35: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.1002 - val_loss: 8.7949\nEpoch 36/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6385\nEpoch 36: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.7096 - val_loss: 12.2059\nEpoch 37/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.0674\nEpoch 37: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.0838 - val_loss: 11.7956\nEpoch 38/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.1844\nEpoch 38: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 10.1914 - val_loss: 8.6263\nEpoch 39/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.6467\nEpoch 39: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.6737 - val_loss: 12.8311\nEpoch 40/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2930\nEpoch 40: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.3018 - val_loss: 8.1189\nEpoch 41/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.3318\nEpoch 41: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 8.3500 - val_loss: 8.9944\nEpoch 42/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2658\nEpoch 42: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.2511 - val_loss: 9.1656\nEpoch 43/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.5596\nEpoch 43: val_loss did not improve from 7.54774\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 8.5374 - val_loss: 8.0713\nEpoch 44/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.1559\nEpoch 44: val_loss improved from 7.54774 to 6.63997, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.1317 - val_loss: 6.6400\nEpoch 45/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.1393\nEpoch 45: val_loss improved from 6.63997 to 5.47399, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 6.1309 - val_loss: 5.4740\nEpoch 46/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.2959\nEpoch 46: val_loss improved from 5.47399 to 4.89093, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.2946 - val_loss: 4.8909\nEpoch 47/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1734\nEpoch 47: val_loss improved from 4.89093 to 4.75480, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run4.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 5.1816 - val_loss: 4.7548\nEpoch 48/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.9735\nEpoch 48: val_loss did not improve from 4.75480\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.9766 - val_loss: 6.4784\nEpoch 49/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.0399\nEpoch 49: val_loss did not improve from 4.75480\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 5.0481 - val_loss: 11.9594\nEpoch 50/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.1703\nEpoch 50: val_loss did not improve from 4.75480\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 11.2145 - val_loss: 9.2469\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 52  64 120  54  50  67 174 168  76  65  58  97  37  62  78  41  80  57\n  66  51  48  68  49  81  92]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 1000, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\nThe model shall evaluate for 5 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   749    33    27     0     2     0  ...    86   450    21     0     0     0     0\n2.0      0    75   394    16     0     0     0  ...    18   211    65     0     0     0     0\n3.0      0    17    47   105     1     2     0  ...     3    18    28     0     0     0     0\n4.0      5     5     0     2   396    11     0  ...     3    14     5     0     7     0     0\n5.0      0     0     0     8     4   626     0  ...     0     1     0     1     8    45     0\n6.0      1     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0     15    18     0     0     0     0     0  ...     0     2     0     0     0     0     0\n8.0      0    16     0     0     0     0     0  ...     0     0     0     1     0     3     0\n9.0      0    76     6     4     0     3     0  ...   380   438    16     0     0     0     0\n10.0     0   173    76    12     2    13     0  ...   195  1822    27     0     0     6     1\n11.0     0    19   121    32     1     1     0  ...    11    57   322     0     0     1     2\n12.0     0     1     0     0     0     1     0  ...     0     1     0   192     0     1     0\n13.0     0     0     0     0    23     3     0  ...     0     0     0    10  1090    76     0\n14.0     4     8     5     6    21    37     0  ...     0     0     0    23    55   202     0\n15.0     0     3     4     0     0     0     0  ...     9     4     0     0     0     0    67\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   778    16    15     2     2     0  ...   110   421    11     0     0     0     1\n2.0      0    22   416    53     0     0     0  ...     0   274    29     0     0     0     0\n3.0      0     5    21   181     1     4     0  ...     2     6     1     0     0     0     0\n4.0      0     2     0     2   380    15     1  ...     0     7     0     0    51     0     0\n5.0      0     0     0     0    15   621     0  ...     0     1     0     0     1    51     0\n6.0      0     0     0     0     1     0    10  ...     0     0     0     0     0     0     0\n7.0      9     0     0     0     1     0     5  ...     0     0     0     0     0     0     0\n8.0      0     0     0     5     5     4     0  ...     0     0     0     5     0     1     0\n9.0      0   135     1     4    11     3     0  ...   497   272     6     0     0     0     0\n10.0     0   182    36    30     9    14     1  ...    68  1935    41     0     0     3     1\n11.0     0    26    55    25     0     5     0  ...     3    77   373     0     0     0     4\n12.0     0     0     0     2     0     0     0  ...     0     0     0   190     0     0     0\n13.0     0     0     0     0    30     3     0  ...     0     0     0     4  1109    61     0\n14.0     0     0     1     0    37    88     0  ...     0     0     0    30    71   138     2\n15.0     0     3     0     0     0     0     0  ...     1     5     3     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     1     0     0  ...     0     0     1     0     0     0     0\n1.0      0   846    24    31     5     5     0  ...    50   376     8     0     0     0     0\n2.0      0   106   393    15     2     2     0  ...    17   201    57     0     0     1     0\n3.0      3    73     8    55     1    29     0  ...     2    25    33     0     0     0     0\n4.0     12     0     1     8   406     6     1  ...     0     4     3     0    10     7     0\n5.0      0     0     0     0    13   660     0  ...     5     0     0     1     3    14     0\n6.0      1     0     0     0     5     0    16  ...     0     0     0     0     0     0     0\n7.0     11     0     0     0     1     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     6     0  ...     0     0     0     1     0     1     0\n9.0      0    80    10     5    10     2     0  ...   261   543    13     0     0     2     0\n10.0     0   186    78    11    19    13     1  ...    80  1866    73     0     0     3     1\n11.0     0    59    35    31     0     9     0  ...     4    49   369     0     0     0     0\n12.0     0     0     0     1     0     0     0  ...     0     0     0   192     0     0     0\n13.0     0     0     0     2    43     2     0  ...     0     2     0     2  1120    33     0\n14.0     1     0     0     0    13    44     0  ...     0     3     3    10    89   203     2\n15.0     0     0     6     1     0     0     0  ...     2     0     5     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     30     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   855    10    23     1     2     0  ...    79   370    13     0     0     0     0\n2.0      0    57   435     8     0     0     0  ...     1   220    75     0     0     0     0\n3.0      1     5    75   113     0     8     0  ...     7    10    10     0     0     0     0\n4.0     13     2     1     5   334    30     2  ...     5     4     6     0    26    36     0\n5.0      0     3     0     7     5   581     0  ...     3    23     2     0     4    67     0\n6.0      0     0     0     0     1     0    24  ...     0     0     0     0     0     0     0\n7.0      7     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     1     0    15     0  ...     0     0     0     0     0     4     0\n9.0      0   126     8     4     1     0     0  ...   584   185     9     0     0     0     0\n10.0     1   242    85    14     2     1     0  ...    75  1788   111     0     0    10     0\n11.0     0    17    58     6     0     0     0  ...    17    82   379     0     0     1     0\n12.0     0     0     1     0     0     4     0  ...     0     0     0   186     0     1     0\n13.0     0     0     0     0    18     2     0  ...     0     0     0     6  1152    24     0\n14.0     0     0     1     0    12    56     0  ...     3     0     5    36    90   161     0\n15.0     0     2     0     0     0     0     0  ...     7     0     7     0     0     0    71\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     14     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   857    47     3     2     3     0  ...    60   349    28     0     0     0     0\n2.0      0   120   379     8     0     3     0  ...    26   187    67     0     0     0     0\n3.0      3    37    36    53    10    14     0  ...     0    26    48     0     0     0     0\n4.0     14     3     0     6   400     9     4  ...     0     8     6     0     8     2     0\n5.0      0     0     0     2    11   664     0  ...     0     1     0     0     9     6     0\n6.0      3     0     0     0     0     0    20  ...     0     0     0     0     0     0     0\n7.0      8     0     0     5     0     0    43  ...     0     0     0     0     6     0     0\n8.0      0     0     0     0     0     4     0  ...     0     0     0     0     0     0     0\n9.0      1   117    17     3     1     8     0  ...   244   539     4     0     0     0     0\n10.0     0   262   108     6     3    12     2  ...   110  1770    37     0     0     0     0\n11.0     0    59    42    23     0     2     0  ...    20    86   325     0     0     0     1\n12.0     0     0     0     0     0    14     0  ...     0     0     0   179     0     1     0\n13.0     0     0     0     0    43     5     0  ...     0     0     0     3  1089    63     0\n14.0     2     0     0     1    38    88     0  ...     0     2     2    31    92   107     2\n15.0     0     3    14     0     0     2     0  ...     2     6     4     0     0     0    56\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results4.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.695081          0.582247           0.648307\n1    2          0.737291          0.684670           0.697336\n2    3          0.711821          0.670818           0.666978\n3    4          0.732977          0.692036           0.693421\n4    5          0.675054          0.640800           0.624930\n\nAverage Performance Over 5 Runs:\nOverall Accuracy: 0.7104\nAverage Accuracy: 0.6541\nKappa Coefficient: 0.6662\nFigure(800x500)\n\u001b[1mModel: \"OSEN\"\u001b[0m\n\n\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n\n input (\u001b[94mInputLayer\u001b[0m)         (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  -                      \n\n SparseAutoencoderNonLine  (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m200\u001b[0m)                \u001b[32m40,200\u001b[0m  input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n (\u001b[94mSparseAutoencoderNonLin\u001b[0m                                                                 \n\n dot_5 (\u001b[94mDot\u001b[0m)                (\u001b[96mNone\u001b[0m, \u001b[32m200\u001b[0m, \u001b[32m1\u001b[0m)                       \u001b[32m0\u001b[0m  SparseAutoencoderNonL \n                                                                    input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            \n\n\u001b[1m Total params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m40,200\u001b[0m (157.03 KB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\nEpoch 1/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 36.7278\nEpoch 1: val_loss improved from inf to 26.24405, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 36.6536 - val_loss: 26.2440\nEpoch 2/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 28.4219\nEpoch 2: val_loss improved from 26.24405 to 25.87011, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 28.4325 - val_loss: 25.8701\nEpoch 3/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.0760\nEpoch 3: val_loss improved from 25.87011 to 24.38579, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 25.0688 - val_loss: 24.3858\nEpoch 4/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.0527\nEpoch 4: val_loss improved from 24.38579 to 22.91959, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 24.0501 - val_loss: 22.9196\nEpoch 5/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.4231\nEpoch 5: val_loss improved from 22.91959 to 22.73110, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 23.4287 - val_loss: 22.7311\nEpoch 6/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.0460\nEpoch 6: val_loss did not improve from 22.73110\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 22.0831 - val_loss: 26.6656\nEpoch 7/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 29.8628\nEpoch 7: val_loss improved from 22.73110 to 21.80623, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 29.8275 - val_loss: 21.8062\nEpoch 8/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.6552\nEpoch 8: val_loss improved from 21.80623 to 21.06219, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 24.6713 - val_loss: 21.0622\nEpoch 9/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.6031\nEpoch 9: val_loss improved from 21.06219 to 20.30596, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 20.5967 - val_loss: 20.3060\nEpoch 10/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.2522\nEpoch 10: val_loss improved from 20.30596 to 19.09968, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 20.2129 - val_loss: 19.0997\nEpoch 11/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18.6548\nEpoch 11: val_loss improved from 19.09968 to 18.99949, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 18.6441 - val_loss: 18.9995\nEpoch 12/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18.1497\nEpoch 12: val_loss improved from 18.99949 to 17.78353, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 18.1241 - val_loss: 17.7835\nEpoch 13/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.0699\nEpoch 13: val_loss improved from 17.78353 to 16.48631, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 17.0574 - val_loss: 16.4863\nEpoch 14/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 16.1069\nEpoch 14: val_loss improved from 16.48631 to 15.65219, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 16.1048 - val_loss: 15.6522\nEpoch 15/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.4318\nEpoch 15: val_loss improved from 15.65219 to 15.00949, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 15.4285 - val_loss: 15.0095\nEpoch 16/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.9325\nEpoch 16: val_loss improved from 15.00949 to 14.66566, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 14.9237 - val_loss: 14.6657\nEpoch 17/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.7988\nEpoch 17: val_loss improved from 14.66566 to 14.22937, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 14.7916 - val_loss: 14.2294\nEpoch 18/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14.0527\nEpoch 18: val_loss did not improve from 14.22937\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 14.1293 - val_loss: 34.6677\nEpoch 19/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26.8382\nEpoch 19: val_loss improved from 14.22937 to 13.58381, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 26.6080 - val_loss: 13.5838\nEpoch 20/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16.4043\nEpoch 20: val_loss improved from 13.58381 to 12.97197, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 16.3802 - val_loss: 12.9720\nEpoch 21/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 13.3417\nEpoch 21: val_loss improved from 12.97197 to 12.13962, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 13.3200 - val_loss: 12.1396\nEpoch 22/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.2683\nEpoch 22: val_loss improved from 12.13962 to 11.88979, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 12.2563 - val_loss: 11.8898\nEpoch 23/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.6820\nEpoch 23: val_loss improved from 11.88979 to 11.51687, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 11.6739 - val_loss: 11.5169\nEpoch 24/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.0162\nEpoch 24: val_loss improved from 11.51687 to 10.96635, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 11.0135 - val_loss: 10.9664\nEpoch 25/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.2839\nEpoch 25: val_loss improved from 10.96635 to 10.17615, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 10.2787 - val_loss: 10.1761\nEpoch 26/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.6081\nEpoch 26: val_loss improved from 10.17615 to 9.43165, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.6025 - val_loss: 9.4316\nEpoch 27/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.0484\nEpoch 27: val_loss did not improve from 9.43165\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.0532 - val_loss: 10.8845\nEpoch 28/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.9765\nEpoch 28: val_loss did not improve from 9.43165\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 10.0574 - val_loss: 29.0153\nEpoch 29/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18.1767\nEpoch 29: val_loss did not improve from 9.43165\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 18.1009 - val_loss: 9.4487\nEpoch 30/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.7093\nEpoch 30: val_loss improved from 9.43165 to 9.39076, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 10.7124 - val_loss: 9.3908\nEpoch 31/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.1135\nEpoch 31: val_loss improved from 9.39076 to 8.05959, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.0916 - val_loss: 8.0596\nEpoch 32/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.7146\nEpoch 32: val_loss improved from 8.05959 to 7.91473, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.7092 - val_loss: 7.9147\nEpoch 33/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.4530\nEpoch 33: val_loss improved from 7.91473 to 7.51620, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.4494 - val_loss: 7.5162\nEpoch 34/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9026\nEpoch 34: val_loss did not improve from 7.51620\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.9043 - val_loss: 8.6467\nEpoch 35/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.2254\nEpoch 35: val_loss did not improve from 7.51620\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 8.2808 - val_loss: 18.0662\nEpoch 36/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.7633\nEpoch 36: val_loss did not improve from 7.51620\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 12.7198 - val_loss: 7.9882\nEpoch 37/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6208\nEpoch 37: val_loss improved from 7.51620 to 7.38735, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.6254 - val_loss: 7.3873\nEpoch 38/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.8632\nEpoch 38: val_loss improved from 7.38735 to 6.36550, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.8593 - val_loss: 6.3655\nEpoch 39/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.1134\nEpoch 39: val_loss improved from 6.36550 to 5.93666, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.1036 - val_loss: 5.9367\nEpoch 40/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.5007\nEpoch 40: val_loss did not improve from 5.93666\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 5.5020 - val_loss: 7.4540\nEpoch 41/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9439\nEpoch 41: val_loss did not improve from 5.93666\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.9676 - val_loss: 15.1547\nEpoch 42/50\n\u001b[1m101/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.5064\nEpoch 42: val_loss did not improve from 5.93666\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 11.4851 - val_loss: 7.1427\nEpoch 43/50\n\u001b[1m100/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.3283\nEpoch 43: val_loss did not improve from 5.93666\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.3308 - val_loss: 6.1466\nEpoch 44/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.7062\nEpoch 44: val_loss improved from 5.93666 to 5.41820, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5.6900 - val_loss: 5.4182\nEpoch 45/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1223\nEpoch 45: val_loss improved from 5.41820 to 4.83597, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5.1127 - val_loss: 4.8360\nEpoch 46/50\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.6685\nEpoch 46: val_loss did not improve from 4.83597\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4.6815 - val_loss: 16.4462\nEpoch 47/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.0562\nEpoch 47: val_loss did not improve from 4.83597\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 11.9342 - val_loss: 6.0290\nEpoch 48/50\n\u001b[1m102/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.0694\nEpoch 48: val_loss did not improve from 4.83597\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 6.0682 - val_loss: 5.1334\nEpoch 49/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.5088\nEpoch 49: val_loss improved from 4.83597 to 4.60611, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.5056 - val_loss: 4.6061\nEpoch 50/50\n\u001b[1m 99/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0818\nEpoch 50: val_loss improved from 4.60611 to 4.13299, saving model to weights/Indian_pines_corrected/SRL-SOA_q3_run5.weights.h5\n\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 4.0797 - val_loss: 4.1330\nSRL-SOA is trained!\nSelected number of bands:  25\n======Selected band indices ======= \n [ 21 162  45 179 172 114 124 139 170 154 193  13  59 132  51  47  69 190\n  52 176  26  44  40 160 148]\nClassification...\n\nSVM parameter search is selected.\nSVM Train...\nSVM Train Finished.\n\nBest paramters:{'C': 100, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'kernel': 'rbf'}\nThe model shall evaluate for 6 times\n\nConfusion Matrix for Run 1:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0      6     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   749    33    27     0     2     0  ...    86   450    21     0     0     0     0\n2.0      0    75   394    16     0     0     0  ...    18   211    65     0     0     0     0\n3.0      0    17    47   105     1     2     0  ...     3    18    28     0     0     0     0\n4.0      5     5     0     2   396    11     0  ...     3    14     5     0     7     0     0\n5.0      0     0     0     8     4   626     0  ...     0     1     0     1     8    45     0\n6.0      1     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n7.0     15    18     0     0     0     0     0  ...     0     2     0     0     0     0     0\n8.0      0    16     0     0     0     0     0  ...     0     0     0     1     0     3     0\n9.0      0    76     6     4     0     3     0  ...   380   438    16     0     0     0     0\n10.0     0   173    76    12     2    13     0  ...   195  1822    27     0     0     6     1\n11.0     0    19   121    32     1     1     0  ...    11    57   322     0     0     1     2\n12.0     0     1     0     0     0     1     0  ...     0     1     0   192     0     1     0\n13.0     0     0     0     0    23     3     0  ...     0     0     0    10  1090    76     0\n14.0     4     8     5     6    21    37     0  ...     0     0     0    23    55   202     0\n15.0     0     3     4     0     0     0     0  ...     9     4     0     0     0     0    67\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 2:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     34     1     0     0     1     0     1  ...     0     0     0     0     0     0     0\n1.0      0   778    16    15     2     2     0  ...   110   421    11     0     0     0     1\n2.0      0    22   416    53     0     0     0  ...     0   274    29     0     0     0     0\n3.0      0     5    21   181     1     4     0  ...     2     6     1     0     0     0     0\n4.0      0     2     0     2   380    15     1  ...     0     7     0     0    51     0     0\n5.0      0     0     0     0    15   621     0  ...     0     1     0     0     1    51     0\n6.0      0     0     0     0     1     0    10  ...     0     0     0     0     0     0     0\n7.0      9     0     0     0     1     0     5  ...     0     0     0     0     0     0     0\n8.0      0     0     0     5     5     4     0  ...     0     0     0     5     0     1     0\n9.0      0   135     1     4    11     3     0  ...   497   272     6     0     0     0     0\n10.0     0   182    36    30     9    14     1  ...    68  1935    41     0     0     3     1\n11.0     0    26    55    25     0     5     0  ...     3    77   373     0     0     0     4\n12.0     0     0     0     2     0     0     0  ...     0     0     0   190     0     0     0\n13.0     0     0     0     0    30     3     0  ...     0     0     0     4  1109    61     0\n14.0     0     0     1     0    37    88     0  ...     0     0     0    30    71   138     2\n15.0     0     3     0     0     0     0     0  ...     1     5     3     0     0     0    76\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 3:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     15     0     0     0     1     0     0  ...     0     0     1     0     0     0     0\n1.0      0   846    24    31     5     5     0  ...    50   376     8     0     0     0     0\n2.0      0   106   393    15     2     2     0  ...    17   201    57     0     0     1     0\n3.0      3    73     8    55     1    29     0  ...     2    25    33     0     0     0     0\n4.0     12     0     1     8   406     6     1  ...     0     4     3     0    10     7     0\n5.0      0     0     0     0    13   660     0  ...     5     0     0     1     3    14     0\n6.0      1     0     0     0     5     0    16  ...     0     0     0     0     0     0     0\n7.0     11     0     0     0     1     0     2  ...     0     0     0     0     0     0     0\n8.0      0     0     0     0     0     6     0  ...     0     0     0     1     0     1     0\n9.0      0    80    10     5    10     2     0  ...   261   543    13     0     0     2     0\n10.0     0   186    78    11    19    13     1  ...    80  1866    73     0     0     3     1\n11.0     0    59    35    31     0     9     0  ...     4    49   369     0     0     0     0\n12.0     0     0     0     1     0     0     0  ...     0     0     0   192     0     0     0\n13.0     0     0     0     2    43     2     0  ...     0     2     0     2  1120    33     0\n14.0     1     0     0     0    13    44     0  ...     0     3     3    10    89   203     2\n15.0     0     0     6     1     0     0     0  ...     2     0     5     0     0     0    73\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 4:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     30     0     0     0     0     0     0  ...     1     0     0     0     0     0     0\n1.0      0   855    10    23     1     2     0  ...    79   370    13     0     0     0     0\n2.0      0    57   435     8     0     0     0  ...     1   220    75     0     0     0     0\n3.0      1     5    75   113     0     8     0  ...     7    10    10     0     0     0     0\n4.0     13     2     1     5   334    30     2  ...     5     4     6     0    26    36     0\n5.0      0     3     0     7     5   581     0  ...     3    23     2     0     4    67     0\n6.0      0     0     0     0     1     0    24  ...     0     0     0     0     0     0     0\n7.0      7     0     0     0     1     0     0  ...     0     0     0     0     0     0     0\n8.0      0     0     0     1     0    15     0  ...     0     0     0     0     0     4     0\n9.0      0   126     8     4     1     0     0  ...   584   185     9     0     0     0     0\n10.0     1   242    85    14     2     1     0  ...    75  1788   111     0     0    10     0\n11.0     0    17    58     6     0     0     0  ...    17    82   379     0     0     1     0\n12.0     0     0     1     0     0     4     0  ...     0     0     0   186     0     1     0\n13.0     0     0     0     0    18     2     0  ...     0     0     0     6  1152    24     0\n14.0     0     0     1     0    12    56     0  ...     3     0     5    36    90   161     0\n15.0     0     2     0     0     0     0     0  ...     7     0     7     0     0     0    71\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 5:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     14     0     0     0     0     0     0  ...     0     0     0     0     0     0     0\n1.0      0   857    47     3     2     3     0  ...    60   349    28     0     0     0     0\n2.0      0   120   379     8     0     3     0  ...    26   187    67     0     0     0     0\n3.0      3    37    36    53    10    14     0  ...     0    26    48     0     0     0     0\n4.0     14     3     0     6   400     9     4  ...     0     8     6     0     8     2     0\n5.0      0     0     0     2    11   664     0  ...     0     1     0     0     9     6     0\n6.0      3     0     0     0     0     0    20  ...     0     0     0     0     0     0     0\n7.0      8     0     0     5     0     0    43  ...     0     0     0     0     6     0     0\n8.0      0     0     0     0     0     4     0  ...     0     0     0     0     0     0     0\n9.0      1   117    17     3     1     8     0  ...   244   539     4     0     0     0     0\n10.0     0   262   108     6     3    12     2  ...   110  1770    37     0     0     0     0\n11.0     0    59    42    23     0     2     0  ...    20    86   325     0     0     0     1\n12.0     0     0     0     0     0    14     0  ...     0     0     0   179     0     1     0\n13.0     0     0     0     0    43     5     0  ...     0     0     0     3  1089    63     0\n14.0     2     0     0     1    38    88     0  ...     0     2     2    31    92   107     2\n15.0     0     3    14     0     0     2     0  ...     2     6     4     0     0     0    56\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nConfusion Matrix for Run 6:\n      0.0   1.0   2.0   3.0   4.0   5.0   6.0   ...  9.0   10.0  11.0  12.0  13.0  14.0  15.0\n0.0     25     0     0     0     1     0     8  ...     1     0     0     0     0     0     0\n1.0      1   977    37    17     2     4     0  ...    72   238     9     0     0     0     0\n2.0      0    49   480    40     0     0     0  ...     7   165    51     0     0     0     0\n3.0      0    50    44   107     2     6     3  ...     1     6     4     0     0     0     0\n4.0      2     5     0     7   401     8     9  ...     1     5     1     0    13     5     0\n5.0      0     0     0     2     3   648     0  ...     0     1     0     9     0    28     0\n6.0      0     0     0     0     1     0    22  ...     0     0     0     0     0     0     0\n7.0      9     0     0     0     2     0     1  ...     0     1     0     0     0     0     0\n8.0      0     0     0     0     2     1     0  ...     0     0     0     0     0     0     0\n9.0      0    95     5     4     0     6     3  ...   668   140     6     0     0     0     0\n10.0     0   206    85    23     7    11     5  ...   104  1827    52     0     0     3     1\n11.0     0    47    70    43     0     4     0  ...    10    31   364     0     0     0     0\n12.0     0     0     0     0     0     4     1  ...     0     0     0   151     0    12     0\n13.0     0     0     0     0    47     9     0  ...     0     2     0     1  1123    18     0\n14.0     0     1     0     1    16    66     2  ...     0     4     0    17   112   145     0\n15.0     0    12    11     1     0     0     0  ...     0    10     1     0     0     0    55\n\n[16 rows x 16 columns]\nFigure(600x500)\n\nPerformance results saved to: results/performance_results5.csv\nConfusion matrices saved to: results/confusion_matrices.csv\n\nPerformance Metrics Summary:\n   Run  Overall Accuracy  Average Accuracy  Kappa Coefficient\n0    1          0.695081          0.582247           0.648307\n1    2          0.737291          0.684670           0.697336\n2    3          0.711821          0.670818           0.666978\n3    4          0.732977          0.692036           0.693421\n4    5          0.675054          0.640800           0.624930\n5    6          0.765225          0.736956           0.731529\n\nAverage Performance Over 6 Runs:\nOverall Accuracy: 0.7196\nAverage Accuracy: 0.6679\nKappa Coefficient: 0.6771\nFigure(800x500)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"%matplotlib inline\n!python main.py --dataset Indian_pines_corrected --method SRL-SOA --q 3 --bands 25 --weights False\n\n# [3] with attention\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Dagshub \n!pip install mlflow dagshub\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:50:26.201314Z","iopub.execute_input":"2025-02-19T15:50:26.201858Z","iopub.status.idle":"2025-02-19T15:50:46.311989Z","shell.execute_reply.started":"2025-02-19T15:50:26.201816Z","shell.execute_reply":"2025-02-19T15:50:46.310546Z"}},"outputs":[{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-2.20.2-py3-none-any.whl.metadata (30 kB)\nCollecting dagshub\n  Downloading dagshub-0.5.6-py3-none-any.whl.metadata (12 kB)\nCollecting mlflow-skinny==2.20.2 (from mlflow)\n  Downloading mlflow_skinny-2.20.2-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.14.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.3)\nCollecting pyarrow<19,>=4.0.0 (from mlflow)\n  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (3.1.0)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.20.2->mlflow)\n  Downloading databricks_sdk-0.44.1-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (8.5.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (1.29.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (1.29.0)\nRequirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (24.2)\nRequirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (2.11.0a1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.20.2->mlflow) (4.12.2)\nCollecting appdirs>=1.4.4 (from dagshub)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from dagshub) (0.28.1)\nRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from dagshub) (13.9.4)\nCollecting dacite~=1.6.0 (from dagshub)\n  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from dagshub) (9.0.0)\nCollecting gql[requests] (from dagshub)\n  Downloading gql-3.5.1-py2.py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from dagshub) (0.6.7)\nCollecting treelib>=1.6.4 (from dagshub)\n  Downloading treelib-1.7.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting pathvalidate>=3.0.0 (from dagshub)\n  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from dagshub) (1.36.13)\nRequirement already satisfied: semver in /usr/local/lib/python3.10/dist-packages (from dagshub) (3.0.4)\nCollecting dagshub-annotation-converter>=0.1.3 (from dagshub)\n  Downloading dagshub_annotation_converter-0.1.3-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dagshub-annotation-converter>=0.1.3->dagshub) (5.3.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from dagshub-annotation-converter>=0.1.3->dagshub) (11.0.0)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.2->mlflow) (4.0.11)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3->mlflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3->mlflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dagshub) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->dagshub) (2.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: botocore<1.37.0,>=1.36.13 in /usr/local/lib/python3.10/dist-packages (from boto3->dagshub) (1.36.13)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from boto3->dagshub) (0.11.2)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->dagshub) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->dagshub) (0.9.0)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (1.18.3)\nCollecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.2.2)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.2->mlflow) (2.27.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.2->mlflow) (5.0.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.2->mlflow) (3.21.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.2->mlflow) (1.2.15)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.2->mlflow) (0.50b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.2->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.2->mlflow) (2.28.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.2->mlflow) (3.4.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\nRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.2.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3->mlflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.2->mlflow) (1.17.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.2->mlflow) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.2->mlflow) (4.9)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.2->mlflow) (0.6.1)\nDownloading mlflow-2.20.2-py3-none-any.whl (28.4 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-2.20.2-py3-none-any.whl (6.0 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dagshub-0.5.6-py3-none-any.whl (259 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading dacite-1.6.0-py3-none-any.whl (12 kB)\nDownloading dagshub_annotation_converter-0.1.3-py3-none-any.whl (33 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\nDownloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading treelib-1.7.0-py3-none-any.whl (18 kB)\nDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading databricks_sdk-0.44.1-py3-none-any.whl (648 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m648.7/648.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading gql-3.5.1-py2.py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m74.2/74.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, treelib, pyarrow, pathvalidate, gunicorn, graphql-core, dacite, backoff, graphql-relay, graphene, gql, databricks-sdk, mlflow-skinny, dagshub-annotation-converter, mlflow, dagshub\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.0\n    Uninstalling pyarrow-19.0.0:\n      Successfully uninstalled pyarrow-19.0.0\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.9.2\n    Uninstalling dacite-1.9.2:\n      Successfully uninstalled dacite-1.9.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nydata-profiling 4.12.2 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 dacite-1.6.0 dagshub-0.5.6 dagshub-annotation-converter-0.1.3 databricks-sdk-0.44.1 gql-3.5.1 graphene-3.4.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.20.2 mlflow-skinny-2.20.2 pathvalidate-3.2.3 pyarrow-18.1.0 treelib-1.7.0\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import mlflow\nimport dagshub\nimport dagshub\ndagshub.init(repo_owner='vidhi-gajra-git', repo_name='SRL_SOA', mlflow=True)\n# Replace with your DAGsHub repository details\nDAGSHUB_REPO_OWNER = \"your-username\"\nDAGSHUB_REPO_NAME = \"your-repo\"\nDAGSHUB_USERNAME = \"your-username\"\nDAGSHUB_TOKEN = \"your-dagshub-token\"  # Get this from DAGsHub settings\n\ndagshub.auth.add_basic_auth(DAGSHUB_USERNAME, DAGSHUB_TOKEN)\n\nMLFLOW_TRACKING_URI = f\"https://dagshub.com/{DAGSHUB_REPO_OWNER}/{DAGSHUB_REPO_NAME}.mlflow\"\nmlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\nmlflow.set_experiment(\"SparseAutoencoder_Attention\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}